/* 
  This file was generated by KreMLin <https://github.com/FStarLang/kremlin>
  KreMLin invocation: /home/nkulatov/new2/kremlin/kremlin/krml -fbuiltin-uint128 -funroll-loops 8 -add-include "TestLib.h" /dist/generic/testlib.c -skip-compilation -no-prefix Hacl.Impl.P256 -bundle Lib.* -bundle Spec.* -bundle Hacl.Impl.P256=Hacl.Impl.P256,Hacl.Impl.LowLevel,Hacl.Impl.SolinasReduction,Hacl.Spec.P256.*,Hacl.Spec.Curve25519.*,Hacl.Impl.Curve25519.* -bundle Hacl.Impl.ECDSA.P256SHA256.Verification=Hacl.Impl.MontgomeryMultiplication,Hacl.Impl.ECDSA.P256SHA256.Verification,Hacl.Impl.MM.Exponent -library C,FStar -drop LowStar,Spec,Prims,Lib,C.Loops.*,Hacl.Spec.P256.Lemmas,Hacl.Spec.P256,Hacl.Spec.ECDSA -add-include "c/Lib_PrintBuffer.h" -add-include "FStar_UInt_8_16_32_64.h" -tmpdir p256-c .output/prims.krml .output/FStar_Pervasives_Native.krml .output/FStar_Pervasives.krml .output/FStar_Squash.krml .output/FStar_Classical.krml .output/FStar_StrongExcludedMiddle.krml .output/FStar_FunctionalExtensionality.krml .output/FStar_List_Tot_Base.krml .output/FStar_List_Tot_Properties.krml .output/FStar_List_Tot.krml .output/FStar_Mul.krml .output/FStar_Math_Lib.krml .output/FStar_Math_Lemmas.krml .output/FStar_Seq_Base.krml .output/FStar_Seq_Properties.krml .output/FStar_Seq.krml .output/FStar_Set.krml .output/FStar_Preorder.krml .output/FStar_Ghost.krml .output/FStar_ErasedLogic.krml .output/FStar_PropositionalExtensionality.krml .output/FStar_PredicateExtensionality.krml .output/FStar_TSet.krml .output/FStar_Monotonic_Heap.krml .output/FStar_Heap.krml .output/FStar_Map.krml .output/FStar_Monotonic_Witnessed.krml .output/FStar_Monotonic_HyperHeap.krml .output/FStar_Monotonic_HyperStack.krml .output/FStar_HyperStack.krml .output/FStar_HyperStack_ST.krml .output/FStar_Calc.krml .output/FStar_BitVector.krml .output/FStar_UInt.krml .output/FStar_UInt32.krml .output/FStar_Universe.krml .output/FStar_GSet.krml .output/FStar_ModifiesGen.krml .output/FStar_Range.krml .output/FStar_Reflection_Types.krml .output/FStar_Tactics_Types.krml .output/FStar_Tactics_Result.krml .output/FStar_Tactics_Effect.krml .output/FStar_Tactics_Util.krml .output/FStar_Reflection_Data.krml .output/FStar_Reflection_Const.krml .output/FStar_Char.krml .output/FStar_Exn.krml .output/FStar_ST.krml .output/FStar_All.krml .output/FStar_List.krml .output/FStar_String.krml .output/FStar_Order.krml .output/FStar_Reflection_Basic.krml .output/FStar_Reflection_Derived.krml .output/FStar_Tactics_Builtins.krml .output/FStar_Reflection_Formula.krml .output/FStar_Reflection_Derived_Lemmas.krml .output/FStar_Reflection.krml .output/FStar_Tactics_Derived.krml .output/FStar_Tactics_Logic.krml .output/FStar_Tactics.krml .output/FStar_BigOps.krml .output/LowStar_Monotonic_Buffer.krml .output/LowStar_Buffer.krml .output/LowStar_BufferOps.krml .output/Spec_Loops.krml .output/FStar_UInt64.krml .output/C_Loops.krml .output/FStar_Int.krml .output/FStar_Int64.krml .output/FStar_Int63.krml .output/FStar_Int32.krml .output/FStar_Int16.krml .output/FStar_Int8.krml .output/FStar_UInt63.krml .output/FStar_UInt16.krml .output/FStar_UInt8.krml .output/FStar_Int_Cast.krml .output/FStar_UInt128.krml .output/FStar_Int_Cast_Full.krml .output/FStar_Int128.krml .output/Lib_IntTypes.krml .output/Lib_Loops.krml .output/Lib_LoopCombinators.krml .output/Lib_RawIntTypes.krml .output/Lib_Sequence.krml .output/Lib_ByteSequence.krml .output/LowStar_ImmutableBuffer.krml .output/Lib_Buffer.krml .output/FStar_HyperStack_All.krml .output/Hacl_Spec_ECDSAP256_Definition.krml .output/Spec_Hash_Definitions.krml .output/Spec_Hash_Lemmas0.krml .output/Spec_Hash_PadFinish.krml .output/Spec_SHA1.krml .output/Spec_MD5.krml .output/Spec_SHA2_Constants.krml .output/Spec_SHA2.krml .output/Spec_Hash.krml .output/Spec_Curve25519_Lemmas.krml .output/FStar_Reflection_Arith.krml .output/FStar_Tactics_Canon.krml .output/Hacl_Spec_P256_Definitions.krml .output/Hacl_Impl_Curve25519_Lemmas.krml .output/Spec_Curve25519.krml .output/Hacl_Spec_Curve25519_Field64_Definition.krml .output/Hacl_Spec_Curve25519_Field64_Lemmas.krml .output/Hacl_Spec_P256_Basic.krml .output/Hacl_Spec_P256_Lemmas.krml .output/Hacl_Spec_P256_Core.krml .output/Hacl_Spec_P256_MontgomeryMultiplication.krml .output/Hacl_Impl_LowLevel.krml .output/Hacl_Spec_P256_SolinasReduction.krml .output/Hacl_Impl_SolinasReduction.krml .output/FStar_Kremlin_Endianness.krml .output/C_Endianness.krml .output/C.krml .output/Lib_ByteBuffer.krml .output/Spec_Hash_Incremental.krml .output/Spec_Hash_Lemmas.krml .output/Hacl_Hash_Lemmas.krml .output/LowStar_Modifies.krml .output/Hacl_Hash_Definitions.krml .output/Hacl_Hash_PadFinish.krml .output/Hacl_Hash_MD.krml .output/Hacl_Impl_MontgomeryMultiplication.krml .output/Hacl_Spec_P256.krml .output/Hacl_Spec_P256_MontgomeryMultiplication_PointDouble.krml .output/Hacl_Spec_P256_MontgomeryMultiplication_PointAdd.krml .output/Hacl_Spec_P256_Ladder.krml .output/Hacl_Spec_ECDSA.krml .output/Hacl_Impl_MM_Exponent.krml .output/Hacl_Hash_Core_SHA2_Constants.krml .output/Hacl_Hash_Core_SHA2.krml .output/Hacl_Hash_SHA2.krml .output/Hacl_Spec_P256_Normalisation.krml .output/Hacl_Impl_P256.krml .output/Hacl_Impl_ECDSA_P256SHA256_Verification.krml
  F* version: ea91ae8c
  KreMLin version: 27ce15c8
 */

#include "Hacl_Impl_P256.h"

inline K___uint64_t_uint64_t
Hacl_Spec_P256_Basic_addcarry(uint64_t x, uint64_t y, uint64_t cin)
{
  uint64_t res1 = x + cin;
  uint64_t c;
  if (res1 < cin)
    c = (uint64_t)1U;
  else
    c = (uint64_t)0U;
  uint64_t res = res1 + y;
  uint64_t c1;
  if (res < res1)
    c1 = c + (uint64_t)1U;
  else
    c1 = c;
  return ((K___uint64_t_uint64_t){ .fst = res, .snd = c1 });
}

inline static K___uint64_t_uint64_t
Hacl_Spec_P256_Basic_subborrow(uint64_t x, uint64_t y, uint64_t cin)
{
  uint64_t res = x - y - cin;
  uint64_t c;
  if (cin == (uint64_t)1U)
    if (x <= y)
      c = (uint64_t)1U;
    else
      c = (uint64_t)0U;
  else if (x < y)
    c = (uint64_t)1U;
  else
    c = (uint64_t)0U;
  return ((K___uint64_t_uint64_t){ .fst = res, .snd = c });
}

typedef struct
K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t_s
{
  K___uint64_t_uint64_t_uint64_t_uint64_t fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t snd;
}
K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t;

static K___uint64_t_uint64_t_uint64_t_uint64_t
Hacl_Spec_P256_Core_reduction_prime_2prime_with_carry(
  uint64_t carry,
  K___uint64_t_uint64_t_uint64_t_uint64_t a
)
{
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut0 =
    {
      .fst = a,
      .snd = {
        .fst = (uint64_t)0xffffffffffffffffU,
        .snd = (uint64_t)0xffffffffU,
        .thd = (uint64_t)0U,
        .f3 = (uint64_t)0xffffffff00000001U
      }
    };
  uint64_t f23 = scrut0.snd.f3;
  uint64_t f22 = scrut0.snd.thd;
  uint64_t f21 = scrut0.snd.snd;
  uint64_t f20 = scrut0.snd.fst;
  uint64_t f13 = scrut0.fst.f3;
  uint64_t f12 = scrut0.fst.thd;
  uint64_t f11 = scrut0.fst.snd;
  uint64_t f10 = scrut0.fst.fst;
  K___uint64_t_uint64_t scrut1 = Hacl_Spec_P256_Basic_subborrow(f10, f20, (uint64_t)0U);
  uint64_t o0 = scrut1.fst;
  uint64_t c0 = scrut1.snd;
  K___uint64_t_uint64_t scrut2 = Hacl_Spec_P256_Basic_subborrow(f11, f21, c0);
  uint64_t o1 = scrut2.fst;
  uint64_t c1 = scrut2.snd;
  K___uint64_t_uint64_t scrut3 = Hacl_Spec_P256_Basic_subborrow(f12, f22, c1);
  uint64_t o2 = scrut3.fst;
  uint64_t c2 = scrut3.snd;
  K___uint64_t_uint64_t scrut4 = Hacl_Spec_P256_Basic_subborrow(f13, f23, c2);
  uint64_t o3 = scrut4.fst;
  uint64_t c3 = scrut4.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut5 = { .fst = c3, .snd = { .fst = o0, .snd = o1, .thd = o2, .f3 = o3 } };
  uint64_t r3 = scrut5.snd.f3;
  uint64_t r2 = scrut5.snd.thd;
  uint64_t r1 = scrut5.snd.snd;
  uint64_t r0 = scrut5.snd.fst;
  uint64_t cin = scrut5.fst;
  K___uint64_t_uint64_t scrut6 = Hacl_Spec_P256_Basic_subborrow(carry, (uint64_t)0U, cin);
  uint64_t c = scrut6.snd;
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut = { .fst = { .fst = r0, .snd = r1, .thd = r2, .f3 = r3 }, .snd = a };
  uint64_t y3 = scrut.snd.f3;
  uint64_t y2 = scrut.snd.thd;
  uint64_t y1 = scrut.snd.snd;
  uint64_t y0 = scrut.snd.fst;
  uint64_t x3 = scrut.fst.f3;
  uint64_t x2 = scrut.fst.thd;
  uint64_t x1 = scrut.fst.snd;
  uint64_t x0 = scrut.fst.fst;
  uint64_t mask = ~FStar_UInt64_eq_mask(c, (uint64_t)0U);
  uint64_t r01 = y0 & mask | x0 & ~mask;
  uint64_t r11 = y1 & mask | x1 & ~mask;
  uint64_t r21 = y2 & mask | x2 & ~mask;
  uint64_t r31 = y3 & mask | x3 & ~mask;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  result = { .fst = r01, .snd = r11, .thd = r21, .f3 = r31 };
  return result;
}

static void
Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(
  uint64_t *a,
  uint64_t *b,
  uint64_t *r
)
{
  uint64_t a0 = a[0U];
  uint64_t a1 = a[1U];
  uint64_t a2 = a[2U];
  uint64_t a3 = a[3U];
  uint64_t b0 = b[0U];
  uint64_t b1 = b[1U];
  uint64_t b2 = b[2U];
  uint64_t b3 = b[3U];
  uint64_t prim0 = (uint64_t)0xffffffffffffffffU;
  uint64_t prim1 = (uint64_t)0x00000000ffffffffU;
  uint64_t prim2 = (uint64_t)0U;
  uint64_t prim3 = (uint64_t)0xffffffff00000001U;
  uint128_t res0 = (uint128_t)b0 * a0;
  uint64_t l00 = (uint64_t)res0;
  uint64_t h010 = (uint64_t)(res0 >> (uint32_t)64U);
  uint128_t res1 = (uint128_t)b1 * a0;
  uint64_t l10 = (uint64_t)res1;
  uint64_t h10 = (uint64_t)(res1 >> (uint32_t)64U);
  uint128_t res2 = (uint128_t)b2 * a0;
  uint64_t l20 = (uint64_t)res2;
  uint64_t h20 = (uint64_t)(res2 >> (uint32_t)64U);
  uint128_t res3 = (uint128_t)b3 * a0;
  uint64_t l30 = (uint64_t)res3;
  uint64_t h30 = (uint64_t)(res3 >> (uint32_t)64U);
  uint64_t o04 = l00;
  K___uint64_t_uint64_t scrut0 = Hacl_Spec_P256_Basic_addcarry(l10, h010, (uint64_t)0U);
  uint64_t o10 = scrut0.fst;
  uint64_t c00 = scrut0.snd;
  K___uint64_t_uint64_t scrut1 = Hacl_Spec_P256_Basic_addcarry(l20, h10, c00);
  uint64_t o20 = scrut1.fst;
  uint64_t c10 = scrut1.snd;
  K___uint64_t_uint64_t scrut2 = Hacl_Spec_P256_Basic_addcarry(l30, h20, c10);
  uint64_t o30 = scrut2.fst;
  uint64_t c20 = scrut2.snd;
  uint64_t c30 = h30 + c20;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut3 = { .fst = c30, .snd = { .fst = o04, .snd = o10, .thd = o20, .f3 = o30 } };
  uint64_t o03 = scrut3.snd.f3;
  uint64_t o02 = scrut3.snd.thd;
  uint64_t o01 = scrut3.snd.snd;
  uint64_t o00 = scrut3.snd.fst;
  uint64_t c02 = scrut3.fst;
  uint128_t res4 = (uint128_t)b0 * a1;
  uint64_t l01 = (uint64_t)res4;
  uint64_t h011 = (uint64_t)(res4 >> (uint32_t)64U);
  uint128_t res5 = (uint128_t)b1 * a1;
  uint64_t l11 = (uint64_t)res5;
  uint64_t h11 = (uint64_t)(res5 >> (uint32_t)64U);
  uint128_t res6 = (uint128_t)b2 * a1;
  uint64_t l21 = (uint64_t)res6;
  uint64_t h21 = (uint64_t)(res6 >> (uint32_t)64U);
  uint128_t res7 = (uint128_t)b3 * a1;
  uint64_t l31 = (uint64_t)res7;
  uint64_t h31 = (uint64_t)(res7 >> (uint32_t)64U);
  uint64_t o05 = l01;
  K___uint64_t_uint64_t scrut4 = Hacl_Spec_P256_Basic_addcarry(l11, h011, (uint64_t)0U);
  uint64_t o15 = scrut4.fst;
  uint64_t c010 = scrut4.snd;
  K___uint64_t_uint64_t scrut5 = Hacl_Spec_P256_Basic_addcarry(l21, h11, c010);
  uint64_t o21 = scrut5.fst;
  uint64_t c12 = scrut5.snd;
  K___uint64_t_uint64_t scrut6 = Hacl_Spec_P256_Basic_addcarry(l31, h21, c12);
  uint64_t o31 = scrut6.fst;
  uint64_t c22 = scrut6.snd;
  uint64_t c31 = h31 + c22;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut7 = { .fst = c31, .snd = { .fst = o05, .snd = o15, .thd = o21, .f3 = o31 } };
  uint64_t c8 = scrut7.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t out00 = scrut7.snd;
  uint64_t o06 = out00.fst;
  uint64_t o16 = out00.snd;
  uint64_t o26 = out00.thd;
  uint64_t o32 = out00.f3;
  uint64_t f300 = o01;
  uint64_t f310 = o02;
  uint64_t f320 = o03;
  uint64_t f330 = c02;
  K___uint64_t_uint64_t scrut8 = Hacl_Spec_P256_Basic_addcarry(f300, o06, (uint64_t)0U);
  uint64_t o0_ = scrut8.fst;
  uint64_t c011 = scrut8.snd;
  K___uint64_t_uint64_t scrut9 = Hacl_Spec_P256_Basic_addcarry(f310, o16, c011);
  uint64_t o1_ = scrut9.fst;
  uint64_t c13 = scrut9.snd;
  K___uint64_t_uint64_t scrut10 = Hacl_Spec_P256_Basic_addcarry(f320, o26, c13);
  uint64_t o2_ = scrut10.fst;
  uint64_t c23 = scrut10.snd;
  K___uint64_t_uint64_t scrut11 = Hacl_Spec_P256_Basic_addcarry(f330, o32, c23);
  uint64_t o3_ = scrut11.fst;
  uint64_t c32 = scrut11.snd;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  out1 = { .fst = o0_, .snd = o1_, .thd = o2_, .f3 = o3_ };
  uint64_t c40 = c8 + c32;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t scrut12 = { .fst = c40, .snd = out1 };
  uint64_t o14 = scrut12.snd.f3;
  uint64_t o13 = scrut12.snd.thd;
  uint64_t o12 = scrut12.snd.snd;
  uint64_t o11 = scrut12.snd.fst;
  uint64_t c14 = scrut12.fst;
  uint128_t res8 = (uint128_t)b0 * a2;
  uint64_t l02 = (uint64_t)res8;
  uint64_t h012 = (uint64_t)(res8 >> (uint32_t)64U);
  uint128_t res9 = (uint128_t)b1 * a2;
  uint64_t l12 = (uint64_t)res9;
  uint64_t h12 = (uint64_t)(res9 >> (uint32_t)64U);
  uint128_t res10 = (uint128_t)b2 * a2;
  uint64_t l22 = (uint64_t)res10;
  uint64_t h22 = (uint64_t)(res10 >> (uint32_t)64U);
  uint128_t res11 = (uint128_t)b3 * a2;
  uint64_t l32 = (uint64_t)res11;
  uint64_t h32 = (uint64_t)(res11 >> (uint32_t)64U);
  uint64_t o07 = l02;
  K___uint64_t_uint64_t scrut13 = Hacl_Spec_P256_Basic_addcarry(l12, h012, (uint64_t)0U);
  uint64_t o17 = scrut13.fst;
  uint64_t c012 = scrut13.snd;
  K___uint64_t_uint64_t scrut14 = Hacl_Spec_P256_Basic_addcarry(l22, h12, c012);
  uint64_t o27 = scrut14.fst;
  uint64_t c110 = scrut14.snd;
  K___uint64_t_uint64_t scrut15 = Hacl_Spec_P256_Basic_addcarry(l32, h22, c110);
  uint64_t o37 = scrut15.fst;
  uint64_t c24 = scrut15.snd;
  uint64_t c33 = h32 + c24;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut16 = { .fst = c33, .snd = { .fst = o07, .snd = o17, .thd = o27, .f3 = o37 } };
  uint64_t c9 = scrut16.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t out01 = scrut16.snd;
  uint64_t o08 = out01.fst;
  uint64_t o18 = out01.snd;
  uint64_t o28 = out01.thd;
  uint64_t o38 = out01.f3;
  uint64_t f301 = o12;
  uint64_t f311 = o13;
  uint64_t f321 = o14;
  uint64_t f331 = c14;
  K___uint64_t_uint64_t scrut17 = Hacl_Spec_P256_Basic_addcarry(f301, o08, (uint64_t)0U);
  uint64_t o0_0 = scrut17.fst;
  uint64_t c013 = scrut17.snd;
  K___uint64_t_uint64_t scrut18 = Hacl_Spec_P256_Basic_addcarry(f311, o18, c013);
  uint64_t o1_0 = scrut18.fst;
  uint64_t c111 = scrut18.snd;
  K___uint64_t_uint64_t scrut19 = Hacl_Spec_P256_Basic_addcarry(f321, o28, c111);
  uint64_t o2_0 = scrut19.fst;
  uint64_t c25 = scrut19.snd;
  K___uint64_t_uint64_t scrut20 = Hacl_Spec_P256_Basic_addcarry(f331, o38, c25);
  uint64_t o3_0 = scrut20.fst;
  uint64_t c34 = scrut20.snd;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  out2 = { .fst = o0_0, .snd = o1_0, .thd = o2_0, .f3 = o3_0 };
  uint64_t c41 = c9 + c34;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t scrut21 = { .fst = c41, .snd = out2 };
  uint64_t o25 = scrut21.snd.f3;
  uint64_t o24 = scrut21.snd.thd;
  uint64_t o23 = scrut21.snd.snd;
  uint64_t o22 = scrut21.snd.fst;
  uint64_t c26 = scrut21.fst;
  uint128_t res12 = (uint128_t)b0 * a3;
  uint64_t l03 = (uint64_t)res12;
  uint64_t h013 = (uint64_t)(res12 >> (uint32_t)64U);
  uint128_t res13 = (uint128_t)b1 * a3;
  uint64_t l13 = (uint64_t)res13;
  uint64_t h13 = (uint64_t)(res13 >> (uint32_t)64U);
  uint128_t res14 = (uint128_t)b2 * a3;
  uint64_t l23 = (uint64_t)res14;
  uint64_t h23 = (uint64_t)(res14 >> (uint32_t)64U);
  uint128_t res15 = (uint128_t)b3 * a3;
  uint64_t l33 = (uint64_t)res15;
  uint64_t h33 = (uint64_t)(res15 >> (uint32_t)64U);
  uint64_t o09 = l03;
  K___uint64_t_uint64_t scrut22 = Hacl_Spec_P256_Basic_addcarry(l13, h013, (uint64_t)0U);
  uint64_t o19 = scrut22.fst;
  uint64_t c014 = scrut22.snd;
  K___uint64_t_uint64_t scrut23 = Hacl_Spec_P256_Basic_addcarry(l23, h13, c014);
  uint64_t o29 = scrut23.fst;
  uint64_t c112 = scrut23.snd;
  K___uint64_t_uint64_t scrut24 = Hacl_Spec_P256_Basic_addcarry(l33, h23, c112);
  uint64_t o39 = scrut24.fst;
  uint64_t c210 = scrut24.snd;
  uint64_t c35 = h33 + c210;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut25 = { .fst = c35, .snd = { .fst = o09, .snd = o19, .thd = o29, .f3 = o39 } };
  uint64_t c15 = scrut25.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t out0 = scrut25.snd;
  uint64_t o010 = out0.fst;
  uint64_t o110 = out0.snd;
  uint64_t o210 = out0.thd;
  uint64_t o310 = out0.f3;
  uint64_t f30 = o23;
  uint64_t f31 = o24;
  uint64_t f32 = o25;
  uint64_t f33 = c26;
  K___uint64_t_uint64_t scrut26 = Hacl_Spec_P256_Basic_addcarry(f30, o010, (uint64_t)0U);
  uint64_t o0_1 = scrut26.fst;
  uint64_t c01 = scrut26.snd;
  K___uint64_t_uint64_t scrut27 = Hacl_Spec_P256_Basic_addcarry(f31, o110, c01);
  uint64_t o1_1 = scrut27.fst;
  uint64_t c11 = scrut27.snd;
  K___uint64_t_uint64_t scrut28 = Hacl_Spec_P256_Basic_addcarry(f32, o210, c11);
  uint64_t o2_1 = scrut28.fst;
  uint64_t c21 = scrut28.snd;
  K___uint64_t_uint64_t scrut29 = Hacl_Spec_P256_Basic_addcarry(f33, o310, c21);
  uint64_t o3_1 = scrut29.fst;
  uint64_t c36 = scrut29.snd;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  out = { .fst = o0_1, .snd = o1_1, .thd = o2_1, .f3 = o3_1 };
  uint64_t c42 = c15 + c36;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t scrut30 = { .fst = c42, .snd = out };
  uint64_t o36 = scrut30.snd.f3;
  uint64_t o35 = scrut30.snd.thd;
  uint64_t o34 = scrut30.snd.snd;
  uint64_t o33 = scrut30.snd.fst;
  uint64_t c37 = scrut30.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut31 =
    { .fst = o00, .snd = o11, .thd = o22, .f3 = o33, .f4 = o34, .f5 = o35, .f6 = o36, .f7 = c37 };
  uint64_t t_0 = scrut31.fst;
  uint64_t t_1 = scrut31.snd;
  uint64_t t_2 = scrut31.thd;
  uint64_t t_3 = scrut31.f3;
  uint64_t t_4 = scrut31.f4;
  uint64_t t_5 = scrut31.f5;
  uint64_t t_6 = scrut31.f6;
  uint64_t t_7 = scrut31.f7;
  uint64_t t1 = t_0;
  uint128_t res16 = (uint128_t)prim0 * t1;
  uint64_t l04 = (uint64_t)res16;
  uint64_t h014 = (uint64_t)(res16 >> (uint32_t)64U);
  uint128_t res17 = (uint128_t)prim1 * t1;
  uint64_t l14 = (uint64_t)res17;
  uint64_t h14 = (uint64_t)(res17 >> (uint32_t)64U);
  uint128_t res18 = (uint128_t)prim2 * t1;
  uint64_t l24 = (uint64_t)res18;
  uint64_t h24 = (uint64_t)(res18 >> (uint32_t)64U);
  uint128_t res19 = (uint128_t)prim3 * t1;
  uint64_t l34 = (uint64_t)res19;
  uint64_t h34 = (uint64_t)(res19 >> (uint32_t)64U);
  uint64_t o011 = l04;
  K___uint64_t_uint64_t scrut32 = Hacl_Spec_P256_Basic_addcarry(l14, h014, (uint64_t)0U);
  uint64_t o111 = scrut32.fst;
  uint64_t c03 = scrut32.snd;
  K___uint64_t_uint64_t scrut33 = Hacl_Spec_P256_Basic_addcarry(l24, h14, c03);
  uint64_t o211 = scrut33.fst;
  uint64_t c16 = scrut33.snd;
  K___uint64_t_uint64_t scrut34 = Hacl_Spec_P256_Basic_addcarry(l34, h24, c16);
  uint64_t o311 = scrut34.fst;
  uint64_t c27 = scrut34.snd;
  uint64_t c38 = h34 + c27;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut35 = { .fst = c38, .snd = { .fst = o011, .snd = o111, .thd = o211, .f3 = o311 } };
  uint64_t f34 = scrut35.snd.f3;
  uint64_t f20 = scrut35.snd.thd;
  uint64_t f10 = scrut35.snd.snd;
  uint64_t f00 = scrut35.snd.fst;
  uint64_t c17 = scrut35.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut36 =
    {
      .fst = f00, .snd = f10, .thd = f20, .f3 = f34, .f4 = c17, .f5 = (uint64_t)0U,
      .f6 = (uint64_t)0U, .f7 = (uint64_t)0U
    };
  uint64_t t2_0 = scrut36.fst;
  uint64_t t2_1 = scrut36.snd;
  uint64_t t2_2 = scrut36.thd;
  uint64_t t2_3 = scrut36.f3;
  uint64_t t2_4 = scrut36.f4;
  uint64_t t2_5 = scrut36.f5;
  uint64_t t2_6 = scrut36.f6;
  uint64_t t2_7 = scrut36.f7;
  K___uint64_t_uint64_t scrut37 = Hacl_Spec_P256_Basic_addcarry(t_0, t2_0, (uint64_t)0U);
  uint64_t o012 = scrut37.fst;
  uint64_t c04 = scrut37.snd;
  K___uint64_t_uint64_t scrut38 = Hacl_Spec_P256_Basic_addcarry(t_1, t2_1, c04);
  uint64_t o112 = scrut38.fst;
  uint64_t c18 = scrut38.snd;
  K___uint64_t_uint64_t scrut39 = Hacl_Spec_P256_Basic_addcarry(t_2, t2_2, c18);
  uint64_t o212 = scrut39.fst;
  uint64_t c28 = scrut39.snd;
  K___uint64_t_uint64_t scrut40 = Hacl_Spec_P256_Basic_addcarry(t_3, t2_3, c28);
  uint64_t o312 = scrut40.fst;
  uint64_t c39 = scrut40.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut41 = { .fst = c39, .snd = { .fst = o012, .snd = o112, .thd = o212, .f3 = o312 } };
  uint64_t o313 = scrut41.snd.f3;
  uint64_t o213 = scrut41.snd.thd;
  uint64_t o113 = scrut41.snd.snd;
  uint64_t o013 = scrut41.snd.fst;
  uint64_t c310 = scrut41.fst;
  K___uint64_t_uint64_t scrut42 = Hacl_Spec_P256_Basic_addcarry(t_4, t2_4, c310);
  uint64_t o40 = scrut42.fst;
  uint64_t c43 = scrut42.snd;
  K___uint64_t_uint64_t scrut43 = Hacl_Spec_P256_Basic_addcarry(t_5, t2_5, c43);
  uint64_t o50 = scrut43.fst;
  uint64_t c50 = scrut43.snd;
  K___uint64_t_uint64_t scrut44 = Hacl_Spec_P256_Basic_addcarry(t_6, t2_6, c50);
  uint64_t o60 = scrut44.fst;
  uint64_t c60 = scrut44.snd;
  K___uint64_t_uint64_t scrut45 = Hacl_Spec_P256_Basic_addcarry(t_7, t2_7, c60);
  uint64_t o70 = scrut45.fst;
  uint64_t c70 = scrut45.snd;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut46 =
    {
      .fst = c70, .snd = o013, .thd = o113, .f3 = o213, .f4 = o313, .f5 = o40, .f6 = o50, .f7 = o60,
      .f8 = o70
    };
  uint64_t r00 = scrut46.snd;
  uint64_t r10 = scrut46.thd;
  uint64_t r20 = scrut46.f3;
  uint64_t r30 = scrut46.f4;
  uint64_t r40 = scrut46.f5;
  uint64_t r50 = scrut46.f6;
  uint64_t r60 = scrut46.f7;
  uint64_t r70 = scrut46.f8;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut47 =
    { .fst = r00, .snd = r10, .thd = r20, .f3 = r30, .f4 = r40, .f5 = r50, .f6 = r60, .f7 = r70 };
  uint64_t t3_1 = scrut47.snd;
  uint64_t t3_2 = scrut47.thd;
  uint64_t t3_3 = scrut47.f3;
  uint64_t t3_4 = scrut47.f4;
  uint64_t t3_5 = scrut47.f5;
  uint64_t t3_6 = scrut47.f6;
  uint64_t t3_7 = scrut47.f7;
  uint64_t st0 = t3_1;
  uint64_t st1 = t3_2;
  uint64_t st2 = t3_3;
  uint64_t st3 = t3_4;
  uint64_t st4 = t3_5;
  uint64_t st5 = t3_6;
  uint64_t st6 = t3_7;
  uint64_t st7 = (uint64_t)0U;
  uint64_t t110 = st0;
  uint128_t res20 = (uint128_t)prim0 * t110;
  uint64_t l05 = (uint64_t)res20;
  uint64_t h015 = (uint64_t)(res20 >> (uint32_t)64U);
  uint128_t res21 = (uint128_t)prim1 * t110;
  uint64_t l15 = (uint64_t)res21;
  uint64_t h15 = (uint64_t)(res21 >> (uint32_t)64U);
  uint128_t res22 = (uint128_t)prim2 * t110;
  uint64_t l25 = (uint64_t)res22;
  uint64_t h25 = (uint64_t)(res22 >> (uint32_t)64U);
  uint128_t res23 = (uint128_t)prim3 * t110;
  uint64_t l35 = (uint64_t)res23;
  uint64_t h35 = (uint64_t)(res23 >> (uint32_t)64U);
  uint64_t o014 = l05;
  K___uint64_t_uint64_t scrut48 = Hacl_Spec_P256_Basic_addcarry(l15, h015, (uint64_t)0U);
  uint64_t o114 = scrut48.fst;
  uint64_t c05 = scrut48.snd;
  K___uint64_t_uint64_t scrut49 = Hacl_Spec_P256_Basic_addcarry(l25, h15, c05);
  uint64_t o214 = scrut49.fst;
  uint64_t c19 = scrut49.snd;
  K___uint64_t_uint64_t scrut50 = Hacl_Spec_P256_Basic_addcarry(l35, h25, c19);
  uint64_t o314 = scrut50.fst;
  uint64_t c29 = scrut50.snd;
  uint64_t c311 = h35 + c29;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut51 = { .fst = c311, .snd = { .fst = o014, .snd = o114, .thd = o214, .f3 = o314 } };
  uint64_t f35 = scrut51.snd.f3;
  uint64_t f21 = scrut51.snd.thd;
  uint64_t f11 = scrut51.snd.snd;
  uint64_t f01 = scrut51.snd.fst;
  uint64_t c44 = scrut51.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut52 =
    {
      .fst = f01, .snd = f11, .thd = f21, .f3 = f35, .f4 = c44, .f5 = (uint64_t)0U,
      .f6 = (uint64_t)0U, .f7 = (uint64_t)0U
    };
  uint64_t t2_010 = scrut52.fst;
  uint64_t t2_110 = scrut52.snd;
  uint64_t t2_210 = scrut52.thd;
  uint64_t t2_310 = scrut52.f3;
  uint64_t t2_410 = scrut52.f4;
  uint64_t t2_510 = scrut52.f5;
  uint64_t t2_610 = scrut52.f6;
  uint64_t t2_710 = scrut52.f7;
  K___uint64_t_uint64_t scrut53 = Hacl_Spec_P256_Basic_addcarry(st0, t2_010, (uint64_t)0U);
  uint64_t o015 = scrut53.fst;
  uint64_t c06 = scrut53.snd;
  K___uint64_t_uint64_t scrut54 = Hacl_Spec_P256_Basic_addcarry(st1, t2_110, c06);
  uint64_t o115 = scrut54.fst;
  uint64_t c113 = scrut54.snd;
  K___uint64_t_uint64_t scrut55 = Hacl_Spec_P256_Basic_addcarry(st2, t2_210, c113);
  uint64_t o215 = scrut55.fst;
  uint64_t c211 = scrut55.snd;
  K___uint64_t_uint64_t scrut56 = Hacl_Spec_P256_Basic_addcarry(st3, t2_310, c211);
  uint64_t o315 = scrut56.fst;
  uint64_t c312 = scrut56.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut57 = { .fst = c312, .snd = { .fst = o015, .snd = o115, .thd = o215, .f3 = o315 } };
  uint64_t o316 = scrut57.snd.f3;
  uint64_t o216 = scrut57.snd.thd;
  uint64_t o116 = scrut57.snd.snd;
  uint64_t o016 = scrut57.snd.fst;
  uint64_t c313 = scrut57.fst;
  K___uint64_t_uint64_t scrut58 = Hacl_Spec_P256_Basic_addcarry(st4, t2_410, c313);
  uint64_t o41 = scrut58.fst;
  uint64_t c45 = scrut58.snd;
  K___uint64_t_uint64_t scrut59 = Hacl_Spec_P256_Basic_addcarry(st5, t2_510, c45);
  uint64_t o51 = scrut59.fst;
  uint64_t c51 = scrut59.snd;
  K___uint64_t_uint64_t scrut60 = Hacl_Spec_P256_Basic_addcarry(st6, t2_610, c51);
  uint64_t o61 = scrut60.fst;
  uint64_t c61 = scrut60.snd;
  K___uint64_t_uint64_t scrut61 = Hacl_Spec_P256_Basic_addcarry(st7, t2_710, c61);
  uint64_t o71 = scrut61.fst;
  uint64_t c71 = scrut61.snd;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut62 =
    {
      .fst = c71, .snd = o016, .thd = o116, .f3 = o216, .f4 = o316, .f5 = o41, .f6 = o51, .f7 = o61,
      .f8 = o71
    };
  uint64_t r01 = scrut62.snd;
  uint64_t r11 = scrut62.thd;
  uint64_t r21 = scrut62.f3;
  uint64_t r31 = scrut62.f4;
  uint64_t r41 = scrut62.f5;
  uint64_t r51 = scrut62.f6;
  uint64_t r61 = scrut62.f7;
  uint64_t r71 = scrut62.f8;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut63 =
    { .fst = r01, .snd = r11, .thd = r21, .f3 = r31, .f4 = r41, .f5 = r51, .f6 = r61, .f7 = r71 };
  uint64_t t3_110 = scrut63.snd;
  uint64_t t3_210 = scrut63.thd;
  uint64_t t3_310 = scrut63.f3;
  uint64_t t3_410 = scrut63.f4;
  uint64_t t3_510 = scrut63.f5;
  uint64_t t3_610 = scrut63.f6;
  uint64_t t3_710 = scrut63.f7;
  uint64_t r_00 = t3_110;
  uint64_t r_10 = t3_210;
  uint64_t r_20 = t3_310;
  uint64_t r_30 = t3_410;
  uint64_t r_40 = t3_510;
  uint64_t r_50 = t3_610;
  uint64_t r_60 = t3_710;
  uint64_t r_70 = (uint64_t)0U;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut64 =
    {
      .fst = r_00, .snd = r_10, .thd = r_20, .f3 = r_30, .f4 = r_40, .f5 = r_50, .f6 = r_60,
      .f7 = r_70
    };
  uint64_t st10 = scrut64.fst;
  uint64_t st11 = scrut64.snd;
  uint64_t st12 = scrut64.thd;
  uint64_t st13 = scrut64.f3;
  uint64_t st14 = scrut64.f4;
  uint64_t st15 = scrut64.f5;
  uint64_t st16 = scrut64.f6;
  uint64_t st17 = scrut64.f7;
  uint64_t t111 = st10;
  uint128_t res24 = (uint128_t)prim0 * t111;
  uint64_t l06 = (uint64_t)res24;
  uint64_t h016 = (uint64_t)(res24 >> (uint32_t)64U);
  uint128_t res25 = (uint128_t)prim1 * t111;
  uint64_t l16 = (uint64_t)res25;
  uint64_t h16 = (uint64_t)(res25 >> (uint32_t)64U);
  uint128_t res26 = (uint128_t)prim2 * t111;
  uint64_t l26 = (uint64_t)res26;
  uint64_t h26 = (uint64_t)(res26 >> (uint32_t)64U);
  uint128_t res27 = (uint128_t)prim3 * t111;
  uint64_t l36 = (uint64_t)res27;
  uint64_t h36 = (uint64_t)(res27 >> (uint32_t)64U);
  uint64_t o017 = l06;
  K___uint64_t_uint64_t scrut65 = Hacl_Spec_P256_Basic_addcarry(l16, h016, (uint64_t)0U);
  uint64_t o117 = scrut65.fst;
  uint64_t c07 = scrut65.snd;
  K___uint64_t_uint64_t scrut66 = Hacl_Spec_P256_Basic_addcarry(l26, h16, c07);
  uint64_t o217 = scrut66.fst;
  uint64_t c114 = scrut66.snd;
  K___uint64_t_uint64_t scrut67 = Hacl_Spec_P256_Basic_addcarry(l36, h26, c114);
  uint64_t o317 = scrut67.fst;
  uint64_t c212 = scrut67.snd;
  uint64_t c314 = h36 + c212;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut68 = { .fst = c314, .snd = { .fst = o017, .snd = o117, .thd = o217, .f3 = o317 } };
  uint64_t f36 = scrut68.snd.f3;
  uint64_t f22 = scrut68.snd.thd;
  uint64_t f12 = scrut68.snd.snd;
  uint64_t f02 = scrut68.snd.fst;
  uint64_t c46 = scrut68.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut69 =
    {
      .fst = f02, .snd = f12, .thd = f22, .f3 = f36, .f4 = c46, .f5 = (uint64_t)0U,
      .f6 = (uint64_t)0U, .f7 = (uint64_t)0U
    };
  uint64_t t2_011 = scrut69.fst;
  uint64_t t2_111 = scrut69.snd;
  uint64_t t2_211 = scrut69.thd;
  uint64_t t2_311 = scrut69.f3;
  uint64_t t2_411 = scrut69.f4;
  uint64_t t2_511 = scrut69.f5;
  uint64_t t2_611 = scrut69.f6;
  uint64_t t2_711 = scrut69.f7;
  K___uint64_t_uint64_t scrut70 = Hacl_Spec_P256_Basic_addcarry(st10, t2_011, (uint64_t)0U);
  uint64_t o018 = scrut70.fst;
  uint64_t c08 = scrut70.snd;
  K___uint64_t_uint64_t scrut71 = Hacl_Spec_P256_Basic_addcarry(st11, t2_111, c08);
  uint64_t o118 = scrut71.fst;
  uint64_t c115 = scrut71.snd;
  K___uint64_t_uint64_t scrut72 = Hacl_Spec_P256_Basic_addcarry(st12, t2_211, c115);
  uint64_t o218 = scrut72.fst;
  uint64_t c213 = scrut72.snd;
  K___uint64_t_uint64_t scrut73 = Hacl_Spec_P256_Basic_addcarry(st13, t2_311, c213);
  uint64_t o318 = scrut73.fst;
  uint64_t c315 = scrut73.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut74 = { .fst = c315, .snd = { .fst = o018, .snd = o118, .thd = o218, .f3 = o318 } };
  uint64_t o319 = scrut74.snd.f3;
  uint64_t o219 = scrut74.snd.thd;
  uint64_t o119 = scrut74.snd.snd;
  uint64_t o019 = scrut74.snd.fst;
  uint64_t c316 = scrut74.fst;
  K___uint64_t_uint64_t scrut75 = Hacl_Spec_P256_Basic_addcarry(st14, t2_411, c316);
  uint64_t o42 = scrut75.fst;
  uint64_t c47 = scrut75.snd;
  K___uint64_t_uint64_t scrut76 = Hacl_Spec_P256_Basic_addcarry(st15, t2_511, c47);
  uint64_t o52 = scrut76.fst;
  uint64_t c52 = scrut76.snd;
  K___uint64_t_uint64_t scrut77 = Hacl_Spec_P256_Basic_addcarry(st16, t2_611, c52);
  uint64_t o62 = scrut77.fst;
  uint64_t c62 = scrut77.snd;
  K___uint64_t_uint64_t scrut78 = Hacl_Spec_P256_Basic_addcarry(st17, t2_711, c62);
  uint64_t o72 = scrut78.fst;
  uint64_t c72 = scrut78.snd;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut79 =
    {
      .fst = c72, .snd = o019, .thd = o119, .f3 = o219, .f4 = o319, .f5 = o42, .f6 = o52, .f7 = o62,
      .f8 = o72
    };
  uint64_t r02 = scrut79.snd;
  uint64_t r12 = scrut79.thd;
  uint64_t r22 = scrut79.f3;
  uint64_t r32 = scrut79.f4;
  uint64_t r42 = scrut79.f5;
  uint64_t r52 = scrut79.f6;
  uint64_t r62 = scrut79.f7;
  uint64_t r72 = scrut79.f8;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut80 =
    { .fst = r02, .snd = r12, .thd = r22, .f3 = r32, .f4 = r42, .f5 = r52, .f6 = r62, .f7 = r72 };
  uint64_t t3_111 = scrut80.snd;
  uint64_t t3_211 = scrut80.thd;
  uint64_t t3_311 = scrut80.f3;
  uint64_t t3_411 = scrut80.f4;
  uint64_t t3_511 = scrut80.f5;
  uint64_t t3_611 = scrut80.f6;
  uint64_t t3_711 = scrut80.f7;
  uint64_t r_01 = t3_111;
  uint64_t r_11 = t3_211;
  uint64_t r_21 = t3_311;
  uint64_t r_31 = t3_411;
  uint64_t r_41 = t3_511;
  uint64_t r_51 = t3_611;
  uint64_t r_61 = t3_711;
  uint64_t r_71 = (uint64_t)0U;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut81 =
    {
      .fst = r_01, .snd = r_11, .thd = r_21, .f3 = r_31, .f4 = r_41, .f5 = r_51, .f6 = r_61,
      .f7 = r_71
    };
  uint64_t st20 = scrut81.fst;
  uint64_t st21 = scrut81.snd;
  uint64_t st22 = scrut81.thd;
  uint64_t st23 = scrut81.f3;
  uint64_t st24 = scrut81.f4;
  uint64_t st25 = scrut81.f5;
  uint64_t st26 = scrut81.f6;
  uint64_t st27 = scrut81.f7;
  uint64_t t11 = st20;
  uint128_t res28 = (uint128_t)prim0 * t11;
  uint64_t l0 = (uint64_t)res28;
  uint64_t h01 = (uint64_t)(res28 >> (uint32_t)64U);
  uint128_t res29 = (uint128_t)prim1 * t11;
  uint64_t l1 = (uint64_t)res29;
  uint64_t h1 = (uint64_t)(res29 >> (uint32_t)64U);
  uint128_t res30 = (uint128_t)prim2 * t11;
  uint64_t l2 = (uint64_t)res30;
  uint64_t h2 = (uint64_t)(res30 >> (uint32_t)64U);
  uint128_t res = (uint128_t)prim3 * t11;
  uint64_t l3 = (uint64_t)res;
  uint64_t h3 = (uint64_t)(res >> (uint32_t)64U);
  uint64_t o020 = l0;
  K___uint64_t_uint64_t scrut82 = Hacl_Spec_P256_Basic_addcarry(l1, h01, (uint64_t)0U);
  uint64_t o120 = scrut82.fst;
  uint64_t c09 = scrut82.snd;
  K___uint64_t_uint64_t scrut83 = Hacl_Spec_P256_Basic_addcarry(l2, h1, c09);
  uint64_t o220 = scrut83.fst;
  uint64_t c116 = scrut83.snd;
  K___uint64_t_uint64_t scrut84 = Hacl_Spec_P256_Basic_addcarry(l3, h2, c116);
  uint64_t o320 = scrut84.fst;
  uint64_t c214 = scrut84.snd;
  uint64_t c317 = h3 + c214;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut85 = { .fst = c317, .snd = { .fst = o020, .snd = o120, .thd = o220, .f3 = o320 } };
  uint64_t f3 = scrut85.snd.f3;
  uint64_t f2 = scrut85.snd.thd;
  uint64_t f1 = scrut85.snd.snd;
  uint64_t f0 = scrut85.snd.fst;
  uint64_t c = scrut85.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut86 =
    {
      .fst = f0, .snd = f1, .thd = f2, .f3 = f3, .f4 = c, .f5 = (uint64_t)0U, .f6 = (uint64_t)0U,
      .f7 = (uint64_t)0U
    };
  uint64_t t2_01 = scrut86.fst;
  uint64_t t2_11 = scrut86.snd;
  uint64_t t2_21 = scrut86.thd;
  uint64_t t2_31 = scrut86.f3;
  uint64_t t2_41 = scrut86.f4;
  uint64_t t2_51 = scrut86.f5;
  uint64_t t2_61 = scrut86.f6;
  uint64_t t2_71 = scrut86.f7;
  K___uint64_t_uint64_t scrut = Hacl_Spec_P256_Basic_addcarry(st20, t2_01, (uint64_t)0U);
  uint64_t o021 = scrut.fst;
  uint64_t c0 = scrut.snd;
  K___uint64_t_uint64_t scrut87 = Hacl_Spec_P256_Basic_addcarry(st21, t2_11, c0);
  uint64_t o121 = scrut87.fst;
  uint64_t c1 = scrut87.snd;
  K___uint64_t_uint64_t scrut88 = Hacl_Spec_P256_Basic_addcarry(st22, t2_21, c1);
  uint64_t o221 = scrut88.fst;
  uint64_t c2 = scrut88.snd;
  K___uint64_t_uint64_t scrut89 = Hacl_Spec_P256_Basic_addcarry(st23, t2_31, c2);
  uint64_t o321 = scrut89.fst;
  uint64_t c318 = scrut89.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut90 = { .fst = c318, .snd = { .fst = o021, .snd = o121, .thd = o221, .f3 = o321 } };
  uint64_t o3 = scrut90.snd.f3;
  uint64_t o2 = scrut90.snd.thd;
  uint64_t o1 = scrut90.snd.snd;
  uint64_t o0 = scrut90.snd.fst;
  uint64_t c3 = scrut90.fst;
  K___uint64_t_uint64_t scrut91 = Hacl_Spec_P256_Basic_addcarry(st24, t2_41, c3);
  uint64_t o4 = scrut91.fst;
  uint64_t c4 = scrut91.snd;
  K___uint64_t_uint64_t scrut92 = Hacl_Spec_P256_Basic_addcarry(st25, t2_51, c4);
  uint64_t o5 = scrut92.fst;
  uint64_t c5 = scrut92.snd;
  K___uint64_t_uint64_t scrut93 = Hacl_Spec_P256_Basic_addcarry(st26, t2_61, c5);
  uint64_t o6 = scrut93.fst;
  uint64_t c6 = scrut93.snd;
  K___uint64_t_uint64_t scrut94 = Hacl_Spec_P256_Basic_addcarry(st27, t2_71, c6);
  uint64_t o7 = scrut94.fst;
  uint64_t c7 = scrut94.snd;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut95 =
    { .fst = c7, .snd = o0, .thd = o1, .f3 = o2, .f4 = o3, .f5 = o4, .f6 = o5, .f7 = o6, .f8 = o7 };
  uint64_t r03 = scrut95.snd;
  uint64_t r13 = scrut95.thd;
  uint64_t r23 = scrut95.f3;
  uint64_t r33 = scrut95.f4;
  uint64_t r4 = scrut95.f5;
  uint64_t r5 = scrut95.f6;
  uint64_t r6 = scrut95.f7;
  uint64_t r7 = scrut95.f8;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut96 =
    { .fst = r03, .snd = r13, .thd = r23, .f3 = r33, .f4 = r4, .f5 = r5, .f6 = r6, .f7 = r7 };
  uint64_t t3_11 = scrut96.snd;
  uint64_t t3_21 = scrut96.thd;
  uint64_t t3_31 = scrut96.f3;
  uint64_t t3_41 = scrut96.f4;
  uint64_t t3_51 = scrut96.f5;
  uint64_t t3_61 = scrut96.f6;
  uint64_t t3_71 = scrut96.f7;
  uint64_t r_0 = t3_11;
  uint64_t r_1 = t3_21;
  uint64_t r_2 = t3_31;
  uint64_t r_3 = t3_41;
  uint64_t r_4 = t3_51;
  uint64_t r_5 = t3_61;
  uint64_t r_6 = t3_71;
  uint64_t r_7 = (uint64_t)0U;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut97 =
    { .fst = r_0, .snd = r_1, .thd = r_2, .f3 = r_3, .f4 = r_4, .f5 = r_5, .f6 = r_6, .f7 = r_7 };
  uint64_t st30 = scrut97.fst;
  uint64_t st31 = scrut97.snd;
  uint64_t st32 = scrut97.thd;
  uint64_t st33 = scrut97.f3;
  uint64_t st34 = scrut97.f4;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut98 =
    Hacl_Spec_P256_Core_reduction_prime_2prime_with_carry(st34,
      (
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = st30,
          .snd = st31,
          .thd = st32,
          .f3 = st33
        }
      ));
  uint64_t r0 = scrut98.fst;
  uint64_t r1 = scrut98.snd;
  uint64_t r2 = scrut98.thd;
  uint64_t r3 = scrut98.f3;
  r[0U] = r0;
  r[1U] = r1;
  r[2U] = r2;
  r[3U] = r3;
}

static void Hacl_Spec_P256_MontgomeryMultiplication_fsquarePowN(uint32_t n1, uint64_t *a)
{
  for (uint32_t i = (uint32_t)0U; i < n1; i = i + (uint32_t)1U)
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(a, a, a);
}

static void
Hacl_Spec_P256_MontgomeryMultiplication_fsquarePowNminusOne(
  uint32_t n1,
  uint64_t *a,
  uint64_t *b
)
{
  b[0U] = (uint64_t)1U;
  b[1U] = (uint64_t)18446744069414584320U;
  b[2U] = (uint64_t)18446744073709551615U;
  b[3U] = (uint64_t)4294967294U;
  for (uint32_t i = (uint32_t)0U; i < n1; i = i + (uint32_t)1U)
  {
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(b, a, b);
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(a, a, a);
  }
}

static void
Hacl_Spec_P256_MontgomeryMultiplication_exponent(
  uint64_t *a,
  uint64_t *result,
  uint64_t *tempBuffer
)
{
  uint64_t *buffer_norm_1 = tempBuffer;
  uint64_t *buffer_result1 = tempBuffer + (uint32_t)4U;
  uint64_t *buffer_result2 = tempBuffer + (uint32_t)8U;
  uint64_t *buffer_norm_3 = tempBuffer + (uint32_t)12U;
  uint64_t *buffer_result3 = tempBuffer + (uint32_t)16U;
  memcpy(buffer_norm_1, a, (uint32_t)4U * sizeof a[0U]);
  uint64_t *buffer_a = buffer_norm_1;
  uint64_t *buffer_b0 = buffer_norm_1 + (uint32_t)4U;
  Hacl_Spec_P256_MontgomeryMultiplication_fsquarePowNminusOne((uint32_t)32U,
    buffer_a,
    buffer_b0);
  Hacl_Spec_P256_MontgomeryMultiplication_fsquarePowN((uint32_t)224U, buffer_b0);
  memcpy(buffer_result2, a, (uint32_t)4U * sizeof a[0U]);
  Hacl_Spec_P256_MontgomeryMultiplication_fsquarePowN((uint32_t)192U, buffer_result2);
  memcpy(buffer_norm_3, a, (uint32_t)4U * sizeof a[0U]);
  uint64_t *buffer_a0 = buffer_norm_3;
  uint64_t *buffer_b = buffer_norm_3 + (uint32_t)4U;
  Hacl_Spec_P256_MontgomeryMultiplication_fsquarePowNminusOne((uint32_t)94U,
    buffer_a0,
    buffer_b);
  Hacl_Spec_P256_MontgomeryMultiplication_fsquarePowN((uint32_t)2U, buffer_b);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(buffer_result1,
    buffer_result2,
    buffer_result1);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(buffer_result1,
    buffer_result3,
    buffer_result1);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(buffer_result1,
    a,
    buffer_result1);
  memcpy(result, buffer_result1, (uint32_t)4U * sizeof buffer_result1[0U]);
}

uint64_t
Hacl_Impl_LowLevel_prime256_buffer[4U] =
  {
    (uint64_t)0xffffffffffffffffU,
    (uint64_t)0xffffffffU,
    (uint64_t)0U,
    (uint64_t)0xffffffff00000001U
  };

static uint64_t
Hacl_Impl_LowLevel_add_carry(uint64_t cin, uint64_t x, uint64_t y, uint64_t *result1)
{
  uint64_t res1 = x + cin;
  uint64_t c;
  if (res1 < cin)
    c = (uint64_t)1U;
  else
    c = (uint64_t)0U;
  uint64_t res = res1 + y;
  uint64_t c1;
  if (res < res1)
    c1 = c + (uint64_t)1U;
  else
    c1 = c;
  result1[0U] = res;
  return c1;
}

uint64_t Hacl_Impl_LowLevel_sub_borrow(uint64_t cin, uint64_t x, uint64_t y, uint64_t *result1)
{
  uint64_t res = x - y - cin;
  uint64_t c;
  if (cin == (uint64_t)1U)
    if (x <= y)
      c = (uint64_t)1U;
    else
      c = (uint64_t)0U;
  else if (x < y)
    c = (uint64_t)1U;
  else
    c = (uint64_t)0U;
  result1[0U] = res;
  return c;
}

uint64_t Hacl_Impl_LowLevel_sub4_il(uint64_t *x, uint64_t *y, uint64_t *result)
{
  uint64_t *r0 = result;
  uint64_t *r1 = result + (uint32_t)1U;
  uint64_t *r2 = result + (uint32_t)2U;
  uint64_t *r3 = result + (uint32_t)3U;
  uint64_t cc = Hacl_Impl_LowLevel_sub_borrow((uint64_t)0U, x[0U], y[0U], r0);
  uint64_t cc1 = Hacl_Impl_LowLevel_sub_borrow(cc, x[1U], y[1U], r1);
  uint64_t cc2 = Hacl_Impl_LowLevel_sub_borrow(cc1, x[2U], y[2U], r2);
  uint64_t cc3 = Hacl_Impl_LowLevel_sub_borrow(cc2, x[3U], y[3U], r3);
  return cc3;
}

static uint64_t Hacl_Impl_LowLevel_sub4(uint64_t *x, uint64_t *y, uint64_t *result)
{
  uint64_t *r0 = result;
  uint64_t *r1 = result + (uint32_t)1U;
  uint64_t *r2 = result + (uint32_t)2U;
  uint64_t *r3 = result + (uint32_t)3U;
  uint64_t cc = Hacl_Impl_LowLevel_sub_borrow((uint64_t)0U, x[0U], y[0U], r0);
  uint64_t cc1 = Hacl_Impl_LowLevel_sub_borrow(cc, x[1U], y[1U], r1);
  uint64_t cc2 = Hacl_Impl_LowLevel_sub_borrow(cc1, x[2U], y[2U], r2);
  uint64_t cc3 = Hacl_Impl_LowLevel_sub_borrow(cc2, x[3U], y[3U], r3);
  return cc3;
}

void Hacl_Impl_LowLevel_cmovznz4(uint64_t cin, uint64_t *x, uint64_t *y, uint64_t *r)
{
  uint64_t mask = ~FStar_UInt64_eq_mask(cin, (uint64_t)0U);
  uint64_t r0 = y[0U] & mask | x[0U] & ~mask;
  uint64_t r1 = y[1U] & mask | x[1U] & ~mask;
  uint64_t r2 = y[2U] & mask | x[2U] & ~mask;
  uint64_t r3 = y[3U] & mask | x[3U] & ~mask;
  r[0U] = r0;
  r[1U] = r1;
  r[2U] = r2;
  r[3U] = r3;
}

static void Hacl_Impl_LowLevel_reduction_prime_2prime_impl(uint64_t *x, uint64_t *result)
{
  uint64_t tempBuffer[4U] = { 0U };
  uint64_t c = Hacl_Impl_LowLevel_sub4_il(x, Hacl_Impl_LowLevel_prime256_buffer, tempBuffer);
  Hacl_Impl_LowLevel_cmovznz4(c, tempBuffer, x, result);
}

static void Hacl_Impl_LowLevel_shift_256_impl(uint64_t *i, uint64_t *o)
{
  o[0U] = (uint64_t)0U;
  o[1U] = (uint64_t)0U;
  o[2U] = (uint64_t)0U;
  o[3U] = (uint64_t)0U;
  o[4U] = i[0U];
  o[5U] = i[1U];
  o[6U] = i[2U];
  o[7U] = i[3U];
}

static void Hacl_Impl_LowLevel_p256_add(uint64_t *arg1, uint64_t *arg2, uint64_t *out)
{
  uint64_t *r0 = out;
  uint64_t *r1 = out + (uint32_t)1U;
  uint64_t *r2 = out + (uint32_t)2U;
  uint64_t *r3 = out + (uint32_t)3U;
  uint64_t cc = Hacl_Impl_LowLevel_add_carry((uint64_t)0U, arg1[0U], arg2[0U], r0);
  uint64_t cc1 = Hacl_Impl_LowLevel_add_carry(cc, arg1[1U], arg2[1U], r1);
  uint64_t cc2 = Hacl_Impl_LowLevel_add_carry(cc1, arg1[2U], arg2[2U], r2);
  uint64_t cc3 = Hacl_Impl_LowLevel_add_carry(cc2, arg1[3U], arg2[3U], r3);
  uint64_t t = cc3;
  uint64_t tempBuffer[4U] = { 0U };
  uint64_t tempBufferForSubborrow = (uint64_t)0U;
  uint64_t c = Hacl_Impl_LowLevel_sub4_il(out, Hacl_Impl_LowLevel_prime256_buffer, tempBuffer);
  uint64_t carry = Hacl_Impl_LowLevel_sub_borrow(c, t, (uint64_t)0U, &tempBufferForSubborrow);
  Hacl_Impl_LowLevel_cmovznz4(carry, tempBuffer, out, out);
}

static void Hacl_Impl_LowLevel_p256_double(uint64_t *arg1, uint64_t *out)
{
  uint64_t *r0 = out;
  uint64_t *r1 = out + (uint32_t)1U;
  uint64_t *r2 = out + (uint32_t)2U;
  uint64_t *r3 = out + (uint32_t)3U;
  uint64_t cc = Hacl_Impl_LowLevel_add_carry((uint64_t)0U, arg1[0U], arg1[0U], r0);
  uint64_t cc1 = Hacl_Impl_LowLevel_add_carry(cc, arg1[1U], arg1[1U], r1);
  uint64_t cc2 = Hacl_Impl_LowLevel_add_carry(cc1, arg1[2U], arg1[2U], r2);
  uint64_t cc3 = Hacl_Impl_LowLevel_add_carry(cc2, arg1[3U], arg1[3U], r3);
  uint64_t t = cc3;
  uint64_t tempBuffer[4U] = { 0U };
  uint64_t tempBufferForSubborrow = (uint64_t)0U;
  uint64_t c = Hacl_Impl_LowLevel_sub4_il(out, Hacl_Impl_LowLevel_prime256_buffer, tempBuffer);
  uint64_t carry = Hacl_Impl_LowLevel_sub_borrow(c, t, (uint64_t)0U, &tempBufferForSubborrow);
  Hacl_Impl_LowLevel_cmovznz4(carry, tempBuffer, out, out);
}

static void Hacl_Impl_LowLevel_p256_sub(uint64_t *arg1, uint64_t *arg2, uint64_t *out)
{
  uint64_t t = Hacl_Impl_LowLevel_sub4(arg1, arg2, out);
  uint64_t t0 = (uint64_t)0U - t;
  uint64_t t1 = (uint64_t)0U - t >> (uint32_t)32U;
  uint64_t t2 = (uint64_t)0U;
  uint64_t t3 = t - (t << (uint32_t)32U);
  uint64_t *r0 = out;
  uint64_t *r1 = out + (uint32_t)1U;
  uint64_t *r2 = out + (uint32_t)2U;
  uint64_t *r3 = out + (uint32_t)3U;
  uint64_t cc0 = Hacl_Impl_LowLevel_add_carry((uint64_t)0U, out[0U], t0, r0);
  uint64_t cc1 = Hacl_Impl_LowLevel_add_carry(cc0, out[1U], t1, r1);
  uint64_t cc = Hacl_Impl_LowLevel_add_carry(cc1, out[2U], t2, r2);
  uint64_t cc2 = Hacl_Impl_LowLevel_add_carry(cc, out[3U], t3, r3);
  uint64_t c = cc2;
}

static uint64_t Hacl_Spec_P256_SolinasReduction_store_high_low_u(uint32_t high, uint32_t low)
{
  uint64_t as_uint64_high = (uint64_t)high;
  uint64_t as_uint64_high1 = as_uint64_high << (uint32_t)32U;
  uint64_t as_uint64_low = (uint64_t)low;
  return as_uint64_low ^ as_uint64_high1;
}

static void
Hacl_Impl_SolinasReduction_upl_zer_buffer(
  uint32_t c0,
  uint32_t c1,
  uint32_t c2,
  uint32_t c3,
  uint32_t c4,
  uint32_t c5,
  uint32_t c6,
  uint32_t c7,
  uint64_t *temp,
  uint64_t *o
)
{
  uint64_t b0 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c1, c0);
  uint64_t b1 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c3, c2);
  uint64_t b2 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c5, c4);
  uint64_t b3 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c7, c6);
  temp[0U] = b0;
  temp[1U] = b1;
  temp[2U] = b2;
  temp[3U] = b3;
  Hacl_Impl_LowLevel_reduction_prime_2prime_impl(temp, o);
}

static void
Hacl_Impl_SolinasReduction_upl_fir_buffer(
  uint32_t c11,
  uint32_t c12,
  uint32_t c13,
  uint32_t c14,
  uint32_t c15,
  uint64_t *temp,
  uint64_t *o
)
{
  uint64_t b0 = (uint64_t)0U;
  uint64_t b1 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c11, (uint32_t)0U);
  uint64_t b2 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c13, c12);
  uint64_t b3 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c15, c14);
  temp[0U] = b0;
  temp[1U] = b1;
  temp[2U] = b2;
  temp[3U] = b3;
  Hacl_Impl_LowLevel_reduction_prime_2prime_impl(temp, o);
}

static void
Hacl_Impl_SolinasReduction_upl_sec_buffer(
  uint32_t c12,
  uint32_t c13,
  uint32_t c14,
  uint32_t c15,
  uint64_t *temp,
  uint64_t *o
)
{
  uint64_t b0 = (uint64_t)0U;
  uint64_t b1 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c12, (uint32_t)0U);
  uint64_t b2 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c14, c13);
  uint64_t b3 = Hacl_Spec_P256_SolinasReduction_store_high_low_u((uint32_t)0U, c15);
  o[0U] = b0;
  o[1U] = b1;
  o[2U] = b2;
  o[3U] = b3;
}

static void
Hacl_Impl_SolinasReduction_upl_thi_buffer(
  uint32_t c8,
  uint32_t c9,
  uint32_t c10,
  uint32_t c14,
  uint32_t c15,
  uint64_t *temp,
  uint64_t *o
)
{
  uint64_t b0 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c9, c8);
  uint64_t b1 = Hacl_Spec_P256_SolinasReduction_store_high_low_u((uint32_t)0U, c10);
  uint64_t b2 = (uint64_t)0U;
  uint64_t b3 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c15, c14);
  temp[0U] = b0;
  temp[1U] = b1;
  temp[2U] = b2;
  temp[3U] = b3;
  Hacl_Impl_LowLevel_reduction_prime_2prime_impl(temp, o);
}

static void
Hacl_Impl_SolinasReduction_upl_for_buffer(
  uint32_t c8,
  uint32_t c9,
  uint32_t c10,
  uint32_t c11,
  uint32_t c13,
  uint32_t c14,
  uint32_t c15,
  uint64_t *temp,
  uint64_t *o
)
{
  uint64_t b0 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c10, c9);
  uint64_t b1 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c13, c11);
  uint64_t b2 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c15, c14);
  uint64_t b3 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c8, c13);
  temp[0U] = b0;
  temp[1U] = b1;
  temp[2U] = b2;
  temp[3U] = b3;
  Hacl_Impl_LowLevel_reduction_prime_2prime_impl(temp, o);
}

static void
Hacl_Impl_SolinasReduction_upl_fif_buffer(
  uint32_t c8,
  uint32_t c10,
  uint32_t c11,
  uint32_t c12,
  uint32_t c13,
  uint64_t *temp,
  uint64_t *o
)
{
  uint64_t b0 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c12, c11);
  uint64_t b1 = Hacl_Spec_P256_SolinasReduction_store_high_low_u((uint32_t)0U, c13);
  uint64_t b2 = (uint64_t)0U;
  uint64_t b3 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c10, c8);
  temp[0U] = b0;
  temp[1U] = b1;
  temp[2U] = b2;
  temp[3U] = b3;
  Hacl_Impl_LowLevel_reduction_prime_2prime_impl(temp, o);
}

static void
Hacl_Impl_SolinasReduction_upl_six_buffer(
  uint32_t c9,
  uint32_t c11,
  uint32_t c12,
  uint32_t c13,
  uint32_t c14,
  uint32_t c15,
  uint64_t *temp,
  uint64_t *o
)
{
  uint64_t b0 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c13, c12);
  uint64_t b1 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c15, c14);
  uint64_t b2 = (uint64_t)0U;
  uint64_t b3 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c11, c9);
  temp[0U] = b0;
  temp[1U] = b1;
  temp[2U] = b2;
  temp[3U] = b3;
  Hacl_Impl_LowLevel_reduction_prime_2prime_impl(temp, o);
}

static void
Hacl_Impl_SolinasReduction_upl_sev_buffer(
  uint32_t c8,
  uint32_t c9,
  uint32_t c10,
  uint32_t c12,
  uint32_t c13,
  uint32_t c14,
  uint32_t c15,
  uint64_t *temp,
  uint64_t *o
)
{
  uint64_t b0 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c14, c13);
  uint64_t b1 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c8, c15);
  uint64_t b2 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c10, c9);
  uint64_t b3 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c12, (uint32_t)0U);
  temp[0U] = b0;
  temp[1U] = b1;
  temp[2U] = b2;
  temp[3U] = b3;
  Hacl_Impl_LowLevel_reduction_prime_2prime_impl(temp, o);
}

static void
Hacl_Impl_SolinasReduction_upl_eig_buffer(
  uint32_t c9,
  uint32_t c10,
  uint32_t c11,
  uint32_t c12,
  uint32_t c13,
  uint32_t c14,
  uint32_t c15,
  uint64_t *temp,
  uint64_t *o
)
{
  uint64_t b0 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c15, c14);
  uint64_t b1 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c9, (uint32_t)0U);
  uint64_t b2 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c11, c10);
  uint64_t b3 = Hacl_Spec_P256_SolinasReduction_store_high_low_u(c13, (uint32_t)0U);
  temp[0U] = b0;
  temp[1U] = b1;
  temp[2U] = b2;
  temp[3U] = b3;
  Hacl_Impl_LowLevel_reduction_prime_2prime_impl(temp, o);
}

static void Hacl_Impl_SolinasReduction_solinas_reduction_impl(uint64_t *i, uint64_t *o)
{
  uint64_t tempBuffer[36U] = { 0U };
  uint64_t i0 = i[0U];
  uint64_t i1 = i[1U];
  uint64_t i2 = i[2U];
  uint64_t i3 = i[3U];
  uint64_t i4 = i[4U];
  uint64_t i5 = i[5U];
  uint64_t i6 = i[6U];
  uint64_t i7 = i[7U];
  uint32_t c0 = (uint32_t)i0;
  uint32_t c1 = (uint32_t)(i0 >> (uint32_t)32U);
  uint32_t c2 = (uint32_t)i1;
  uint32_t c3 = (uint32_t)(i1 >> (uint32_t)32U);
  uint32_t c4 = (uint32_t)i2;
  uint32_t c5 = (uint32_t)(i2 >> (uint32_t)32U);
  uint32_t c6 = (uint32_t)i3;
  uint32_t c7 = (uint32_t)(i3 >> (uint32_t)32U);
  uint32_t c8 = (uint32_t)i4;
  uint32_t c9 = (uint32_t)(i4 >> (uint32_t)32U);
  uint32_t c10 = (uint32_t)i5;
  uint32_t c11 = (uint32_t)(i5 >> (uint32_t)32U);
  uint32_t c12 = (uint32_t)i6;
  uint32_t c13 = (uint32_t)(i6 >> (uint32_t)32U);
  uint32_t c14 = (uint32_t)i7;
  uint32_t c15 = (uint32_t)(i7 >> (uint32_t)32U);
  uint64_t redBuffer[4U] = { 0U };
  uint64_t *t610 = tempBuffer + (uint32_t)24U;
  uint64_t *t710 = tempBuffer + (uint32_t)28U;
  uint64_t *t810 = tempBuffer + (uint32_t)32U;
  uint64_t *t01 = tempBuffer;
  uint64_t *t110 = tempBuffer + (uint32_t)4U;
  uint64_t *t210 = tempBuffer + (uint32_t)8U;
  uint64_t *t310 = tempBuffer + (uint32_t)12U;
  uint64_t *t410 = tempBuffer + (uint32_t)16U;
  uint64_t *t510 = tempBuffer + (uint32_t)20U;
  Hacl_Impl_SolinasReduction_upl_zer_buffer(c0, c1, c2, c3, c4, c5, c6, c7, redBuffer, t01);
  Hacl_Impl_SolinasReduction_upl_fir_buffer(c11, c12, c13, c14, c15, redBuffer, t110);
  Hacl_Impl_SolinasReduction_upl_sec_buffer(c12, c13, c14, c15, redBuffer, t210);
  Hacl_Impl_SolinasReduction_upl_thi_buffer(c8, c9, c10, c14, c15, redBuffer, t310);
  Hacl_Impl_SolinasReduction_upl_for_buffer(c8, c9, c10, c11, c13, c14, c15, redBuffer, t410);
  Hacl_Impl_SolinasReduction_upl_fif_buffer(c8, c10, c11, c12, c13, redBuffer, t510);
  Hacl_Impl_SolinasReduction_upl_six_buffer(c9, c11, c12, c13, c14, c15, redBuffer, t610);
  Hacl_Impl_SolinasReduction_upl_sev_buffer(c8, c9, c10, c12, c13, c14, c15, redBuffer, t710);
  Hacl_Impl_SolinasReduction_upl_eig_buffer(c9, c10, c11, c12, c13, c14, c15, redBuffer, t810);
  uint64_t *t010 = tempBuffer;
  uint64_t *t11 = tempBuffer + (uint32_t)4U;
  uint64_t *t21 = tempBuffer + (uint32_t)8U;
  uint64_t *t31 = tempBuffer + (uint32_t)12U;
  uint64_t *t41 = tempBuffer + (uint32_t)16U;
  uint64_t *t51 = tempBuffer + (uint32_t)20U;
  uint64_t *t61 = tempBuffer + (uint32_t)24U;
  uint64_t *t71 = tempBuffer + (uint32_t)28U;
  uint64_t *t81 = tempBuffer + (uint32_t)32U;
  Hacl_Impl_LowLevel_p256_double(t21, t21);
  Hacl_Impl_LowLevel_p256_double(t11, t11);
  Hacl_Impl_LowLevel_p256_add(t010, t11, o);
  Hacl_Impl_LowLevel_p256_add(t21, o, o);
  Hacl_Impl_LowLevel_p256_add(t31, o, o);
  Hacl_Impl_LowLevel_p256_add(t41, o, o);
  Hacl_Impl_LowLevel_p256_sub(o, t51, o);
  Hacl_Impl_LowLevel_p256_sub(o, t61, o);
  Hacl_Impl_LowLevel_p256_sub(o, t71, o);
  Hacl_Impl_LowLevel_p256_sub(o, t81, o);
}

static void Hacl_Spec_P256_Ladder_cswap(uint64_t bit, uint64_t *p1, uint64_t *p2)
{
  uint64_t mask = (uint64_t)0U - bit;
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)12U; i = i + (uint32_t)1U)
  {
    uint64_t dummy = mask & (p1[i] ^ p2[i]);
    p1[i] = p1[i] ^ dummy;
    p2[i] = p2[i] ^ dummy;
  }
}

void pointToDomain(uint64_t *p, uint64_t *result)
{
  uint64_t *p_x = p;
  uint64_t *p_y = p + (uint32_t)4U;
  uint64_t *p_z = p + (uint32_t)8U;
  uint64_t *r_x = result;
  uint64_t *r_y = result + (uint32_t)4U;
  uint64_t *r_z = result + (uint32_t)8U;
  uint64_t multBuffer[8U] = { 0U };
  Hacl_Impl_LowLevel_shift_256_impl(p_x, multBuffer);
  Hacl_Impl_SolinasReduction_solinas_reduction_impl(multBuffer, r_x);
  uint64_t multBuffer0[8U] = { 0U };
  Hacl_Impl_LowLevel_shift_256_impl(p_y, multBuffer0);
  Hacl_Impl_SolinasReduction_solinas_reduction_impl(multBuffer0, r_y);
  uint64_t multBuffer1[8U] = { 0U };
  Hacl_Impl_LowLevel_shift_256_impl(p_z, multBuffer1);
  Hacl_Impl_SolinasReduction_solinas_reduction_impl(multBuffer1, r_z);
}

static void fromDomain(uint64_t *f, uint64_t *result)
{
  uint64_t b0 = f[0U];
  uint64_t b1 = f[1U];
  uint64_t b2 = f[2U];
  uint64_t b3 = f[3U];
  uint64_t prim0 = (uint64_t)0xffffffffffffffffU;
  uint64_t prim1 = (uint64_t)0x00000000ffffffffU;
  uint64_t prim2 = (uint64_t)0U;
  uint64_t prim3 = (uint64_t)0xffffffff00000001U;
  uint128_t res0 = (uint128_t)b0 * (uint64_t)1U;
  uint64_t l00 = (uint64_t)res0;
  uint64_t h00 = (uint64_t)(res0 >> (uint32_t)64U);
  uint128_t res1 = (uint128_t)b1 * (uint64_t)1U;
  uint64_t l10 = (uint64_t)res1;
  uint64_t h10 = (uint64_t)(res1 >> (uint32_t)64U);
  uint128_t res2 = (uint128_t)b2 * (uint64_t)1U;
  uint64_t l20 = (uint64_t)res2;
  uint64_t h20 = (uint64_t)(res2 >> (uint32_t)64U);
  uint128_t res3 = (uint128_t)b3 * (uint64_t)1U;
  uint64_t l30 = (uint64_t)res3;
  uint64_t h30 = (uint64_t)(res3 >> (uint32_t)64U);
  uint64_t o04 = l00;
  K___uint64_t_uint64_t scrut0 = Hacl_Spec_P256_Basic_addcarry(l10, h00, (uint64_t)0U);
  uint64_t o10 = scrut0.fst;
  uint64_t c00 = scrut0.snd;
  K___uint64_t_uint64_t scrut1 = Hacl_Spec_P256_Basic_addcarry(l20, h10, c00);
  uint64_t o20 = scrut1.fst;
  uint64_t c10 = scrut1.snd;
  K___uint64_t_uint64_t scrut2 = Hacl_Spec_P256_Basic_addcarry(l30, h20, c10);
  uint64_t o30 = scrut2.fst;
  uint64_t c20 = scrut2.snd;
  uint64_t c30 = h30 + c20;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut3 = { .fst = c30, .snd = { .fst = o04, .snd = o10, .thd = o20, .f3 = o30 } };
  uint64_t o03 = scrut3.snd.f3;
  uint64_t o02 = scrut3.snd.thd;
  uint64_t o01 = scrut3.snd.snd;
  uint64_t o00 = scrut3.snd.fst;
  uint64_t c02 = scrut3.fst;
  uint128_t res4 = (uint128_t)b0 * (uint64_t)0U;
  uint64_t l01 = (uint64_t)res4;
  uint64_t h01 = (uint64_t)(res4 >> (uint32_t)64U);
  uint128_t res5 = (uint128_t)b1 * (uint64_t)0U;
  uint64_t l11 = (uint64_t)res5;
  uint64_t h11 = (uint64_t)(res5 >> (uint32_t)64U);
  uint128_t res6 = (uint128_t)b2 * (uint64_t)0U;
  uint64_t l21 = (uint64_t)res6;
  uint64_t h21 = (uint64_t)(res6 >> (uint32_t)64U);
  uint128_t res7 = (uint128_t)b3 * (uint64_t)0U;
  uint64_t l31 = (uint64_t)res7;
  uint64_t h31 = (uint64_t)(res7 >> (uint32_t)64U);
  uint64_t o05 = l01;
  K___uint64_t_uint64_t scrut4 = Hacl_Spec_P256_Basic_addcarry(l11, h01, (uint64_t)0U);
  uint64_t o15 = scrut4.fst;
  uint64_t c010 = scrut4.snd;
  K___uint64_t_uint64_t scrut5 = Hacl_Spec_P256_Basic_addcarry(l21, h11, c010);
  uint64_t o21 = scrut5.fst;
  uint64_t c12 = scrut5.snd;
  K___uint64_t_uint64_t scrut6 = Hacl_Spec_P256_Basic_addcarry(l31, h21, c12);
  uint64_t o31 = scrut6.fst;
  uint64_t c22 = scrut6.snd;
  uint64_t c31 = h31 + c22;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut7 = { .fst = c31, .snd = { .fst = o05, .snd = o15, .thd = o21, .f3 = o31 } };
  uint64_t c8 = scrut7.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t out00 = scrut7.snd;
  uint64_t o06 = out00.fst;
  uint64_t o16 = out00.snd;
  uint64_t o26 = out00.thd;
  uint64_t o32 = out00.f3;
  uint64_t f300 = o01;
  uint64_t f310 = o02;
  uint64_t f320 = o03;
  uint64_t f330 = c02;
  K___uint64_t_uint64_t scrut8 = Hacl_Spec_P256_Basic_addcarry(f300, o06, (uint64_t)0U);
  uint64_t o0_ = scrut8.fst;
  uint64_t c011 = scrut8.snd;
  K___uint64_t_uint64_t scrut9 = Hacl_Spec_P256_Basic_addcarry(f310, o16, c011);
  uint64_t o1_ = scrut9.fst;
  uint64_t c13 = scrut9.snd;
  K___uint64_t_uint64_t scrut10 = Hacl_Spec_P256_Basic_addcarry(f320, o26, c13);
  uint64_t o2_ = scrut10.fst;
  uint64_t c23 = scrut10.snd;
  K___uint64_t_uint64_t scrut11 = Hacl_Spec_P256_Basic_addcarry(f330, o32, c23);
  uint64_t o3_ = scrut11.fst;
  uint64_t c32 = scrut11.snd;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  out1 = { .fst = o0_, .snd = o1_, .thd = o2_, .f3 = o3_ };
  uint64_t c40 = c8 + c32;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t scrut12 = { .fst = c40, .snd = out1 };
  uint64_t o14 = scrut12.snd.f3;
  uint64_t o13 = scrut12.snd.thd;
  uint64_t o12 = scrut12.snd.snd;
  uint64_t o11 = scrut12.snd.fst;
  uint64_t c14 = scrut12.fst;
  uint128_t res8 = (uint128_t)b0 * (uint64_t)0U;
  uint64_t l02 = (uint64_t)res8;
  uint64_t h02 = (uint64_t)(res8 >> (uint32_t)64U);
  uint128_t res9 = (uint128_t)b1 * (uint64_t)0U;
  uint64_t l12 = (uint64_t)res9;
  uint64_t h12 = (uint64_t)(res9 >> (uint32_t)64U);
  uint128_t res10 = (uint128_t)b2 * (uint64_t)0U;
  uint64_t l22 = (uint64_t)res10;
  uint64_t h22 = (uint64_t)(res10 >> (uint32_t)64U);
  uint128_t res11 = (uint128_t)b3 * (uint64_t)0U;
  uint64_t l32 = (uint64_t)res11;
  uint64_t h32 = (uint64_t)(res11 >> (uint32_t)64U);
  uint64_t o07 = l02;
  K___uint64_t_uint64_t scrut13 = Hacl_Spec_P256_Basic_addcarry(l12, h02, (uint64_t)0U);
  uint64_t o17 = scrut13.fst;
  uint64_t c012 = scrut13.snd;
  K___uint64_t_uint64_t scrut14 = Hacl_Spec_P256_Basic_addcarry(l22, h12, c012);
  uint64_t o27 = scrut14.fst;
  uint64_t c110 = scrut14.snd;
  K___uint64_t_uint64_t scrut15 = Hacl_Spec_P256_Basic_addcarry(l32, h22, c110);
  uint64_t o37 = scrut15.fst;
  uint64_t c24 = scrut15.snd;
  uint64_t c33 = h32 + c24;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut16 = { .fst = c33, .snd = { .fst = o07, .snd = o17, .thd = o27, .f3 = o37 } };
  uint64_t c9 = scrut16.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t out01 = scrut16.snd;
  uint64_t o08 = out01.fst;
  uint64_t o18 = out01.snd;
  uint64_t o28 = out01.thd;
  uint64_t o38 = out01.f3;
  uint64_t f301 = o12;
  uint64_t f311 = o13;
  uint64_t f321 = o14;
  uint64_t f331 = c14;
  K___uint64_t_uint64_t scrut17 = Hacl_Spec_P256_Basic_addcarry(f301, o08, (uint64_t)0U);
  uint64_t o0_0 = scrut17.fst;
  uint64_t c013 = scrut17.snd;
  K___uint64_t_uint64_t scrut18 = Hacl_Spec_P256_Basic_addcarry(f311, o18, c013);
  uint64_t o1_0 = scrut18.fst;
  uint64_t c111 = scrut18.snd;
  K___uint64_t_uint64_t scrut19 = Hacl_Spec_P256_Basic_addcarry(f321, o28, c111);
  uint64_t o2_0 = scrut19.fst;
  uint64_t c25 = scrut19.snd;
  K___uint64_t_uint64_t scrut20 = Hacl_Spec_P256_Basic_addcarry(f331, o38, c25);
  uint64_t o3_0 = scrut20.fst;
  uint64_t c34 = scrut20.snd;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  out2 = { .fst = o0_0, .snd = o1_0, .thd = o2_0, .f3 = o3_0 };
  uint64_t c41 = c9 + c34;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t scrut21 = { .fst = c41, .snd = out2 };
  uint64_t o25 = scrut21.snd.f3;
  uint64_t o24 = scrut21.snd.thd;
  uint64_t o23 = scrut21.snd.snd;
  uint64_t o22 = scrut21.snd.fst;
  uint64_t c26 = scrut21.fst;
  uint128_t res12 = (uint128_t)b0 * (uint64_t)0U;
  uint64_t l03 = (uint64_t)res12;
  uint64_t h03 = (uint64_t)(res12 >> (uint32_t)64U);
  uint128_t res13 = (uint128_t)b1 * (uint64_t)0U;
  uint64_t l13 = (uint64_t)res13;
  uint64_t h13 = (uint64_t)(res13 >> (uint32_t)64U);
  uint128_t res14 = (uint128_t)b2 * (uint64_t)0U;
  uint64_t l23 = (uint64_t)res14;
  uint64_t h23 = (uint64_t)(res14 >> (uint32_t)64U);
  uint128_t res15 = (uint128_t)b3 * (uint64_t)0U;
  uint64_t l33 = (uint64_t)res15;
  uint64_t h33 = (uint64_t)(res15 >> (uint32_t)64U);
  uint64_t o09 = l03;
  K___uint64_t_uint64_t scrut22 = Hacl_Spec_P256_Basic_addcarry(l13, h03, (uint64_t)0U);
  uint64_t o19 = scrut22.fst;
  uint64_t c014 = scrut22.snd;
  K___uint64_t_uint64_t scrut23 = Hacl_Spec_P256_Basic_addcarry(l23, h13, c014);
  uint64_t o29 = scrut23.fst;
  uint64_t c112 = scrut23.snd;
  K___uint64_t_uint64_t scrut24 = Hacl_Spec_P256_Basic_addcarry(l33, h23, c112);
  uint64_t o39 = scrut24.fst;
  uint64_t c210 = scrut24.snd;
  uint64_t c35 = h33 + c210;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut25 = { .fst = c35, .snd = { .fst = o09, .snd = o19, .thd = o29, .f3 = o39 } };
  uint64_t c15 = scrut25.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t out0 = scrut25.snd;
  uint64_t o010 = out0.fst;
  uint64_t o110 = out0.snd;
  uint64_t o210 = out0.thd;
  uint64_t o310 = out0.f3;
  uint64_t f30 = o23;
  uint64_t f31 = o24;
  uint64_t f32 = o25;
  uint64_t f33 = c26;
  K___uint64_t_uint64_t scrut26 = Hacl_Spec_P256_Basic_addcarry(f30, o010, (uint64_t)0U);
  uint64_t o0_1 = scrut26.fst;
  uint64_t c01 = scrut26.snd;
  K___uint64_t_uint64_t scrut27 = Hacl_Spec_P256_Basic_addcarry(f31, o110, c01);
  uint64_t o1_1 = scrut27.fst;
  uint64_t c11 = scrut27.snd;
  K___uint64_t_uint64_t scrut28 = Hacl_Spec_P256_Basic_addcarry(f32, o210, c11);
  uint64_t o2_1 = scrut28.fst;
  uint64_t c21 = scrut28.snd;
  K___uint64_t_uint64_t scrut29 = Hacl_Spec_P256_Basic_addcarry(f33, o310, c21);
  uint64_t o3_1 = scrut29.fst;
  uint64_t c36 = scrut29.snd;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  out = { .fst = o0_1, .snd = o1_1, .thd = o2_1, .f3 = o3_1 };
  uint64_t c42 = c15 + c36;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t scrut30 = { .fst = c42, .snd = out };
  uint64_t o36 = scrut30.snd.f3;
  uint64_t o35 = scrut30.snd.thd;
  uint64_t o34 = scrut30.snd.snd;
  uint64_t o33 = scrut30.snd.fst;
  uint64_t c37 = scrut30.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut31 =
    { .fst = o00, .snd = o11, .thd = o22, .f3 = o33, .f4 = o34, .f5 = o35, .f6 = o36, .f7 = c37 };
  uint64_t t_0 = scrut31.fst;
  uint64_t t_1 = scrut31.snd;
  uint64_t t_2 = scrut31.thd;
  uint64_t t_3 = scrut31.f3;
  uint64_t t_4 = scrut31.f4;
  uint64_t t_5 = scrut31.f5;
  uint64_t t_6 = scrut31.f6;
  uint64_t t_7 = scrut31.f7;
  uint64_t t1 = t_0;
  uint128_t res16 = (uint128_t)prim0 * t1;
  uint64_t l04 = (uint64_t)res16;
  uint64_t h04 = (uint64_t)(res16 >> (uint32_t)64U);
  uint128_t res17 = (uint128_t)prim1 * t1;
  uint64_t l14 = (uint64_t)res17;
  uint64_t h14 = (uint64_t)(res17 >> (uint32_t)64U);
  uint128_t res18 = (uint128_t)prim2 * t1;
  uint64_t l24 = (uint64_t)res18;
  uint64_t h24 = (uint64_t)(res18 >> (uint32_t)64U);
  uint128_t res19 = (uint128_t)prim3 * t1;
  uint64_t l34 = (uint64_t)res19;
  uint64_t h34 = (uint64_t)(res19 >> (uint32_t)64U);
  uint64_t o011 = l04;
  K___uint64_t_uint64_t scrut32 = Hacl_Spec_P256_Basic_addcarry(l14, h04, (uint64_t)0U);
  uint64_t o111 = scrut32.fst;
  uint64_t c03 = scrut32.snd;
  K___uint64_t_uint64_t scrut33 = Hacl_Spec_P256_Basic_addcarry(l24, h14, c03);
  uint64_t o211 = scrut33.fst;
  uint64_t c16 = scrut33.snd;
  K___uint64_t_uint64_t scrut34 = Hacl_Spec_P256_Basic_addcarry(l34, h24, c16);
  uint64_t o311 = scrut34.fst;
  uint64_t c27 = scrut34.snd;
  uint64_t c38 = h34 + c27;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut35 = { .fst = c38, .snd = { .fst = o011, .snd = o111, .thd = o211, .f3 = o311 } };
  uint64_t f34 = scrut35.snd.f3;
  uint64_t f20 = scrut35.snd.thd;
  uint64_t f10 = scrut35.snd.snd;
  uint64_t f00 = scrut35.snd.fst;
  uint64_t c17 = scrut35.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut36 =
    {
      .fst = f00, .snd = f10, .thd = f20, .f3 = f34, .f4 = c17, .f5 = (uint64_t)0U,
      .f6 = (uint64_t)0U, .f7 = (uint64_t)0U
    };
  uint64_t t2_0 = scrut36.fst;
  uint64_t t2_1 = scrut36.snd;
  uint64_t t2_2 = scrut36.thd;
  uint64_t t2_3 = scrut36.f3;
  uint64_t t2_4 = scrut36.f4;
  uint64_t t2_5 = scrut36.f5;
  uint64_t t2_6 = scrut36.f6;
  uint64_t t2_7 = scrut36.f7;
  K___uint64_t_uint64_t scrut37 = Hacl_Spec_P256_Basic_addcarry(t_0, t2_0, (uint64_t)0U);
  uint64_t o012 = scrut37.fst;
  uint64_t c04 = scrut37.snd;
  K___uint64_t_uint64_t scrut38 = Hacl_Spec_P256_Basic_addcarry(t_1, t2_1, c04);
  uint64_t o112 = scrut38.fst;
  uint64_t c18 = scrut38.snd;
  K___uint64_t_uint64_t scrut39 = Hacl_Spec_P256_Basic_addcarry(t_2, t2_2, c18);
  uint64_t o212 = scrut39.fst;
  uint64_t c28 = scrut39.snd;
  K___uint64_t_uint64_t scrut40 = Hacl_Spec_P256_Basic_addcarry(t_3, t2_3, c28);
  uint64_t o312 = scrut40.fst;
  uint64_t c39 = scrut40.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut41 = { .fst = c39, .snd = { .fst = o012, .snd = o112, .thd = o212, .f3 = o312 } };
  uint64_t o313 = scrut41.snd.f3;
  uint64_t o213 = scrut41.snd.thd;
  uint64_t o113 = scrut41.snd.snd;
  uint64_t o013 = scrut41.snd.fst;
  uint64_t c310 = scrut41.fst;
  K___uint64_t_uint64_t scrut42 = Hacl_Spec_P256_Basic_addcarry(t_4, t2_4, c310);
  uint64_t o40 = scrut42.fst;
  uint64_t c43 = scrut42.snd;
  K___uint64_t_uint64_t scrut43 = Hacl_Spec_P256_Basic_addcarry(t_5, t2_5, c43);
  uint64_t o50 = scrut43.fst;
  uint64_t c50 = scrut43.snd;
  K___uint64_t_uint64_t scrut44 = Hacl_Spec_P256_Basic_addcarry(t_6, t2_6, c50);
  uint64_t o60 = scrut44.fst;
  uint64_t c60 = scrut44.snd;
  K___uint64_t_uint64_t scrut45 = Hacl_Spec_P256_Basic_addcarry(t_7, t2_7, c60);
  uint64_t o70 = scrut45.fst;
  uint64_t c70 = scrut45.snd;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut46 =
    {
      .fst = c70, .snd = o013, .thd = o113, .f3 = o213, .f4 = o313, .f5 = o40, .f6 = o50, .f7 = o60,
      .f8 = o70
    };
  uint64_t r00 = scrut46.snd;
  uint64_t r10 = scrut46.thd;
  uint64_t r20 = scrut46.f3;
  uint64_t r30 = scrut46.f4;
  uint64_t r40 = scrut46.f5;
  uint64_t r50 = scrut46.f6;
  uint64_t r60 = scrut46.f7;
  uint64_t r70 = scrut46.f8;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut47 =
    { .fst = r00, .snd = r10, .thd = r20, .f3 = r30, .f4 = r40, .f5 = r50, .f6 = r60, .f7 = r70 };
  uint64_t t3_1 = scrut47.snd;
  uint64_t t3_2 = scrut47.thd;
  uint64_t t3_3 = scrut47.f3;
  uint64_t t3_4 = scrut47.f4;
  uint64_t t3_5 = scrut47.f5;
  uint64_t t3_6 = scrut47.f6;
  uint64_t t3_7 = scrut47.f7;
  uint64_t st0 = t3_1;
  uint64_t st1 = t3_2;
  uint64_t st2 = t3_3;
  uint64_t st3 = t3_4;
  uint64_t st4 = t3_5;
  uint64_t st5 = t3_6;
  uint64_t st6 = t3_7;
  uint64_t st7 = (uint64_t)0U;
  uint64_t t110 = st0;
  uint128_t res20 = (uint128_t)prim0 * t110;
  uint64_t l05 = (uint64_t)res20;
  uint64_t h05 = (uint64_t)(res20 >> (uint32_t)64U);
  uint128_t res21 = (uint128_t)prim1 * t110;
  uint64_t l15 = (uint64_t)res21;
  uint64_t h15 = (uint64_t)(res21 >> (uint32_t)64U);
  uint128_t res22 = (uint128_t)prim2 * t110;
  uint64_t l25 = (uint64_t)res22;
  uint64_t h25 = (uint64_t)(res22 >> (uint32_t)64U);
  uint128_t res23 = (uint128_t)prim3 * t110;
  uint64_t l35 = (uint64_t)res23;
  uint64_t h35 = (uint64_t)(res23 >> (uint32_t)64U);
  uint64_t o014 = l05;
  K___uint64_t_uint64_t scrut48 = Hacl_Spec_P256_Basic_addcarry(l15, h05, (uint64_t)0U);
  uint64_t o114 = scrut48.fst;
  uint64_t c05 = scrut48.snd;
  K___uint64_t_uint64_t scrut49 = Hacl_Spec_P256_Basic_addcarry(l25, h15, c05);
  uint64_t o214 = scrut49.fst;
  uint64_t c19 = scrut49.snd;
  K___uint64_t_uint64_t scrut50 = Hacl_Spec_P256_Basic_addcarry(l35, h25, c19);
  uint64_t o314 = scrut50.fst;
  uint64_t c29 = scrut50.snd;
  uint64_t c311 = h35 + c29;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut51 = { .fst = c311, .snd = { .fst = o014, .snd = o114, .thd = o214, .f3 = o314 } };
  uint64_t f35 = scrut51.snd.f3;
  uint64_t f21 = scrut51.snd.thd;
  uint64_t f11 = scrut51.snd.snd;
  uint64_t f01 = scrut51.snd.fst;
  uint64_t c44 = scrut51.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut52 =
    {
      .fst = f01, .snd = f11, .thd = f21, .f3 = f35, .f4 = c44, .f5 = (uint64_t)0U,
      .f6 = (uint64_t)0U, .f7 = (uint64_t)0U
    };
  uint64_t t2_010 = scrut52.fst;
  uint64_t t2_110 = scrut52.snd;
  uint64_t t2_210 = scrut52.thd;
  uint64_t t2_310 = scrut52.f3;
  uint64_t t2_410 = scrut52.f4;
  uint64_t t2_510 = scrut52.f5;
  uint64_t t2_610 = scrut52.f6;
  uint64_t t2_710 = scrut52.f7;
  K___uint64_t_uint64_t scrut53 = Hacl_Spec_P256_Basic_addcarry(st0, t2_010, (uint64_t)0U);
  uint64_t o015 = scrut53.fst;
  uint64_t c06 = scrut53.snd;
  K___uint64_t_uint64_t scrut54 = Hacl_Spec_P256_Basic_addcarry(st1, t2_110, c06);
  uint64_t o115 = scrut54.fst;
  uint64_t c113 = scrut54.snd;
  K___uint64_t_uint64_t scrut55 = Hacl_Spec_P256_Basic_addcarry(st2, t2_210, c113);
  uint64_t o215 = scrut55.fst;
  uint64_t c211 = scrut55.snd;
  K___uint64_t_uint64_t scrut56 = Hacl_Spec_P256_Basic_addcarry(st3, t2_310, c211);
  uint64_t o315 = scrut56.fst;
  uint64_t c312 = scrut56.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut57 = { .fst = c312, .snd = { .fst = o015, .snd = o115, .thd = o215, .f3 = o315 } };
  uint64_t o316 = scrut57.snd.f3;
  uint64_t o216 = scrut57.snd.thd;
  uint64_t o116 = scrut57.snd.snd;
  uint64_t o016 = scrut57.snd.fst;
  uint64_t c313 = scrut57.fst;
  K___uint64_t_uint64_t scrut58 = Hacl_Spec_P256_Basic_addcarry(st4, t2_410, c313);
  uint64_t o41 = scrut58.fst;
  uint64_t c45 = scrut58.snd;
  K___uint64_t_uint64_t scrut59 = Hacl_Spec_P256_Basic_addcarry(st5, t2_510, c45);
  uint64_t o51 = scrut59.fst;
  uint64_t c51 = scrut59.snd;
  K___uint64_t_uint64_t scrut60 = Hacl_Spec_P256_Basic_addcarry(st6, t2_610, c51);
  uint64_t o61 = scrut60.fst;
  uint64_t c61 = scrut60.snd;
  K___uint64_t_uint64_t scrut61 = Hacl_Spec_P256_Basic_addcarry(st7, t2_710, c61);
  uint64_t o71 = scrut61.fst;
  uint64_t c71 = scrut61.snd;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut62 =
    {
      .fst = c71, .snd = o016, .thd = o116, .f3 = o216, .f4 = o316, .f5 = o41, .f6 = o51, .f7 = o61,
      .f8 = o71
    };
  uint64_t r01 = scrut62.snd;
  uint64_t r11 = scrut62.thd;
  uint64_t r21 = scrut62.f3;
  uint64_t r31 = scrut62.f4;
  uint64_t r41 = scrut62.f5;
  uint64_t r51 = scrut62.f6;
  uint64_t r61 = scrut62.f7;
  uint64_t r71 = scrut62.f8;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut63 =
    { .fst = r01, .snd = r11, .thd = r21, .f3 = r31, .f4 = r41, .f5 = r51, .f6 = r61, .f7 = r71 };
  uint64_t t3_110 = scrut63.snd;
  uint64_t t3_210 = scrut63.thd;
  uint64_t t3_310 = scrut63.f3;
  uint64_t t3_410 = scrut63.f4;
  uint64_t t3_510 = scrut63.f5;
  uint64_t t3_610 = scrut63.f6;
  uint64_t t3_710 = scrut63.f7;
  uint64_t r_00 = t3_110;
  uint64_t r_10 = t3_210;
  uint64_t r_20 = t3_310;
  uint64_t r_30 = t3_410;
  uint64_t r_40 = t3_510;
  uint64_t r_50 = t3_610;
  uint64_t r_60 = t3_710;
  uint64_t r_70 = (uint64_t)0U;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut64 =
    {
      .fst = r_00, .snd = r_10, .thd = r_20, .f3 = r_30, .f4 = r_40, .f5 = r_50, .f6 = r_60,
      .f7 = r_70
    };
  uint64_t st10 = scrut64.fst;
  uint64_t st11 = scrut64.snd;
  uint64_t st12 = scrut64.thd;
  uint64_t st13 = scrut64.f3;
  uint64_t st14 = scrut64.f4;
  uint64_t st15 = scrut64.f5;
  uint64_t st16 = scrut64.f6;
  uint64_t st17 = scrut64.f7;
  uint64_t t111 = st10;
  uint128_t res24 = (uint128_t)prim0 * t111;
  uint64_t l06 = (uint64_t)res24;
  uint64_t h06 = (uint64_t)(res24 >> (uint32_t)64U);
  uint128_t res25 = (uint128_t)prim1 * t111;
  uint64_t l16 = (uint64_t)res25;
  uint64_t h16 = (uint64_t)(res25 >> (uint32_t)64U);
  uint128_t res26 = (uint128_t)prim2 * t111;
  uint64_t l26 = (uint64_t)res26;
  uint64_t h26 = (uint64_t)(res26 >> (uint32_t)64U);
  uint128_t res27 = (uint128_t)prim3 * t111;
  uint64_t l36 = (uint64_t)res27;
  uint64_t h36 = (uint64_t)(res27 >> (uint32_t)64U);
  uint64_t o017 = l06;
  K___uint64_t_uint64_t scrut65 = Hacl_Spec_P256_Basic_addcarry(l16, h06, (uint64_t)0U);
  uint64_t o117 = scrut65.fst;
  uint64_t c07 = scrut65.snd;
  K___uint64_t_uint64_t scrut66 = Hacl_Spec_P256_Basic_addcarry(l26, h16, c07);
  uint64_t o217 = scrut66.fst;
  uint64_t c114 = scrut66.snd;
  K___uint64_t_uint64_t scrut67 = Hacl_Spec_P256_Basic_addcarry(l36, h26, c114);
  uint64_t o317 = scrut67.fst;
  uint64_t c212 = scrut67.snd;
  uint64_t c314 = h36 + c212;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut68 = { .fst = c314, .snd = { .fst = o017, .snd = o117, .thd = o217, .f3 = o317 } };
  uint64_t f36 = scrut68.snd.f3;
  uint64_t f22 = scrut68.snd.thd;
  uint64_t f12 = scrut68.snd.snd;
  uint64_t f02 = scrut68.snd.fst;
  uint64_t c46 = scrut68.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut69 =
    {
      .fst = f02, .snd = f12, .thd = f22, .f3 = f36, .f4 = c46, .f5 = (uint64_t)0U,
      .f6 = (uint64_t)0U, .f7 = (uint64_t)0U
    };
  uint64_t t2_011 = scrut69.fst;
  uint64_t t2_111 = scrut69.snd;
  uint64_t t2_211 = scrut69.thd;
  uint64_t t2_311 = scrut69.f3;
  uint64_t t2_411 = scrut69.f4;
  uint64_t t2_511 = scrut69.f5;
  uint64_t t2_611 = scrut69.f6;
  uint64_t t2_711 = scrut69.f7;
  K___uint64_t_uint64_t scrut70 = Hacl_Spec_P256_Basic_addcarry(st10, t2_011, (uint64_t)0U);
  uint64_t o018 = scrut70.fst;
  uint64_t c08 = scrut70.snd;
  K___uint64_t_uint64_t scrut71 = Hacl_Spec_P256_Basic_addcarry(st11, t2_111, c08);
  uint64_t o118 = scrut71.fst;
  uint64_t c115 = scrut71.snd;
  K___uint64_t_uint64_t scrut72 = Hacl_Spec_P256_Basic_addcarry(st12, t2_211, c115);
  uint64_t o218 = scrut72.fst;
  uint64_t c213 = scrut72.snd;
  K___uint64_t_uint64_t scrut73 = Hacl_Spec_P256_Basic_addcarry(st13, t2_311, c213);
  uint64_t o318 = scrut73.fst;
  uint64_t c315 = scrut73.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut74 = { .fst = c315, .snd = { .fst = o018, .snd = o118, .thd = o218, .f3 = o318 } };
  uint64_t o319 = scrut74.snd.f3;
  uint64_t o219 = scrut74.snd.thd;
  uint64_t o119 = scrut74.snd.snd;
  uint64_t o019 = scrut74.snd.fst;
  uint64_t c316 = scrut74.fst;
  K___uint64_t_uint64_t scrut75 = Hacl_Spec_P256_Basic_addcarry(st14, t2_411, c316);
  uint64_t o42 = scrut75.fst;
  uint64_t c47 = scrut75.snd;
  K___uint64_t_uint64_t scrut76 = Hacl_Spec_P256_Basic_addcarry(st15, t2_511, c47);
  uint64_t o52 = scrut76.fst;
  uint64_t c52 = scrut76.snd;
  K___uint64_t_uint64_t scrut77 = Hacl_Spec_P256_Basic_addcarry(st16, t2_611, c52);
  uint64_t o62 = scrut77.fst;
  uint64_t c62 = scrut77.snd;
  K___uint64_t_uint64_t scrut78 = Hacl_Spec_P256_Basic_addcarry(st17, t2_711, c62);
  uint64_t o72 = scrut78.fst;
  uint64_t c72 = scrut78.snd;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut79 =
    {
      .fst = c72, .snd = o019, .thd = o119, .f3 = o219, .f4 = o319, .f5 = o42, .f6 = o52, .f7 = o62,
      .f8 = o72
    };
  uint64_t r02 = scrut79.snd;
  uint64_t r12 = scrut79.thd;
  uint64_t r22 = scrut79.f3;
  uint64_t r32 = scrut79.f4;
  uint64_t r42 = scrut79.f5;
  uint64_t r52 = scrut79.f6;
  uint64_t r62 = scrut79.f7;
  uint64_t r72 = scrut79.f8;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut80 =
    { .fst = r02, .snd = r12, .thd = r22, .f3 = r32, .f4 = r42, .f5 = r52, .f6 = r62, .f7 = r72 };
  uint64_t t3_111 = scrut80.snd;
  uint64_t t3_211 = scrut80.thd;
  uint64_t t3_311 = scrut80.f3;
  uint64_t t3_411 = scrut80.f4;
  uint64_t t3_511 = scrut80.f5;
  uint64_t t3_611 = scrut80.f6;
  uint64_t t3_711 = scrut80.f7;
  uint64_t r_01 = t3_111;
  uint64_t r_11 = t3_211;
  uint64_t r_21 = t3_311;
  uint64_t r_31 = t3_411;
  uint64_t r_41 = t3_511;
  uint64_t r_51 = t3_611;
  uint64_t r_61 = t3_711;
  uint64_t r_71 = (uint64_t)0U;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut81 =
    {
      .fst = r_01, .snd = r_11, .thd = r_21, .f3 = r_31, .f4 = r_41, .f5 = r_51, .f6 = r_61,
      .f7 = r_71
    };
  uint64_t st20 = scrut81.fst;
  uint64_t st21 = scrut81.snd;
  uint64_t st22 = scrut81.thd;
  uint64_t st23 = scrut81.f3;
  uint64_t st24 = scrut81.f4;
  uint64_t st25 = scrut81.f5;
  uint64_t st26 = scrut81.f6;
  uint64_t st27 = scrut81.f7;
  uint64_t t11 = st20;
  uint128_t res28 = (uint128_t)prim0 * t11;
  uint64_t l0 = (uint64_t)res28;
  uint64_t h0 = (uint64_t)(res28 >> (uint32_t)64U);
  uint128_t res29 = (uint128_t)prim1 * t11;
  uint64_t l1 = (uint64_t)res29;
  uint64_t h1 = (uint64_t)(res29 >> (uint32_t)64U);
  uint128_t res30 = (uint128_t)prim2 * t11;
  uint64_t l2 = (uint64_t)res30;
  uint64_t h2 = (uint64_t)(res30 >> (uint32_t)64U);
  uint128_t res = (uint128_t)prim3 * t11;
  uint64_t l3 = (uint64_t)res;
  uint64_t h3 = (uint64_t)(res >> (uint32_t)64U);
  uint64_t o020 = l0;
  K___uint64_t_uint64_t scrut82 = Hacl_Spec_P256_Basic_addcarry(l1, h0, (uint64_t)0U);
  uint64_t o120 = scrut82.fst;
  uint64_t c09 = scrut82.snd;
  K___uint64_t_uint64_t scrut83 = Hacl_Spec_P256_Basic_addcarry(l2, h1, c09);
  uint64_t o220 = scrut83.fst;
  uint64_t c116 = scrut83.snd;
  K___uint64_t_uint64_t scrut84 = Hacl_Spec_P256_Basic_addcarry(l3, h2, c116);
  uint64_t o320 = scrut84.fst;
  uint64_t c214 = scrut84.snd;
  uint64_t c317 = h3 + c214;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut85 = { .fst = c317, .snd = { .fst = o020, .snd = o120, .thd = o220, .f3 = o320 } };
  uint64_t f3 = scrut85.snd.f3;
  uint64_t f2 = scrut85.snd.thd;
  uint64_t f1 = scrut85.snd.snd;
  uint64_t f0 = scrut85.snd.fst;
  uint64_t c = scrut85.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut86 =
    {
      .fst = f0, .snd = f1, .thd = f2, .f3 = f3, .f4 = c, .f5 = (uint64_t)0U, .f6 = (uint64_t)0U,
      .f7 = (uint64_t)0U
    };
  uint64_t t2_01 = scrut86.fst;
  uint64_t t2_11 = scrut86.snd;
  uint64_t t2_21 = scrut86.thd;
  uint64_t t2_31 = scrut86.f3;
  uint64_t t2_41 = scrut86.f4;
  uint64_t t2_51 = scrut86.f5;
  uint64_t t2_61 = scrut86.f6;
  uint64_t t2_71 = scrut86.f7;
  K___uint64_t_uint64_t scrut = Hacl_Spec_P256_Basic_addcarry(st20, t2_01, (uint64_t)0U);
  uint64_t o021 = scrut.fst;
  uint64_t c0 = scrut.snd;
  K___uint64_t_uint64_t scrut87 = Hacl_Spec_P256_Basic_addcarry(st21, t2_11, c0);
  uint64_t o121 = scrut87.fst;
  uint64_t c1 = scrut87.snd;
  K___uint64_t_uint64_t scrut88 = Hacl_Spec_P256_Basic_addcarry(st22, t2_21, c1);
  uint64_t o221 = scrut88.fst;
  uint64_t c2 = scrut88.snd;
  K___uint64_t_uint64_t scrut89 = Hacl_Spec_P256_Basic_addcarry(st23, t2_31, c2);
  uint64_t o321 = scrut89.fst;
  uint64_t c318 = scrut89.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut90 = { .fst = c318, .snd = { .fst = o021, .snd = o121, .thd = o221, .f3 = o321 } };
  uint64_t o3 = scrut90.snd.f3;
  uint64_t o2 = scrut90.snd.thd;
  uint64_t o1 = scrut90.snd.snd;
  uint64_t o0 = scrut90.snd.fst;
  uint64_t c3 = scrut90.fst;
  K___uint64_t_uint64_t scrut91 = Hacl_Spec_P256_Basic_addcarry(st24, t2_41, c3);
  uint64_t o4 = scrut91.fst;
  uint64_t c4 = scrut91.snd;
  K___uint64_t_uint64_t scrut92 = Hacl_Spec_P256_Basic_addcarry(st25, t2_51, c4);
  uint64_t o5 = scrut92.fst;
  uint64_t c5 = scrut92.snd;
  K___uint64_t_uint64_t scrut93 = Hacl_Spec_P256_Basic_addcarry(st26, t2_61, c5);
  uint64_t o6 = scrut93.fst;
  uint64_t c6 = scrut93.snd;
  K___uint64_t_uint64_t scrut94 = Hacl_Spec_P256_Basic_addcarry(st27, t2_71, c6);
  uint64_t o7 = scrut94.fst;
  uint64_t c7 = scrut94.snd;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut95 =
    { .fst = c7, .snd = o0, .thd = o1, .f3 = o2, .f4 = o3, .f5 = o4, .f6 = o5, .f7 = o6, .f8 = o7 };
  uint64_t r03 = scrut95.snd;
  uint64_t r13 = scrut95.thd;
  uint64_t r23 = scrut95.f3;
  uint64_t r33 = scrut95.f4;
  uint64_t r4 = scrut95.f5;
  uint64_t r5 = scrut95.f6;
  uint64_t r6 = scrut95.f7;
  uint64_t r7 = scrut95.f8;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut96 =
    { .fst = r03, .snd = r13, .thd = r23, .f3 = r33, .f4 = r4, .f5 = r5, .f6 = r6, .f7 = r7 };
  uint64_t t3_11 = scrut96.snd;
  uint64_t t3_21 = scrut96.thd;
  uint64_t t3_31 = scrut96.f3;
  uint64_t t3_41 = scrut96.f4;
  uint64_t t3_51 = scrut96.f5;
  uint64_t t3_61 = scrut96.f6;
  uint64_t t3_71 = scrut96.f7;
  uint64_t r_0 = t3_11;
  uint64_t r_1 = t3_21;
  uint64_t r_2 = t3_31;
  uint64_t r_3 = t3_41;
  uint64_t r_4 = t3_51;
  uint64_t r_5 = t3_61;
  uint64_t r_6 = t3_71;
  uint64_t r_7 = (uint64_t)0U;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut97 =
    { .fst = r_0, .snd = r_1, .thd = r_2, .f3 = r_3, .f4 = r_4, .f5 = r_5, .f6 = r_6, .f7 = r_7 };
  uint64_t st30 = scrut97.fst;
  uint64_t st31 = scrut97.snd;
  uint64_t st32 = scrut97.thd;
  uint64_t st33 = scrut97.f3;
  uint64_t st34 = scrut97.f4;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut98 =
    Hacl_Spec_P256_Core_reduction_prime_2prime_with_carry(st34,
      (
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = st30,
          .snd = st31,
          .thd = st32,
          .f3 = st33
        }
      ));
  uint64_t r0 = scrut98.fst;
  uint64_t r1 = scrut98.snd;
  uint64_t r2 = scrut98.thd;
  uint64_t r3 = scrut98.f3;
  result[0U] = r0;
  result[1U] = r1;
  result[2U] = r2;
  result[3U] = r3;
}

void pointFromDomain(uint64_t *p, uint64_t *result)
{
  uint64_t *p_x = p;
  uint64_t *p_y = p + (uint32_t)4U;
  uint64_t *p_z = p + (uint32_t)8U;
  uint64_t *r_x = result;
  uint64_t *r_y = result + (uint32_t)4U;
  uint64_t *r_z = result + (uint32_t)8U;
  fromDomain(p_x, r_x);
  fromDomain(p_y, r_y);
  fromDomain(p_z, r_z);
}

static void quatre(uint64_t *a, uint64_t *result)
{
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(a, a, result);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(result,
    result,
    result);
}

static void multByTwo(uint64_t *a, uint64_t *out)
{
  Hacl_Impl_LowLevel_p256_add(a, a, out);
}

static void multByThree(uint64_t *a, uint64_t *result)
{
  multByTwo(a, result);
  Hacl_Impl_LowLevel_p256_add(a, result, result);
}

static void multByFour(uint64_t *a, uint64_t *result)
{
  multByTwo(a, result);
  multByTwo(result, result);
}

static void multByEight(uint64_t *a, uint64_t *result)
{
  multByTwo(a, result);
  multByTwo(result, result);
  multByTwo(result, result);
}

static void multByMinusThree(uint64_t *a, uint64_t *result)
{
  multByThree(a, result);
  uint64_t zeros1[4U] = { 0U };
  Hacl_Impl_LowLevel_p256_sub(zeros1, result, result);
}

static uint64_t isZero_uint64(uint64_t *f)
{
  uint64_t a0 = f[0U];
  uint64_t a1 = f[1U];
  uint64_t a2 = f[2U];
  uint64_t a3 = f[3U];
  uint64_t r0 = FStar_UInt64_eq_mask(a0, (uint64_t)0U);
  uint64_t r1 = FStar_UInt64_eq_mask(a1, (uint64_t)0U);
  uint64_t r2 = FStar_UInt64_eq_mask(a2, (uint64_t)0U);
  uint64_t r3 = FStar_UInt64_eq_mask(a3, (uint64_t)0U);
  uint64_t r01 = r0 & r1;
  uint64_t r23 = r2 & r3;
  return r01 & r23;
}

void point_double(uint64_t *p, uint64_t *result, uint64_t *tempBuffer)
{
  uint64_t *s1 = tempBuffer;
  uint64_t *m = tempBuffer + (uint32_t)4U;
  uint64_t *buffer_for_s_m = tempBuffer + (uint32_t)8U;
  uint64_t *buffer_for_x3 = tempBuffer + (uint32_t)32U;
  uint64_t *buffer_for_y3 = tempBuffer + (uint32_t)40U;
  uint64_t *pypz = tempBuffer + (uint32_t)56U;
  uint64_t *x3 = tempBuffer + (uint32_t)60U;
  uint64_t *y3 = tempBuffer + (uint32_t)64U;
  uint64_t *z3 = tempBuffer + (uint32_t)68U;
  uint64_t *p_y = p + (uint32_t)4U;
  uint64_t *p_z = p + (uint32_t)8U;
  uint64_t *px = p;
  uint64_t *py = p + (uint32_t)4U;
  uint64_t *pz = p + (uint32_t)8U;
  uint64_t *yy = buffer_for_s_m;
  uint64_t *xyy = buffer_for_s_m + (uint32_t)4U;
  uint64_t *zzzz = buffer_for_s_m + (uint32_t)8U;
  uint64_t *minThreeZzzz = buffer_for_s_m + (uint32_t)12U;
  uint64_t *xx = buffer_for_s_m + (uint32_t)16U;
  uint64_t *threeXx = buffer_for_s_m + (uint32_t)20U;
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(py, py, yy);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(px, yy, xyy);
  multByFour(xyy, s1);
  quatre(pz, zzzz);
  multByMinusThree(zzzz, minThreeZzzz);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(px, px, xx);
  multByThree(xx, threeXx);
  Hacl_Impl_LowLevel_p256_add(minThreeZzzz, threeXx, m);
  uint64_t *twoS = buffer_for_x3;
  uint64_t *mm = buffer_for_x3 + (uint32_t)4U;
  multByTwo(s1, twoS);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(m, m, mm);
  Hacl_Impl_LowLevel_p256_sub(mm, twoS, x3);
  uint64_t *yyyy = buffer_for_y3;
  uint64_t *eightYyyy = buffer_for_y3 + (uint32_t)4U;
  uint64_t *sx3 = buffer_for_y3 + (uint32_t)8U;
  uint64_t *msx3 = buffer_for_y3 + (uint32_t)12U;
  quatre(p_y, yyyy);
  multByEight(yyyy, eightYyyy);
  Hacl_Impl_LowLevel_p256_sub(s1, x3, sx3);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(m, sx3, msx3);
  Hacl_Impl_LowLevel_p256_sub(msx3, eightYyyy, y3);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(p_y, p_z, pypz);
  multByTwo(pypz, z3);
  memcpy(result, x3, (uint32_t)4U * sizeof x3[0U]);
  memcpy(result + (uint32_t)4U, y3, (uint32_t)4U * sizeof y3[0U]);
  memcpy(result + (uint32_t)8U, z3, (uint32_t)4U * sizeof z3[0U]);
}

static void
copy_point_conditional(
  uint64_t *x3_out,
  uint64_t *y3_out,
  uint64_t *z3_out,
  uint64_t *p,
  uint64_t *maskPoint
)
{
  uint64_t *z = maskPoint + (uint32_t)8U;
  uint64_t mask = isZero_uint64(z);
  uint64_t *p_x = p;
  uint64_t *p_y = p + (uint32_t)4U;
  uint64_t *p_z = p + (uint32_t)8U;
  uint64_t out_0 = x3_out[0U];
  uint64_t out_10 = x3_out[1U];
  uint64_t out_20 = x3_out[2U];
  uint64_t out_30 = x3_out[3U];
  uint64_t x_00 = p_x[0U];
  uint64_t x_10 = p_x[1U];
  uint64_t x_20 = p_x[2U];
  uint64_t x_30 = p_x[3U];
  uint64_t out_010 = out_0;
  uint64_t out_110 = out_10;
  uint64_t out_210 = out_20;
  uint64_t out_310 = out_30;
  uint64_t x_010 = x_00;
  uint64_t x_110 = x_10;
  uint64_t x_210 = x_20;
  uint64_t x_310 = x_30;
  uint64_t r_00 = out_010 ^ mask & (out_010 ^ x_010);
  uint64_t r_10 = out_110 ^ mask & (out_110 ^ x_110);
  uint64_t r_20 = out_210 ^ mask & (out_210 ^ x_210);
  uint64_t r_30 = out_310 ^ mask & (out_310 ^ x_310);
  uint64_t temp_00 = r_00;
  uint64_t temp_10 = r_10;
  uint64_t temp_20 = r_20;
  uint64_t temp_30 = r_30;
  x3_out[0U] = temp_00;
  x3_out[1U] = temp_10;
  x3_out[2U] = temp_20;
  x3_out[3U] = temp_30;
  uint64_t out_00 = y3_out[0U];
  uint64_t out_12 = y3_out[1U];
  uint64_t out_22 = y3_out[2U];
  uint64_t out_32 = y3_out[3U];
  uint64_t x_02 = p_y[0U];
  uint64_t x_12 = p_y[1U];
  uint64_t x_22 = p_y[2U];
  uint64_t x_32 = p_y[3U];
  uint64_t out_011 = out_00;
  uint64_t out_111 = out_12;
  uint64_t out_211 = out_22;
  uint64_t out_311 = out_32;
  uint64_t x_011 = x_02;
  uint64_t x_111 = x_12;
  uint64_t x_211 = x_22;
  uint64_t x_311 = x_32;
  uint64_t r_01 = out_011 ^ mask & (out_011 ^ x_011);
  uint64_t r_11 = out_111 ^ mask & (out_111 ^ x_111);
  uint64_t r_21 = out_211 ^ mask & (out_211 ^ x_211);
  uint64_t r_31 = out_311 ^ mask & (out_311 ^ x_311);
  uint64_t temp_01 = r_01;
  uint64_t temp_11 = r_11;
  uint64_t temp_21 = r_21;
  uint64_t temp_31 = r_31;
  y3_out[0U] = temp_01;
  y3_out[1U] = temp_11;
  y3_out[2U] = temp_21;
  y3_out[3U] = temp_31;
  uint64_t out_02 = z3_out[0U];
  uint64_t out_1 = z3_out[1U];
  uint64_t out_2 = z3_out[2U];
  uint64_t out_3 = z3_out[3U];
  uint64_t x_0 = p_z[0U];
  uint64_t x_1 = p_z[1U];
  uint64_t x_2 = p_z[2U];
  uint64_t x_3 = p_z[3U];
  uint64_t out_01 = out_02;
  uint64_t out_11 = out_1;
  uint64_t out_21 = out_2;
  uint64_t out_31 = out_3;
  uint64_t x_01 = x_0;
  uint64_t x_11 = x_1;
  uint64_t x_21 = x_2;
  uint64_t x_31 = x_3;
  uint64_t r_0 = out_01 ^ mask & (out_01 ^ x_01);
  uint64_t r_1 = out_11 ^ mask & (out_11 ^ x_11);
  uint64_t r_2 = out_21 ^ mask & (out_21 ^ x_21);
  uint64_t r_3 = out_31 ^ mask & (out_31 ^ x_31);
  uint64_t temp_0 = r_0;
  uint64_t temp_1 = r_1;
  uint64_t temp_2 = r_2;
  uint64_t temp_3 = r_3;
  z3_out[0U] = temp_0;
  z3_out[1U] = temp_1;
  z3_out[2U] = temp_2;
  z3_out[3U] = temp_3;
}

uint64_t compare_felem(uint64_t *a, uint64_t *b)
{
  uint64_t a_0 = a[0U];
  uint64_t a_1 = a[1U];
  uint64_t a_2 = a[2U];
  uint64_t a_3 = a[3U];
  uint64_t b_0 = b[0U];
  uint64_t b_1 = b[1U];
  uint64_t b_2 = b[2U];
  uint64_t b_3 = b[3U];
  uint64_t r_0 = FStar_UInt64_eq_mask(a_0, b_0);
  uint64_t r_1 = FStar_UInt64_eq_mask(a_1, b_1);
  uint64_t r_2 = FStar_UInt64_eq_mask(a_2, b_2);
  uint64_t r_3 = FStar_UInt64_eq_mask(a_3, b_3);
  uint64_t r01 = r_0 & r_1;
  uint64_t r23 = r_2 & r_3;
  return r01 & r23;
}

void point_add(uint64_t *p, uint64_t *q, uint64_t *result, uint64_t *tempBuffer)
{
  uint64_t *z1 = p + (uint32_t)8U;
  uint64_t *z2 = q + (uint32_t)8U;
  uint64_t *tempBuffer16 = tempBuffer;
  uint64_t *u11 = tempBuffer + (uint32_t)16U;
  uint64_t *u2 = tempBuffer + (uint32_t)20U;
  uint64_t *s1 = tempBuffer + (uint32_t)24U;
  uint64_t *s2 = tempBuffer + (uint32_t)28U;
  uint64_t *h = tempBuffer + (uint32_t)32U;
  uint64_t *r = tempBuffer + (uint32_t)36U;
  uint64_t *uh = tempBuffer + (uint32_t)40U;
  uint64_t *hCube = tempBuffer + (uint32_t)44U;
  uint64_t *tempBuffer28 = tempBuffer + (uint32_t)60U;
  uint64_t *x1 = p;
  uint64_t *y1 = p + (uint32_t)4U;
  uint64_t *z11 = p + (uint32_t)8U;
  uint64_t *x2 = q;
  uint64_t *y2 = q + (uint32_t)4U;
  uint64_t *z210 = q + (uint32_t)8U;
  uint64_t *z2Square = tempBuffer16;
  uint64_t *z1Square = tempBuffer16 + (uint32_t)4U;
  uint64_t *z2Cube = tempBuffer16 + (uint32_t)8U;
  uint64_t *z1Cube = tempBuffer16 + (uint32_t)12U;
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(z210, z210, z2Square);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(z11, z11, z1Square);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(z2Square,
    z210,
    z2Cube);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(z1Square,
    z11,
    z1Cube);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(x1, z2Square, u11);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(x2, z1Square, u2);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(y1, z2Cube, s1);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(y2, z1Cube, s2);
  uint64_t one1 = compare_felem(u11, u2);
  uint64_t two = compare_felem(s1, s2);
  uint64_t z1notZero = isZero_uint64(z1);
  uint64_t z2notZero = isZero_uint64(z2);
  uint64_t pointsInf = ~z1notZero & ~z2notZero;
  uint64_t onetwo = one1 & two;
  uint64_t result1 = onetwo & pointsInf;
  bool flag = result1 == (uint64_t)0xffffffffffffffffU;
  if (flag)
    point_double(p, result, tempBuffer);
  else
  {
    uint64_t *temp = tempBuffer16;
    Hacl_Impl_LowLevel_p256_sub(u2, u11, h);
    Hacl_Impl_LowLevel_p256_sub(s2, s1, r);
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(h, h, temp);
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(u11, temp, uh);
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(h, temp, hCube);
    uint64_t *z11 = p + (uint32_t)8U;
    uint64_t *z21 = q + (uint32_t)8U;
    uint64_t *tempBuffer161 = tempBuffer28;
    uint64_t *x3_out1 = tempBuffer28 + (uint32_t)16U;
    uint64_t *y3_out1 = tempBuffer28 + (uint32_t)20U;
    uint64_t *z3_out1 = tempBuffer28 + (uint32_t)24U;
    uint64_t *rSquare = tempBuffer161;
    uint64_t *r_h = tempBuffer161 + (uint32_t)4U;
    uint64_t *twouh = tempBuffer161 + (uint32_t)8U;
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(r, r, rSquare);
    Hacl_Impl_LowLevel_p256_sub(rSquare, hCube, r_h);
    multByTwo(uh, twouh);
    Hacl_Impl_LowLevel_p256_sub(r_h, twouh, x3_out1);
    uint64_t *s1hCube = tempBuffer161;
    uint64_t *u1hx3 = tempBuffer161 + (uint32_t)4U;
    uint64_t *ru1hx3 = tempBuffer161 + (uint32_t)8U;
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(s1, hCube, s1hCube);
    Hacl_Impl_LowLevel_p256_sub(uh, x3_out1, u1hx3);
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(r, u1hx3, ru1hx3);
    Hacl_Impl_LowLevel_p256_sub(ru1hx3, s1hCube, y3_out1);
    uint64_t *z1z2 = tempBuffer161;
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(z11, z21, z1z2);
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(h, z1z2, z3_out1);
    copy_point_conditional(x3_out1, y3_out1, z3_out1, q, p);
    copy_point_conditional(x3_out1, y3_out1, z3_out1, p, q);
    memcpy(result, x3_out1, (uint32_t)4U * sizeof x3_out1[0U]);
    memcpy(result + (uint32_t)4U, y3_out1, (uint32_t)4U * sizeof y3_out1[0U]);
    memcpy(result + (uint32_t)8U, z3_out1, (uint32_t)4U * sizeof z3_out1[0U]);
  }
}

void norm(uint64_t *p, uint64_t *resultPoint, uint64_t *tempBuffer)
{
  uint64_t *xf = p;
  uint64_t *yf = p + (uint32_t)4U;
  uint64_t *zf = p + (uint32_t)8U;
  uint64_t *resultX = resultPoint;
  uint64_t *resultY = resultPoint + (uint32_t)4U;
  uint64_t *resultZ = resultPoint + (uint32_t)8U;
  uint64_t *z2f = tempBuffer + (uint32_t)4U;
  uint64_t *z3f = tempBuffer + (uint32_t)8U;
  uint64_t *tempBuffer20 = tempBuffer + (uint32_t)12U;
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(zf, zf, z2f);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(z2f, zf, z3f);
  Hacl_Spec_P256_MontgomeryMultiplication_exponent(z2f, z2f, tempBuffer20);
  Hacl_Spec_P256_MontgomeryMultiplication_exponent(z3f, z3f, tempBuffer20);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(xf, z2f, z2f);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(yf, z3f, z3f);
  fromDomain(z2f, resultX);
  fromDomain(z3f, resultY);
  resultZ[0U] = (uint64_t)1U;
  resultZ[1U] = (uint64_t)0U;
  resultZ[2U] = (uint64_t)0U;
  resultZ[3U] = (uint64_t)0U;
}

static void zero_buffer(uint64_t *p)
{
  p[0U] = (uint64_t)0U;
  p[1U] = (uint64_t)0U;
  p[2U] = (uint64_t)0U;
  p[3U] = (uint64_t)0U;
  p[4U] = (uint64_t)0U;
  p[5U] = (uint64_t)0U;
  p[6U] = (uint64_t)0U;
  p[7U] = (uint64_t)0U;
  p[8U] = (uint64_t)0U;
  p[9U] = (uint64_t)0U;
  p[10U] = (uint64_t)0U;
  p[11U] = (uint64_t)0U;
}

void
scalarMultiplicationL(uint64_t *p, uint64_t *result, uint8_t *scalar, uint64_t *tempBuffer)
{
  uint64_t *q = tempBuffer;
  zero_buffer(q);
  uint64_t *buff = tempBuffer + (uint32_t)12U;
  pointToDomain(p, result);
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)256U; i = i + (uint32_t)1U)
  {
    uint32_t bit0 = (uint32_t)255U - i;
    uint64_t bit = (uint64_t)(scalar[bit0 / (uint32_t)8U] >> bit0 % (uint32_t)8U & (uint8_t)1U);
    Hacl_Spec_P256_Ladder_cswap(bit, q, result);
    point_add(q, result, result, buff);
    point_double(q, q, buff);
    Hacl_Spec_P256_Ladder_cswap(bit, q, result);
  }
  norm(q, result, buff);
}

void
scalarMultiplicationI(uint64_t *p, uint64_t *result, uint8_t *scalar, uint64_t *tempBuffer)
{
  uint64_t *q = tempBuffer;
  zero_buffer(q);
  uint64_t *buff = tempBuffer + (uint32_t)12U;
  pointToDomain(p, result);
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)256U; i = i + (uint32_t)1U)
  {
    uint32_t bit0 = (uint32_t)255U - i;
    uint64_t bit = (uint64_t)(scalar[bit0 / (uint32_t)8U] >> bit0 % (uint32_t)8U & (uint8_t)1U);
    Hacl_Spec_P256_Ladder_cswap(bit, q, result);
    point_add(q, result, result, buff);
    point_double(q, q, buff);
    Hacl_Spec_P256_Ladder_cswap(bit, q, result);
  }
  norm(q, result, buff);
}

static void uploadBasePoint(uint64_t *p)
{
  p[0U] = (uint64_t)8784043285714375740U;
  p[1U] = (uint64_t)8483257759279461889U;
  p[2U] = (uint64_t)8789745728267363600U;
  p[3U] = (uint64_t)1770019616739251654U;
  p[4U] = (uint64_t)15992936863339206154U;
  p[5U] = (uint64_t)10037038012062884956U;
  p[6U] = (uint64_t)15197544864945402661U;
  p[7U] = (uint64_t)9615747158586711429U;
  p[8U] = (uint64_t)1U;
  p[9U] = (uint64_t)18446744069414584320U;
  p[10U] = (uint64_t)18446744073709551615U;
  p[11U] = (uint64_t)4294967294U;
}

void secretToPublic(uint64_t *result, uint8_t *scalar, uint64_t *tempBuffer)
{
  uint64_t basePoint[12U] = { 0U };
  uploadBasePoint(basePoint);
  uint64_t *q = tempBuffer;
  uint64_t *buff = tempBuffer + (uint32_t)12U;
  zero_buffer(q);
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)256U; i = i + (uint32_t)1U)
  {
    uint32_t bit0 = (uint32_t)255U - i;
    uint64_t bit = (uint64_t)(scalar[bit0 / (uint32_t)8U] >> bit0 % (uint32_t)8U & (uint8_t)1U);
    Hacl_Spec_P256_Ladder_cswap(bit, q, basePoint);
    point_add(q, basePoint, basePoint, buff);
    point_double(q, q, buff);
    Hacl_Spec_P256_Ladder_cswap(bit, q, basePoint);
  }
  norm(q, result, buff);
}

bool isPointAtInfinity(uint64_t *p)
{
  uint64_t z0 = p[8U];
  uint64_t z1 = p[9U];
  uint64_t z2 = p[10U];
  uint64_t z3 = p[11U];
  uint64_t b0 = (uint64_t)0U;
  bool z0_zero = z0 == b0;
  uint64_t b1 = (uint64_t)0U;
  bool z1_zero = z1 == b1;
  uint64_t b2 = (uint64_t)0U;
  bool z2_zero = z2 == b2;
  uint64_t b = (uint64_t)0U;
  bool z3_zero = z3 == b;
  return z0_zero && z1_zero && z2_zero && z3_zero;
}

bool isPointOnCurve(uint64_t *p)
{
  uint64_t y2Buffer[4U] = { 0U };
  uint64_t xBuffer[4U] = { 0U };
  uint64_t *x = p;
  uint64_t *y = p + (uint32_t)4U;
  uint64_t multBuffer0[8U] = { 0U };
  Hacl_Impl_LowLevel_shift_256_impl(y, multBuffer0);
  Hacl_Impl_SolinasReduction_solinas_reduction_impl(multBuffer0, y2Buffer);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(y2Buffer,
    y2Buffer,
    y2Buffer);
  uint64_t xToDomainBuffer[4U] = { 0U };
  uint64_t minusThreeXBuffer[4U] = { 0U };
  uint64_t p256_constant[4U] = { 0U };
  uint64_t multBuffer[8U] = { 0U };
  Hacl_Impl_LowLevel_shift_256_impl(x, multBuffer);
  Hacl_Impl_SolinasReduction_solinas_reduction_impl(multBuffer, xToDomainBuffer);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(xToDomainBuffer,
    xToDomainBuffer,
    xBuffer);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(xBuffer,
    xToDomainBuffer,
    xBuffer);
  multByThree(xToDomainBuffer, minusThreeXBuffer);
  Hacl_Impl_LowLevel_p256_sub(xBuffer, minusThreeXBuffer, xBuffer);
  p256_constant[0U] = (uint64_t)15608596021259845087U;
  p256_constant[1U] = (uint64_t)12461466548982526096U;
  p256_constant[2U] = (uint64_t)16546823903870267094U;
  p256_constant[3U] = (uint64_t)15866188208926050356U;
  Hacl_Impl_LowLevel_p256_sub(xBuffer, p256_constant, xBuffer);
  uint64_t r = compare_felem(y2Buffer, xBuffer);
  uint64_t b = (uint64_t)0U;
  bool z1 = !(r == b);
  return z1;
}

