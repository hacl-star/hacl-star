include "Vale.PPC64LE.InsBasic.vaf"
include "Vale.PPC64LE.InsMem.vaf"
include{:fstar}{:open} "FStar.Seq.Base"
include{:fstar}{:open} "Vale.Def.Words_s"
include{:fstar}{:open} "Vale.Def.Words.Two_s"
include{:fstar}{:open} "Vale.Def.Words.Four_s"
include{:fstar}{:open} "Vale.Def.Types_s"
include{:fstar}{:open} "Vale.PPC64LE.Machine_s"
include{:fstar}{:open} "Vale.PPC64LE.State"
include{:fstar}{:open} "Vale.PPC64LE.Decls"
include{:fstar}{:open} "Vale.PPC64LE.QuickCode"
include{:fstar}{:open} "Vale.PPC64LE.Memory"
include{:fstar}{:open} "Vale.PPC64LE.Memory_Sems"
include{:fstar}{:open} "Vale.Def.Sel"
include{:fstar}{:open} "Spec.SHA2"
include{:fstar}{:open} "Vale.SHA.PPC64LE.SHA_helpers"

module Vale.PPC64LE.InsVector

#verbatim{:interface}
open FStar.Seq
open FStar.Mul
open Vale.Def.Words_s
open Vale.Def.Words.Two_s
open Vale.Def.Words.Four_s
open Vale.Def.Types_s
open Vale.PPC64LE.Machine_s
open Vale.PPC64LE.State
open Vale.PPC64LE.Decls
open Vale.PPC64LE.QuickCode
open Vale.PPC64LE.InsBasic
open Vale.PPC64LE.InsMem
open Vale.PPC64LE.Memory
open Vale.Def.Sel
open Spec.Hash.PadFinish
open Spec.SHA2
open Spec.Hash.Definitions
open Vale.SHA.PPC64LE.SHA_helpers

let buffer128_write (b:buffer128) (i:int) (v:quad32) (h:vale_heap) : Ghost vale_heap
  (requires buffer_readable h b /\ buffer_writeable b)
  (ensures fun _ -> True)
  =
  buffer_write b i v h
#endverbatim

#verbatim
open Vale.Def.Types_s
open Vale.PPC64LE.Machine_s
open Vale.PPC64LE.State
open Vale.PPC64LE.Decls
open Spec.Hash.PadFinish
open Spec.Hash.Definitions
open Spec.SHA2
friend Vale.PPC64LE.Decls
module S = Vale.PPC64LE.Semantics_s
#reset-options "--initial_fuel 2 --max_fuel 4 --max_ifuel 2 --z3rlimit 50"
#endverbatim

function buffer128_write(b:buffer128, i:int, v:quad32, h:vale_heap):vale_heap extern;

var v0:quad32 {:state vec(0)};
var v1:quad32 {:state vec(1)};
var v2:quad32 {:state vec(2)};
var v3:quad32 {:state vec(3)};
var v4:quad32 {:state vec(4)};
var v5:quad32 {:state vec(5)};
var v6:quad32 {:state vec(6)};
var v7:quad32 {:state vec(7)};
var v8:quad32 {:state vec(8)};
var v9:quad32 {:state vec(9)};
var v10:quad32 {:state vec(10)};
var v11:quad32 {:state vec(11)};
var v12:quad32 {:state vec(12)};
var v13:quad32 {:state vec(13)};
var v14:quad32 {:state vec(14)};
var v15:quad32 {:state vec(15)};
var v16:quad32 {:state vec(16)};
var v17:quad32 {:state vec(17)};
var v18:quad32 {:state vec(18)};
var v19:quad32 {:state vec(19)};
var v20:quad32 {:state vec(20)};
var v21:quad32 {:state vec(21)};
var v22:quad32 {:state vec(22)};
var v23:quad32 {:state vec(23)};
var v24:quad32 {:state vec(24)};
var v25:quad32 {:state vec(25)};
var v26:quad32 {:state vec(26)};
var v27:quad32 {:state vec(27)};
var v28:quad32 {:state vec(28)};
var v29:quad32 {:state vec(29)};
var v30:quad32 {:state vec(30)};
var v31:quad32 {:state vec(31)};

// Operands of vector registers
operand_type vec_opr:quad32 @ nat8 :=
| inout v0 | inout v1 | inout v2 | inout v3
| inout v4 | inout v5 | inout v6 | inout v7
| inout v8 | inout v9 | inout v10 | inout v11
| inout v12 | inout v13 | inout v14 | inout v15
| inout v16 | inout v17 | inout v18 | inout v19
| inout v20 | inout v21 | inout v22 | inout v23
| inout v24 | inout v25 | inout v26 | inout v27
| inout v28 | inout v29 | inout v30 | inout v31
;

// Move high 64-bit of vector register to general-purpose register
procedure Mfvsrd(out dst:reg_opr, in src:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Mfvsrd(dst, src))}
    ensures
        dst == hi64(src);
{
    hi64_reveal();
}

// Move low 64-bit of vector register to general-purpose register
procedure Mfvsrld(out dst:reg_opr, in src:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Mfvsrld(dst, src))}
    ensures
        dst == lo64(src);
{
    lo64_reveal();
}

// Move joint of two general-purpose registers to vector register
procedure Mtvsrdd(out dst:vec_opr, in src1:reg_opr, in src2:reg_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Mtvsrdd(dst, src1, src2))}
    ensures
        pow2_32 * dst.hi3 + dst.hi2 == old(src1);
        pow2_32 * dst.lo1 + dst.lo0 == old(src2);
{
}

procedure Vadduwm(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vadduwm(dst, src1, src2))}
    ensures
        dst == old(add_wrap_quad32(src1, src2));
{
}

// XOR operation of two vector registers
procedure Vxor(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vxor(dst, src1, src2))}
    ensures
        dst == old(quad32_xor(src1, src2));
{
}

// Shift left word elements of vector register with correspinding bit values in word elements of vector register
procedure Vslw(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vslw(dst, src1, src2))}
    ensures
        dst == old(Mkfour(
            ishl32(src1.lo0, src2.lo0 % 32),
            ishl32(src1.lo1, src2.lo1 % 32),
            ishl32(src1.hi2, src2.hi2 % 32),
            ishl32(src1.hi3, src2.hi3 % 32)));
{
}

// Shift right word elements of vector register with corresponding bit values in word elements of vector register
procedure Vsrw(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vsrw(dst, src1, src2))}
    ensures
        dst == old(Mkfour(
            ishr32(src1.lo0, src2.lo0 % 32),
            ishr32(src1.lo1, src2.lo1 % 32),
            ishr32(src1.hi2, src2.hi2 % 32),
            ishr32(src1.hi3, src2.hi3 % 32)));
{
}

//  Compare equal word elements of vector register and store either ones or zeros in the corresponding elements of destination register
procedure Vcmpequw(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vcmpequw(dst, src1, src2))}
    ensures
        dst == old(Mkfour(
            if src1.lo0 = src2.lo0 then 0xFFFFFFFF else 0,
            if src1.lo1 = src2.lo1 then 0xFFFFFFFF else 0,
            if src1.hi2 = src2.hi2 then 0xFFFFFFFF else 0,
            if src1.hi3 = src2.hi3 then 0xFFFFFFFF else 0));
{
}

// Joint of last one word of vector register with first 3 words of vector register
procedure Vsldoi(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr, inline count:quad32bytes)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vsldoi(dst, src1, src2, count))}
    requires
        count == 4 || count == 8 || count == 12;
    ensures
        count == 4 ==> dst == old(Mkfour(src2.hi3, src1.lo0, src1.lo1, src1.hi2));
        count == 8 ==> dst == old(Mkfour(src2.hi2, src2.hi3, src1.lo0, src1.lo1));
        count == 12 ==> dst == old(Mkfour(src2.lo1, src2.hi2, src2.hi3, src1.lo0));
{
}

procedure Vmrghw(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vmrghw(dst, src1, src2))}
    ensures
        dst == old(Mkfour(src2.lo1, src1.lo1, src2.hi3, src1.hi3));
{
}

procedure Xxmrghd(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Xxmrghd(dst, src1, src2))}
    ensures
        dst == old(Mkfour(src2.hi2, src2.hi3, src1.hi2, src1.hi3));
{
}

procedure Vsel(out dst:vec_opr, in src1:vec_opr, in src2:vec_opr, in sel:vec_opr)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vsel(dst, src1, src2, sel))}
    ensures
        dst.lo0 == old(isel32(src2.lo0, src1.lo0, sel.lo0));
        dst.lo1 == old(isel32(src2.lo1, src1.lo1, sel.lo1));
        dst.hi2 == old(isel32(src2.hi2, src1.hi2, sel.hi2));
        dst.hi3 == old(isel32(src2.hi3, src1.hi3, sel.hi3));
{
}

procedure Load128_buffer(
        in h:heaplet, out dst:vec_opr, in base:reg_opr, in offset:reg_opr, inline t:taint,
        ghost b:buffer128, ghost index:int)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Load128(dst, base, offset))}
    reads
        memLayout;
    requires
        valid_src_addr(h, b, index);
        valid_layout_buffer(b, memLayout, h, false);
        valid_taint_buf128(b, h, memLayout.vl_taint, t);
        base + offset == buffer_addr(b, h) + 16 * index;
    ensures
        dst == buffer128_read(b, index, h);
{
    low_lemma_load_mem128_full(b, #nat(index), from_heap_impl(this.ms_heap), t, @h);
}

procedure Store128_buffer(
        inout h:heaplet, in src:vec_opr, in base:reg_opr, in offset:reg_opr, inline t:taint,
        ghost b:buffer128, ghost index:int)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Store128(src, base, offset))}
    reads
        memLayout;
    modifies
        mem;
    requires
        valid_dst_addr(h, b, index);
        valid_layout_buffer(b, memLayout, h, true);
        valid_taint_buf128(b, h, memLayout.vl_taint, t);
        base + offset == buffer_addr(b, h) + 16 * index;
    ensures
        h == old(buffer128_write(b, index, src, h));
{
    low_lemma_store_mem128_full(b, #nat(index), old(src), from_heap_impl(old(this).ms_heap), t, @h);
}

procedure Load128_word4_buffer(
        in h:heaplet, out dst:vec_opr, in base:reg_opr, in offset:reg_opr, inline t:taint,
        ghost b:buffer128, ghost index:int)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Load128Word4(dst, base, offset))}
    reads
        memLayout;
    requires
        valid_src_addr(h, b, index);
        valid_layout_buffer(b, memLayout, h, false);
        valid_taint_buf128(b, h, memLayout.vl_taint, t);
        base + offset == buffer_addr(b, h) + 16 * index;
    ensures
        let buf := buffer128_read(b, index, h) in
        dst.lo0 == buf.hi3 /\
        dst.lo1 == buf.hi2 /\
        dst.hi2 == buf.lo1 /\
        dst.hi3 == buf.lo0;
{
    low_lemma_load_mem128_full(b, #nat(index), from_heap_impl(this.ms_heap), t, @h);
}

procedure Store128_word4_buffer(
        inout h:heaplet, in src:vec_opr, in base:reg_opr, in offset:reg_opr, inline t:taint,
        ghost b:buffer128, ghost index:int)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Store128Word4(src, base, offset))}
    reads
        memLayout;
    modifies
        mem;
    requires
        valid_dst_addr(h, b, index);
        valid_layout_buffer(b, memLayout, h, true);
        valid_taint_buf128(b, h, memLayout.vl_taint, t);
        base + offset == buffer_addr(b, h) + 16 * index;
    ensures
        h == old(buffer128_write(b, index, Mkfour(src.hi3, src.hi2, src.lo1, src.lo0), h));
{
    low_lemma_store_mem128_full(b, #nat(index), old(Mkfour(src.hi3, src.hi2, src.lo1, src.lo0)), from_heap_impl(old(this).ms_heap), t, @h);
}

procedure Load128_byte16_buffer(
        in h:heaplet, out dst:vec_opr, in base:reg_opr, in offset:reg_opr, inline t:taint,
        ghost b:buffer128, ghost index:int)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Load128Byte16(dst, base, offset))}
    reads
        memLayout;
    requires
        valid_src_addr(h, b, index);
        valid_layout_buffer(b, memLayout, h, false);
        valid_taint_buf128(b, h, memLayout.vl_taint, t);
        base + offset == buffer_addr(b, h) + 16 * index;
    ensures
        dst == reverse_bytes_quad32(buffer128_read(b, index, h));
{
    low_lemma_load_mem128_full(b, #nat(index), from_heap_impl(this.ms_heap), t, @h);
}

procedure Store128_byte16_buffer(
        inout h:heaplet, in src:vec_opr, in base:reg_opr, in offset:reg_opr, inline t:taint,
        ghost b:buffer128, ghost index:int)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Store128Byte16(src, base, offset))}
    reads
        memLayout;
    modifies
        mem;
    requires
        valid_dst_addr(h, b, index);
        valid_layout_buffer(b, memLayout, h, true);
        valid_taint_buf128(b, h, memLayout.vl_taint, t);
        base + offset == buffer_addr(b, h) + 16 * index;
    ensures
        h == old(buffer128_write(b, index, reverse_bytes_quad32(src), h));
{
    low_lemma_store_mem128_full(b, #nat(index), old(reverse_bytes_quad32(src)), from_heap_impl(old(this).ms_heap), t, @h);
}

procedure SHA256_sigma0(out dst:vec_opr, in src:vec_opr, ghost t:counter, ghost block:block_w)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vshasigmaw0(dst, src))}
    {:typecheck false}
    requires
        16 <= t < size_k_w_256;
        src.hi3 == ws_opaque(block, t-15);
    ensures
        dst.hi3 == sigma_0_0_partial(t, block);
{
    lemma_sha256_sigma0(old(src), t, block);
}

procedure SHA256_sigma1(out dst:vec_opr, in src:vec_opr, ghost t:counter, ghost block:block_w)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vshasigmaw1(dst, src))}
    {:typecheck false}
    requires
        16 <= t < size_k_w_256;
        src.hi3 == ws_opaque(block, t-2);
    ensures
        dst.hi3 == sigma_0_1_partial(t, block);
{
    lemma_sha256_sigma1(old(src), t, block);
}

procedure SHA256_Sigma0(out dst:vec_opr, in src:vec_opr, ghost t:counter, ghost block:block_w, ghost hash_orig:hash256)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vshasigmaw2(dst, src))}
    requires
        t < size_k_w_256;
        src.hi3 == word_to_nat32(index(#(seq(Vale.SHA.PPC64LE.SHA_helpers.word))(repeat_range_vale(t, block, hash_orig)), 0));
    ensures
        dst.hi3 == sigma_1_0_partial(t, block, hash_orig);
{
    lemma_sha256_sigma2(old(src), t, block, hash_orig);
}

procedure SHA256_Sigma1(out dst:vec_opr, in src:vec_opr, ghost t:counter, ghost block:block_w, ghost hash_orig:hash256)
    {:public}
    {:quick exportOnly}
    {:instruction Ins(S.Vshasigmaw3(dst, src))}
    requires
        t < size_k_w_256;
        src.hi3 == word_to_nat32(index(#(seq(Vale.SHA.PPC64LE.SHA_helpers.word))(repeat_range_vale(t, block, hash_orig)), 4));
    ensures
        dst.hi3 == sigma_1_1_partial(t, block, hash_orig);
{
    lemma_sha256_sigma3(old(src), t, block, hash_orig);
}
