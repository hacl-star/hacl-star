///////////////////////////////////////////////////////////////////////////////
//
// Based on poly1305-x86_64.pl from OpenSSL 1.1.1-dev
// See https://github.com/openssl/openssl/blob/master/crypto/poly1305/asm/poly1305-x86_64.pl
// The original file contains the following notices:
//
// # ====================================================================
// # Copyright 2016 The OpenSSL Project Authors. All Rights Reserved.
// #
// # Licensed under the OpenSSL license (the "License").  You may not use
// # this file except in compliance with the License.  You can obtain a copy
// # in the file LICENSE in the source distribution or at
// # https://www.openssl.org/source/license.html
// #
// # ====================================================================
// # Written by Andy Polyakov <appro@openssl.org> for the OpenSSL
// # project. The module is, however, dual licensed under OpenSSL and
// # CRYPTOGAMS licenses depending on where you obtain it. For further
// # details see http://www.openssl.org/~appro/cryptogams/.
// # ====================================================================
//
///////////////////////////////////////////////////////////////////////////////

include "../../../../arch/x64/Vale.X64.InsBasic.vaf"
include "../../../../arch/x64/Vale.X64.InsMem.vaf"
include "../../../../arch/x64/Vale.X64.InsStack.vaf"
include{:fstar}{:open} "Vale.Def.Types_s"
include{:fstar}{:open} "Vale.Arch.Types"
include{:fstar}{:open} "Vale.X64.Machine_s"
include{:fstar}{:open} "Vale.X64.Memory"
include{:fstar}{:open} "Vale.X64.Stack_i"
include{:fstar}{:open} "Vale.X64.State"
include{:fstar}{:open} "Vale.X64.Decls"
include{:fstar}{:open} "Vale.X64.QuickCode"
include{:fstar}{:open} "Vale.Poly1305.Spec_s"
include{:fstar}{:open} "Vale.Poly1305.Math"
include{:fstar}{:open} "Vale.Poly1305.Util"

module Vale.Poly1305.X64

#reset-options "--z3rlimit 40"

#verbatim{:interface}{:implementation}
open Vale.Def.Opaque_s
open Vale.Def.Types_s
open Vale.Arch.Types
open Vale.Arch.HeapImpl
open Vale.X64.Machine_s
open Vale.X64.Memory
open Vale.X64.Stack_i
open Vale.X64.State
open Vale.X64.Decls
open Vale.X64.InsBasic
open Vale.X64.InsMem
open Vale.X64.InsStack
open Vale.X64.QuickCode
open Vale.X64.QuickCodes
open Vale.Poly1305.Spec_s
open Vale.Poly1305.Math
open Vale.Poly1305.Util
#endverbatim

procedure Poly1305_multiply(ghost r1:nat64) returns(ghost hh:int)
    {:quick}
    lets
        d1 @= r8; d2 @= r9; d3 @= r10; r0 @= r11; s1 @= r13; h0 @= r14; h1 @= rbx; h2 @= rbp;
        n := pow2_64;
        p := n * n * 4 - 5;
        r := r1 * n + r0;
        h := h2 * (n * n) + h1 * n + h0;
    reads
        r11; r13;
    modifies
        r8; r9; r10; r14; rbx; rbp;
        rax; rdx;
        efl;
    requires
        r1 % 4 == 0;
        s1 == r1 + r1 / 4;
        h2 * r0 < 7 * (n / 16);
        h0 * r1 < n * (n / 16);
        h1 * r0 < n * (n / 16);
        h2 * s1 < n * (n / 8);
        h0 * r0 < n * (n / 16);
        h1 * s1 < n * (n / 8);
        h2 * s1 < 7 * (5 * n / 64);
        rax == r1;
    ensures
        hh == (n * n) * d3 + n * h1 + h0;
        (h * r) % p == hh % p;
        d3 / 4 * 4 + d3 / 4 < 0x1_0000_0000_0000_0000;
        rax == 0xffff_ffff_ffff_fffc;
{
    assert h0 * r1 == r1 * h0;
    assert r0 * h0 == h0 * r0;
    assert r0 * h1 == h1 * r0;
    //assert r0 * h2 == h2 * r0;
    assert s1 * h1 == h1 * s1;
    //assert s1 * h2 == h2 * s1;

    // TODO: Vale infers a more precise type than int, but F* needs either nonlinear arithmetic or more assistance to accept the inferred type
    let gd0:int := h0 * r0 + h1 * s1;
    let gd1:int := h0 * r1 + h1 * r0 + h2 * s1;
    let gd2:int := h2 * r0;

    assert va_is_src_opr64(va_op_opr64_reg64(rR14), this); // TODO: get rid of this
    Mul64Wrap(h0);  // h0*r1
    Mov64(d2, rax);
    Mov64(rax, r0);
    Mov64(d3, rdx);
    //assert n * d3 + d2 == old(h0 * r1);

    Mul64Wrap(h0);  // h0*r0
    Mov64(h0, rax); // future h0
    Mov64(rax, r0);
    Mov64(d1, rdx);
    //assert n * d1 + h0 == old(h0 * r0);

    Mul64Wrap(h1);  // h1*r0
    Add64Wrap(d2, rax);
    Mov64(rax, s1);
    Adc64Wrap(d3, rdx);
    //assert n * d3 + d2 == old(h0 * r1 + h1 * r0);

    Mul64Wrap(h1);  // h1*s1
    Mov64(h1, h2);  // borrow h1
    Add64Wrap(h0, rax);
    Adc64Wrap(d1, rdx);
    //assert n * d1 + h0 == old(h0 * r0 + h1 * s1);

    IMul64(h1, s1); // h2*s1
    Add64Wrap(d2, h1);
    Mov64(h1, d1);
    Adc64Wrap(d3, 0);
    //assert n * d3 + d2 == old(h0 * r1 + h1 * r0 + h2 * s1);

    IMul64(h2, r0); // h2*r0
    //assert h2 == gd2;
    Add64Wrap(h1, d2);
    Mov64(rax, 0xffff_ffff_ffff_fffc); // mask value
    Adc64Wrap(d3, h2);

    hh := (n * n) * d3 + n * h1 + h0;
    //assert hh == gd2 * (n * n) + gd1 * n + gd0;
    lemma_poly_multiply(n, p, r, h, r0, r1, old(h0), old(h1), old(h2), s1, gd0, gd1, gd2, hh);
}

procedure Poly1305_reduce() returns(ghost hh:int)
    {:quick}
    lets
        d3 @= r10; h0 @= r14; h1 @= rbx; h2 @= rbp;
        n := 0x1_0000_0000_0000_0000;
        p := n * n * 4 - 5;
        hd := (n * n) * d3 + n * h1 + h0;
    modifies
        rax; d3; h0; h1; h2; efl;
    requires
        d3 / 4 * 4 + d3 / 4 < n;
        rax == 0xffff_ffff_ffff_fffc;
    ensures
        hh == (n * n) * h2 + n * h1 + h0;
        hd % p == hh % p;
        h2 < 5;
{
    lemma_poly_bits64();

    And64(rax, d3);
    Mov64(h2, d3);
    Shr64(d3, 2);
    And64(h2, 3);
    Add64Wrap(rax, d3);
    Add64Wrap(h0, rax);
    Adc64Wrap(h1, 0);
    Adc64Wrap(h2, 0);

    let h10 := n * old(h1) + old(h0);
    hh := h10 + rax + (old(d3) % 4) * (n * n);
    lemma_poly_reduce(n, p, hd, old(d3), h10, rax, hh);
}

procedure Poly1305_iteration(ghost r1:nat64) returns(ghost hh:int)
    {:quick}
    lets
        d1 @= r8; d2 @= r9; d3 @= r10; r0 @= r11; s1 @= r13; h0 @= r14; h1 @= rbx; h2 @= rbp;
        n := 0x1_0000_0000_0000_0000;
        p := n * n * 4 - 5;
        r := r1 * n + r0;
        h := h2 * (n * n) + h1 * n + h0;
    reads
        r0; s1;
    modifies
        rax; rdx; d1; d2; d3; h0; h1; h2; efl;
    requires
        r0 < n / 16;
        r1 < n / 16;
        r1 % 4 == 0;
        s1 == r1 + r1 / 4;
        h2 < 7;
        rax == r1;
    ensures
        hh == (n * n) * h2 + n * h1 + h0;
        modp(h * r) == modp(hh);
        h2 < 5;
{
//    Previous version used a forall statement, which isn't yet supported for F*
//    forall(x:nat, xb, y:nat, yb) x < xb && y < yb implies x * y < xb * yb by
//    {
//        lemma_mul_strict_upper_bound(x, xb, y, yb);
//    }

    lemma_mul_strict_upper_bound(h2, 7, r0, n / 16);
    lemma_mul_strict_upper_bound(h0, n, r1, n / 16);
    lemma_mul_strict_upper_bound(h1, n, r0, n / 16);
    lemma_mul_strict_upper_bound(h2, n, s1, n / 8);
    lemma_mul_strict_upper_bound(h0, n, r0, n / 16);
    lemma_mul_strict_upper_bound(h1, n, s1, n / 8);
    lemma_mul_strict_upper_bound(h2, 7, s1, 5 * n / 64);

    let hd := Poly1305_multiply(r1);
    hh := Poly1305_reduce();
    reveal modp;
    assert hh == (n * n) * h2 + n * h1 + h0 /\ (h * r) % p == hh % p;
}

procedure Poly1305_blocks(
        ghost r:int,
        ghost h_in:int,
        ghost ctx_b:buffer64,
        ghost inp_b:buffer64)
    returns(
        ghost h:int)
    {:quick}
    lets
        ctx @= rdi; inp @= rsi; len @= rdx; padbit @= rcx; d1 @= r8; d2 @= r9; d3 @= r10;
        r0 @= r11; r1 @= r12; s1 @= r13; h0 @= r14; h1 @= rbx; h2 @= rbp;
        n := pow2_64;
        p := n * n * 4 - 5;
    reads
        ctx; padbit; memLayout; heap0;
    modifies
        inp; len; d1; d2; d3; r0; r1; s1; h0; h1; h2;
        rax; r15;
        efl;
        heap1;

    requires
        // Len is measured in bytes
        len % 16 == 0; // REVIEW: may be stronger than necessary
        inp + len < pow2_64;
        validDstAddrs64(heap1, ctx, ctx_b, 24, memLayout, Public);
        validSrcAddrs64(heap0, inp, inp_b, len / 8, memLayout, Public);
        let h0_in := buffer64_read(ctx_b, 0, heap1);
        let h1_in := buffer64_read(ctx_b, 1, heap1);
        let h2_in := buffer64_read(ctx_b, 2, heap1);
        let r0_in := buffer64_read(ctx_b, 3, heap1);
        let r1_in := buffer64_read(ctx_b, 4, heap1);
        h_in == h2_in * (n * n) + h1_in * n + h0_in;
        r == r1_in * n + r0_in;
        r0_in < n / 16;
        r1_in < n / 16;
        r1_in % 4 == 0;
        h2_in < 5;
        padbit < 2;
    ensures
        h2 < 5;
        validSrcAddrs64(heap1, ctx, ctx_b, 24, memLayout, Public);
        validSrcAddrs64(heap0, old(inp), inp_b, old(len)/8, memLayout, Public);
        modifies_buffer_specific(ctx_b, old(heap1), heap1, 0, 2);
        h0 == buffer64_read(ctx_b, 0, heap1);
        h1 == buffer64_read(ctx_b, 1, heap1);
        h2 == buffer64_read(ctx_b, 2, heap1);
        r0 == buffer64_read(ctx_b, 3, heap1);
        r1 == buffer64_read(ctx_b, 4, heap1);
        s1 == r1 + r1 / 4;
        inp == old(inp + len);

        // Framing
        rcx == old(rcx);
        ctx == old(ctx); // REVIEW: framing should add this automatically

        let r0_in := buffer64_read(ctx_b, 3, heap1);
        let r1_in := buffer64_read(ctx_b, 4, heap1);
        h == h2 * (pow2_64 * pow2_64) + h1 * pow2_64 + h0;
        modp(h) == poly1305_heap_blocks(modp(h_in), padbit * (n * n), r, buffer64_as_seq(heap0, inp_b), old(len) / 8);
{
    lemma_poly_bits64();

    let length:int := len;

    Shr64(len, 4);  // num_bytes / 16 ==> number of blocks
    // Slight difference: the original code has a special case for len == 0 here.
    // We can let len == 0 pass through because of the slight difference in the loop condition (see below)
    Mov64(r15, len); // reassign len

    Load64_buffer(heap1, r0, ctx, 24, Public, ctx_b, 3); // load r
    Load64_buffer(heap1, s1, ctx, 32, Public, ctx_b, 4);

    Load64_buffer(heap1, h0, ctx, 0, Public, ctx_b, 0); // load hash value
    Load64_buffer(heap1, h1, ctx, 8, Public, ctx_b, 1);
    Load64_buffer(heap1, h2, ctx, 16, Public, ctx_b, 2);

    Mov64(r1, s1);
    Shr64(s1, 2);
    Mov64(rax, r1);
    Add64(s1, r1); // s1 = r1 + (r1 >> 2)

    h := h_in;
    assert modp(h) == poly1305_heap_blocks(modp(h_in), padbit * (n * n), r, buffer64_as_seq(heap0, inp_b), 0) by
    {
        reveal modp;
        reveal_poly1305_heap_blocks(modp(h_in), padbit * (n * n), r, buffer64_as_seq(heap0, inp_b), 0);
    }

    ghost var word_index:nat := 0;

    while (r15 != 0) // Slight difference: the original code uses the zero flag from "len-=16" rather than comparing len to 0
        invariant
            n == pow2_64; // REVIEW: not as good as "let n := pow2_64", because it doesn't let F* substitute pow2_64 for n
            n * n == pow2_64 * pow2_64; // REVIEW: see previous comment
            p == n * n * 4 - 5;
            r == r1 * n + r0;
            h == h2 * (pow2_64 * pow2_64) + h1 * pow2_64 + h0;
            r0 < n / 16;
            r1 < n / 16;
            r1 % 4 == 0;
            s1 == r1 + r1 / 4;
            h2 < 5;
            rax == r1;
            inp + 16 * r15 == old(inp) + length;
            old(inp) + length < pow2_64;
            length == old(len);

            r15 != 0 ==> 8 * (word_index + 1) <= length;
            16 * r15 + 8 * word_index == length;
            inp + 0 /* offset */ == buffer_addr(inp_b, heap0) + 8 * word_index;

            r15 * 16 <= length;    // Not needed with Dafny version
            padbit < 2;            // Not needed with Dafny version
            validDstAddrs64(heap1, ctx, ctx_b, 24, memLayout, Public);
            validSrcAddrs64(heap0, old(inp), inp_b, length/8, memLayout, Public);
            ctx == old(ctx); // REVIEW: framing should add this automatically
            rcx == old(rcx); // REVIEW: framing should add this automatically
            (inp - old(inp)) % 16 == 0;             // Precondition for poly1305_heap_blocks; Not needed in Dafny version
            modp(h) == poly1305_heap_blocks(modp(h_in), padbit * (n * n), r, buffer64_as_seq(heap0, inp_b), word_index);
            heap1 == old(heap1);
        decreases
            r15;
    {
        let nn := pow2_64;
        let hp := h;
        h := h + nn * nn * padbit + nn * buffer64_read(inp_b, word_index + 1, heap0) + buffer64_read(inp_b, word_index, heap0);
        let hq := h;

        Add64Wrap(h0, Mem64(heap0, inp, 0, inp_b, word_index, Public)); // accumulate input
        Adc64Wrap(h1, Mem64(heap0, inp, 8, inp_b, word_index + 1, Public));
        AddLea64(inp, inp, 16);
        Adc64Wrap(h2, padbit);

        assert hq == h2 * (nn * nn) + h1 * nn + h0;

        h := Poly1305_iteration(r1);

        Mov64(rax, r1);
        Sub64(r15, 1); // len-=16
        word_index := word_index + 2;

        assert modp(h) == poly1305_heap_blocks(modp(h_in), padbit * (nn * nn), r, buffer64_as_seq(heap0, inp_b), word_index) by
        {
            reveal_poly1305_heap_blocks(modp(h_in), padbit * (nn * nn), r, buffer64_as_seq(heap0, inp_b), word_index);
            reveal_poly1305_heap_blocks(modp(h_in), padbit * (nn * nn), r, buffer64_as_seq(heap0, inp_b), word_index - 2);
            reveal modp;
            lemma_poly_demod(p, hp, hq - hp, r);
        }
    }
    Store64_buffer(heap1, ctx, h0, 0, Public, ctx_b, 0);
    Store64_buffer(heap1, ctx, h1, 8, Public, ctx_b, 1);
    Store64_buffer(heap1, ctx, h2, 16, Public, ctx_b, 2);
}

#reset-options "--z3rlimit 40"

// last 1..15 bytes, in case len is not a multiple of 16
procedure Poly1305_last_block()
    {:quick}
    lets
        h0 @= r14; h1 @= rbx; h2 @= rbp; r0 @= r11; s1 @= r13; nExtra @= r15;
        n := 0x1_0000_0000_0000_0000;
        p := n * n * 4 - 5;
        r1 := rax;
        r := lowerUpper128(r0, r1);
        hBlocks := lowerUpper192(lowerUpper128(h0, h1), h2);
        inpLast := lowerUpper128(r8, r9);
    reads
        r0; s1; nExtra;
    modifies
        rax; rcx; rdx; r8; r9; r10; h0; h1; h2; efl;
    requires
        h2 < 5;
        r0 < n / 16;
        r1 < n / 16;
        r1 % 4 == 0;
        s1 == r1 + r1 / 4;
        1 <= nExtra < 16;
    ensures
        h2 < 5;
        let padLast := pow2(nExtra * 8);
        let hLast := lowerUpper192(lowerUpper128(h0, h1), h2);
        modp(hLast) == modp((modp(hBlocks) + padLast + (inpLast % padLast)) * r);
{
    let padLast := pow2(nExtra * 8);

    if (nExtra < 8) {
        lemma_bytes_shift_power2(nExtra);
        Mov64(rcx, nExtra);
        Shl64(rcx, 3);
        Mov64(rdx, 1);
        Shl64(rdx, rcx);
        assert rdx == padLast;

        lemma_bytes_and_mod(r8, nExtra);
        //assert iand(r8, shift_left64(1, shift_left64(nExtra, 3)) - 1) == r8 % shift_left64(1, shift_left64(nExtra, 3));
        assert padLast == shift_left64(1, shift_left64(nExtra, 3));
        lemma_mod_power2_lo(r8, r9, nExtra, pow2(nExtra * 8));
        Mov64(rcx, rdx);
        Sub64(rcx, 1);
        And64(r8, rcx);
        Mov64(r9, 0);
        assert r8 == old(r8) % padLast;
        assert lowerUpper128(r8, r9) == inpLast % padLast;

        // h += (inpLast % padLast)
        Add64Wrap(h0, r8);
        Adc64Wrap(h1, r9);
        Adc64Wrap(h2, 0);

        Add64Wrap(h0, rdx);
        Adc64Wrap(h1, 0);
        Adc64Wrap(h2, 0);
    } else {
        let nExtra8 := #nat8(nExtra - 8);
        lemma_bytes_shift_power2(nExtra8);
        Mov64(rcx, nExtra);
        Sub64(rcx, 8);
        Shl64(rcx, 3);
        Mov64(rdx, 1);
        Shl64(rdx, rcx);

        assert padLast == lowerUpper128(0, rdx) by {
            lemma_power2_add64(8 * nExtra8);
            lowerUpper128_reveal();
        }

        // inpLast := (inpLast % padLast)
        lemma_bytes_and_mod(r9, nExtra8);
        lemma_mod_hi(r8, r9, #nat64(pow2(8 * nExtra8)));
        Mov64(rcx, rdx);
        Sub64(rcx, 1);
        And64(r9, rcx);
        assert lowerUpper128(r8, r9) == inpLast % padLast;

        // h += (inpLast % padLast)
        Add64Wrap(h0, r8);
        Adc64Wrap(h1, r9);
        Adc64Wrap(h2, 0);

        Add64Wrap(h0, 0);
        Adc64Wrap(h1, rdx);
        Adc64Wrap(h2, 0);
    }

    let h := hBlocks + (inpLast % padLast) + padLast;
    assert h == h2 * (n * n) + h1 * n + h0 by { lowerUpper192_reveal(); lowerUpper128_reveal(); }
    assert r == r1 * n + r0 by { lowerUpper128_reveal(); }
    let hLast := Poly1305_iteration(r1);
    assert hLast == lowerUpper192(lowerUpper128(h0, h1), h2) by { lowerUpper192_reveal(); lowerUpper128_reveal(); }
    lemma_poly_demod(p, hBlocks, (inpLast % padLast) + padLast, r);
    assert modp(hLast) == modp((modp(hBlocks) + padLast + (inpLast % padLast)) * r) by { reveal modp; }
}

// h := (h % p) % 2^128;
procedure Poly1305_reduce_last()
    {:quick}
    lets
        h0 @= r14; h1 @= rbx; h2 @= rbp;
        h := lowerUpper192(lowerUpper128(h0, h1), h2);
    modifies
        r8; r9; r10; rax; h0; h1; h2; efl;
    requires
        h2 < 5;
    ensures
        lowerUpper128(h0, h1) == mod2_128(modp(h));
{
    lemma_poly_bits64();

    Mov64(r8, h0);
    Mov64(r9, h1);
    Mov64(r10, h2);
    Add64Wrap(r8, 5);
    Adc64Wrap(r9, 0);
    Adc64Wrap(r10, 0);

    assert h + 5 == lowerUpper192(lowerUpper128(r8, r9), r10)
        by { lowerUpper128_reveal(); lowerUpper192_reveal(); }
    lemma_reduce128(h, old(h2), old(h1), old(h0), h + 5, r10, r9, r8);

    Shr64(r10, 2);

    Mov64(rax, r10);
    Sub64Wrap(rax, 1); // mask of ones if h < p, zero otherwise
    //assert rax == (if r10 == 0 then 0xffff_ffff_ffff_ffff else 0);
    And64(h0, rax);
    And64(h1, rax);

    Mov64(rax, 0);
    Sub64Wrap(rax, r10); // mask of ones if p <= h < 2 * p, zero otherwise
    //assert rax == (if r10 == 1 then 0xffff_ffff_ffff_ffff else 0);
    And64(r8, rax);
    And64(r9, rax);

    // Either h1 == h0 == 0 or r9 == r8 == 0; add to select the nonzero one:
    Add64(h0, r8);
    Add64(h1, r9);
}

// h := (h + key_s) % 2^128
procedure Poly1305_add_key_s()
    {:quick}
    lets
        h0 @= r14; h1 @= rbx; key_s0 @= rax; key_s1 @= rdx;
        h_in := lowerUpper128(h0, h1);
        key_s := lowerUpper128(key_s0, key_s1);
    reads
        key_s0; key_s1;
    modifies
        h0; h1; efl;
    ensures
        lowerUpper128(h0, h1) == mod2_128(h_in + key_s);
{
    Add64Wrap(h0, key_s0);
    Adc64Wrap(h1, key_s1);

    lemma_add_key(old(h0), old(h1), h_in, key_s0, key_s1, key_s, h0, h1);
}

#verbatim
// REVIEW: not clear why Vale.Def.TypesNative_s.reveal_iand doesn't work directly
let reveal_logand128 (x y:nat128) : Lemma
  (requires True)
  (ensures Vale.Def.Types_s.iand x y == FStar.UInt.logand #128 x y)
  = Vale.Def.TypesNative_s.reveal_iand 128 x y
#endverbatim
ghost procedure reveal_logand128(ghost x:nat128, ghost y:nat128) {:infer_spec} extern;

procedure Poly1305_impl(
        ghost key_r:nat128,
        ghost key_s:nat128,
        ghost ctx_b:buffer64,
        ghost inp_b:buffer64,
        ghost finish:nat64)
    returns(
        ghost h:int)
    {:quick}
    lets
        ctx @= rdi; inp @= rsi; len @= rdx; r0 @= r11; r1 @= r12; h0 @= r14; h1 @= rbx; h2 @= rbp;
        n := pow2_64;
    reads
        memLayout; heap0;
    modifies
        rax; rcx; rdx; rdi; rsi; rbx; rbp; r8; r9; r10; r11; r12; r13; r14; r15;
        efl;
        heap1;
    requires
        validDstAddrs64(heap1, ctx, ctx_b, 24, memLayout, Public);
        validSrcAddrs64(heap0, inp, inp_b, readable_words(len), memLayout, Public);
        inp + len < pow2_64;
        let h2_in := buffer64_read(ctx_b, 2, heap1);
        let key_r0 := buffer64_read(ctx_b, 3, heap1);
        let key_r1 := buffer64_read(ctx_b, 4, heap1);
        let key_s0 := buffer64_read(ctx_b, 5, heap1);
        let key_s1 := buffer64_read(ctx_b, 6, heap1);
        finish == buffer64_read(ctx_b, 23, heap1);
        key_r == lowerUpper128(key_r0, key_r1);
        key_s == lowerUpper128(key_s0, key_s1);
        h2_in < 5;
        finish < 2;
    ensures
        validSrcAddrs64(heap1, ctx, ctx_b, 24, memLayout, Public);
        modifies_buffer_specific(ctx_b, old(heap1), heap1, 0, 8);
        let h0_in := buffer64_read(ctx_b, 0, old(heap1));
        let h1_in := buffer64_read(ctx_b, 1, old(heap1));
        let h2_in := buffer64_read(ctx_b, 2, old(heap1));
        let h_in := lowerUpper192(lowerUpper128(h0_in, h1_in), h2_in);
        let inp_mem := seqTo128(buffer64_as_seq(heap0, inp_b));
        finish == 0 ==> h == lowerUpper192(lowerUpper128(h0, h1), h2);
        finish == 0 ==>
            modp(h) == poly1305_hash_blocks(modp(h_in), n * n, make_r(key_r), inp_mem, old(len) / 16);
        finish == 0 ==> h2 < 5;
        finish == 1 ==> h == lowerUpper128(h0, h1);
        finish == 1 ==> h == poly1305_hash_all(modp(h_in), key_r, key_s, inp_mem, old(len));
        ctx == old(ctx);
{
    let inp_in := inp;
    let len_in := len;
    let h0_in := buffer64_read(ctx_b, 0, heap1);
    let h1_in := buffer64_read(ctx_b, 1, heap1);
    let h2_in := buffer64_read(ctx_b, 2, heap1);
    let h_in := lowerUpper192(lowerUpper128(h0_in, h1_in), h2_in);
    let key_r0 := buffer64_read(ctx_b, 3, heap1);
    let key_r1 := buffer64_read(ctx_b, 4, heap1);
    lemma_poly_bits64();

    Load64_buffer(heap1, r0, ctx, 24, Public, ctx_b, 3);
    Load64_buffer(heap1, r1, ctx, 32, Public, ctx_b, 4);
    Mov64(rcx, 0x0fff_fffc_0fff_ffff);
    And64(r0, rcx);
    Mov64(rcx, 0x0fff_fffc_0fff_fffc);
    And64(r1, rcx);
    Store64_buffer(heap1, ctx, r0, 24, Public, ctx_b, 3);
    Store64_buffer(heap1, ctx, r1, 32, Public, ctx_b, 4);

    let r:nat128 := lowerUpper128(r0, r1);
    assert r == r0 + n * r1 by { lowerUpper128_reveal(); }

    let mask:nat128 := 0x0ffffffc_0ffffffc_0ffffffc_0fffffff; // REVIEW: why do we need to put this constant in a variable?
    assert r == iand128(key_r, mask) by
    {
        lowerUpper128_reveal();
        lemma_lowerUpper128_and(key_r, key_r0, key_r1, mask,
            0x0fff_fffc_0fff_ffff, 0x0fff_fffc_0fff_fffc, r, r0, r1);
    }

    Mov64(rax, len);
    And64(rax, 15);
    Sub64(len, rax);
    // assert rax == len_in % 16;
    // assert len == len_in / 16 * 16; == (num 16-byte blocks) * 16
    Store64_buffer(heap1, ctx, rax, 56, Public, ctx_b, 7);
    Store64_buffer(heap1, ctx, len, 64, Public, ctx_b, 8);

    Mov64(rcx, 1);
    assert h_in == h2_in * (n * n) + h1_in * n + h0_in by { lowerUpper128_reveal(); lowerUpper192_reveal(); }
    h := Poly1305_blocks(r, h_in, ctx_b, inp_b);
    assert h == lowerUpper192(lowerUpper128(h0, h1), h2)
        by { lowerUpper192_reveal(); lowerUpper128_reveal(); }
    lemma_poly1305_heap_hash_blocks_alt(modp(h_in), n * n, r, heap0, inp_b, old(len) / 16);

    Load64_buffer(heap1, rax, ctx, 184, Public, ctx_b, 23);
    if (rax == 1) // finish == 1
    {
        reveal_logand128(key_r, mask);
        assert r == bare_r(key_r);

        Load64_buffer(heap1, r15, ctx, 56, Public, ctx_b, 7);
        // assert r15 == len_in % 16;
        if (r15 != 0)
        {
            Load64_buffer(heap1, rax, ctx, 32, Public, ctx_b, 4);
            Load64_buffer(heap0, r8, inp, 0, Public, inp_b, (len_in / 16) * 2);
            Load64_buffer(heap0, r9, inp, 8, Public, inp_b, (len_in / 16) * 2 + 1);
            let a := seqTo128_app(buffer64_as_seq(heap0, inp_b), len_in / 16);
            assert lowerUpper128(r8, r9) == a
                by { lowerUpper128_reveal(); }
            Poly1305_last_block();
            h := lowerUpper192(lowerUpper128(h0, h1), h2);
        }

        lemma_add_mod128(modp(h), key_s);
        Poly1305_reduce_last();
        h := lowerUpper128(h0, h1);

        Load64_buffer(heap1, rax, ctx, 40, Public, ctx_b, 5);
        Load64_buffer(heap1, rdx, ctx, 48, Public, ctx_b, 6);
        Poly1305_add_key_s();
        h := lowerUpper128(h0, h1);

        assert h == poly1305_hash_all(modp(h_in), key_r, key_s, seqTo128(buffer64_as_seq(heap0, inp_b)), len_in)
            by { reveal mod2_128; reveal modp; }
    }
}

// Poly1305(ctx, inp, len, finish)
//
// Note that this reads 16-byte chunks directly from the input buffer,
// so (len + 15) / 16 * 16 bytes must be readable, even though only len bytes
// affect the result.
procedure Poly1305(
        inline win:bool,
        ghost ctx_b:buffer64,
        ghost inp_b:buffer64,
        ghost len_in:nat64,
        ghost finish_in:nat64)
    {:public}
    {:quick}
    {:exportSpecs}
    lets
        ctx @= rdi; inp @= rsi; len @= rdx; finish @= rcx;
        h0 @= r14; h1 @= rbx; h2 @= rbp;
        ctx_in := (if win then rcx else ctx);
        inp_in := (if win then rdx else inp);
        n := 0x1_0000_0000_0000_0000;
        p := n * n * 4 - 5;
    reads
        heap0;
    modifies
        rax; rbx; rcx; rdx; rsi; rdi; rbp; rsp; r8; r9; r10; r11; r12; r13; r14; r15;
        efl; heap1; memLayout; stack; stackTaint;
    requires
        rsp == init_rsp(stack);
        is_initial_heap(memLayout, mem);

        buffers_disjoint(ctx_b, inp_b);
        validDstAddrs64(mem, ctx_in, ctx_b, 24, memLayout, Public);
        validSrcAddrs64(mem, inp_in, inp_b, readable_words(len_in), memLayout, Public);
        len_in == (if win then r8 else len);
        finish_in == (if win then r9 else finish);
        let h2_in := buffer64_read(ctx_b, 2, mem);
        h2_in < 5;
        inp_in + len_in < pow2_64;
        finish_in < 2;
    ensures
        modifies_buffer(ctx_b, old(mem), mem);

        let h0_in := buffer64_read(ctx_b, 0, old(mem));
        let h1_in := buffer64_read(ctx_b, 1, old(mem));
        let h2_in := buffer64_read(ctx_b, 2, old(mem));
        let key_r0 := buffer64_read(ctx_b, 3, old(mem));
        let key_r1 := buffer64_read(ctx_b, 4, old(mem));
        let key_s0 := buffer64_read(ctx_b, 5, old(mem));
        let key_s1 := buffer64_read(ctx_b, 6, old(mem));
        let h_in := lowerUpper192(lowerUpper128(h0_in, h1_in), h2_in);
        let key_r := lowerUpper128(key_r0, key_r1);
        let key_s := lowerUpper128(key_s0, key_s1);

        let h0_out := buffer64_read(ctx_b, 0, mem);
        let h1_out := buffer64_read(ctx_b, 1, mem);
        let h2_out := buffer64_read(ctx_b, 2, mem);
        let h10 := lowerUpper128(h0_out, h1_out);
        let h210 := lowerUpper192(h10, h2_out);
        let inp_mem := seqTo128(buffer64_as_seq(mem, inp_b));

        finish_in == 0 ==>
            modp(h210) == poly1305_hash_blocks(modp(h_in), n * n, make_r(key_r), inp_mem, len_in / 16);
        finish_in == 0 ==> h2_out < 5;
        finish_in == 1 ==> h10 == poly1305_hash_all(modp(h_in), key_r, key_s, inp_mem, len_in);

        rsp == old(rsp);

        win ==> rdi == old(rdi);
        win ==> rsi == old(rsi);
        rbx == old(rbx);
        rbp == old(rbp);
        r12 == old(r12);
        r13 == old(r13);
        r14 == old(r14);
        r15 == old(r15);
{
    CreateHeaplets(list(
        declare_buffer64(inp_b, 0, Public, Immutable),
        declare_buffer64(ctx_b, 1, Public, Mutable)));

    let key_r0 := buffer64_read(ctx_b, 3, heap1);
    let key_r1 := buffer64_read(ctx_b, 4, heap1);
    let key_s0 := buffer64_read(ctx_b, 5, heap1);
    let key_s1 := buffer64_read(ctx_b, 6, heap1);
    let key_r := lowerUpper128(key_r0, key_r1);
    let key_s := lowerUpper128(key_s0, key_s1);
    Mov64(rax, ctx);
    Mov64(r11, inp);
    inline if (win)
    {
        Mov64(ctx, rcx);
        Mov64(inp, rdx);
        Mov64(len, r8);
        Mov64(finish, r9);
    }
    // assert ctx == ctx_in;
    // assert inp == inp_in;
    // assert len == len_in;
    // assert finish == finish_in;

    // context:
    //   0, 8, 16: will hold h
    //   24, 32: key_r
    //   40, 48: key_s
    //   56: will hold len % 16
    //   64: will hold len / 16 * 16
    //   184: finish
    Store64_buffer(heap1, ctx, finish, 184, Public, ctx_b, 23);

    // Save callee-saved registers
    Push_Secret(h1);
    Push_Secret(h2);
    Push_Secret(rax);
    Push_Secret(r11);
    Push_Secret(r12);
    Push_Secret(r13);
    Push_Secret(h0);
    Push_Secret(r15);

    let h' := Poly1305_impl(key_r, key_s, ctx_b, inp_b, finish_in);

    Store64_buffer(heap1, ctx, h0,  0, Public, ctx_b, 0);
    Store64_buffer(heap1, ctx, h1,  8, Public, ctx_b, 1);
    Store64_buffer(heap1, ctx, h2, 16, Public, ctx_b, 2);

    // Restore callee-saved registers
    Pop_Secret(r15);
    Pop_Secret(h0);
    Pop_Secret(r13);
    Pop_Secret(r12);
    Pop_Secret(inp);
    Pop_Secret(rax);
    Pop_Secret(h2);
    Pop_Secret(h1);

    Mov64(ctx, rax);

    DestroyHeaplets();
}

