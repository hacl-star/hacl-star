include "../../../arch/x64/Vale.X64.InsBasic.vaf"
include "../../../arch/x64/Vale.X64.InsMem.vaf"
include "../../../arch/x64/Vale.X64.InsVector.vaf"
include "../../../arch/x64/Vale.X64.InsAes.vaf"
include "../../../crypto/aes/x64/Vale.AES.X64.PolyOps.vaf"
include{:fstar}{:open} "Vale.Def.Prop_s"
include{:fstar}{:open} "Vale.Def.Opaque_s"
include{:fstar}{:open} "Vale.Def.Words_s"
include{:fstar}{:open} "Vale.Def.Types_s"
include{:/*TODO*/fstar}{:open} "FStar.Seq.Base"
include{:fstar}{:open} "Vale.AES.AES_s"
include{:fstar}{:open} "Vale.X64.Machine_s"
include{:fstar}{:open} "Vale.X64.Memory"
include{:fstar}{:open} "Vale.X64.State"
include{:fstar}{:open} "Vale.X64.Decls"
include{:fstar}{:open} "Vale.X64.QuickCode"
include{:fstar}{:open} "Vale.X64.QuickCodes"
include{:fstar}{:open} "Vale.Arch.Types"
include{:fstar}{:open} "Vale.AES.AES_helpers"
//include{:fstar}{:open} "Vale.Poly1305.Math"
include{:fstar}{:open} "Vale.AES.GCM_helpers"
include{:fstar}{:open} "Vale.AES.GCTR_s"
include{:fstar}{:open} "Vale.AES.GCTR"
include{:fstar}{:open} "Vale.Arch.TypesNative"
include{:fstar}{:open} "Vale.X64.CPU_Features_s"
include{:fstar}{:open} "Vale.Math.Poly2_s"
include{:fstar}{:open} "Vale.Math.Poly2"
include{:fstar}{:open} "Vale.Math.Poly2.Bits_s"
include{:fstar}{:open} "Vale.Math.Poly2.Bits"
include{:fstar}{:open} "Vale.Math.Poly2.Words"
include{:fstar}{:open} "Vale.Math.Poly2.Lemmas"
include{:fstar}{:open} "Vale.AES.GF128_s"
include{:fstar}{:open} "Vale.AES.GF128"
include{:fstar}{:open} "Vale.AES.GHash"
include "Vale.AES.X64.AESopt2.vaf"

module Vale.AES.X64.AESGCM_expected_code

#verbatim{:interface}{:implementation}
open Vale.Def.Prop_s
open Vale.Def.Opaque_s
open Vale.Def.Words_s
open Vale.Def.Types_s
open FStar.Seq
open Vale.AES.AES_s
open Vale.X64.Machine_s
open Vale.X64.Memory
open Vale.X64.State
open Vale.X64.Decls
open Vale.X64.InsBasic
open Vale.X64.InsMem
open Vale.X64.InsVector
open Vale.X64.InsAes
open Vale.X64.QuickCode
open Vale.X64.QuickCodes
open Vale.Arch.Types
open Vale.AES.AES_helpers
//open Vale.Poly1305.Math    // For lemma_poly_bits64()
open Vale.AES.GCM_helpers
open Vale.AES.GCTR_s
open Vale.AES.GCTR
open Vale.Arch.TypesNative
open Vale.X64.CPU_Features_s
open Vale.AES.X64.PolyOps
open Vale.Math.Poly2_s
open Vale.Math.Poly2
open Vale.Math.Poly2.Bits_s
open Vale.Math.Poly2.Bits
open Vale.Math.Poly2.Lemmas
open Vale.AES.GF128_s
open Vale.AES.GF128
open Vale.AES.GHash
open Vale.AES.X64.AESopt2
#endverbatim

#reset-options " --z3rlimit 50"
procedure Loop6x_partial_expected_code(
        inline alg:algorithm,
        ghost h_LE:quad32,
        ghost y_prev:quad32,
        ghost data:seq(quad32),
        ghost count:nat,        // Number of 6x128-bit blocks processed so far
        ghost in0_count:nat,
        ghost iv_b:buffer128,
        ghost in0_b:buffer128,
        ghost in_b:buffer128,
        ghost scratch_b:buffer128,

        ghost key_words:seq(nat32),
        ghost round_keys:seq(quad32),
        ghost keys_b:buffer128,
        ghost hkeys_b:buffer128,

        //ghost ctr_BE_orig:quad32,
        ghost ctr_BE:quad32)
    returns(
        ghost init0:quad32,
        ghost init1:quad32,
        ghost init2:quad32,
        ghost init3:quad32,
        ghost init4:quad32,
        ghost init5:quad32)
    {:codeOnly}
    {:public}
    lets
//      inp @= rdi; outp @= rsi; len @= rdx; key @= rcx; ivp @= r8; Xip @= r9;
        inp @= rdi; key @= rcx; ivp @= r8; Xip @= r9;
        Ii @= xmm0; T1 @= xmm1; T2 @= xmm2; Hkey @= xmm3;
        Z0 @= xmm4; Z1 @= xmm5; Z2 @= xmm6; Z3 @= xmm7; Xi @= xmm8;
        inout0 @= xmm9; inout1 @= xmm10; inout2 @= xmm11; inout3 @= xmm12;
        inout4 @= xmm13; inout5 @= xmm14; rndkey @= xmm15;
//      counter @= rbx; rounds @= rbp; ret @= r10; constp @= r11; in0 @= r14; end0 @= r15;
        counter @= rbx; constp @= r11; in0 @= r14;
        h := of_quad32(reverse_bytes_quad32(h_LE));
        prev := of_quad32(reverse_bytes_quad32(y_prev));
{
    init0 := inout0;
    init1 := quad32_xor(reverse_bytes_quad32(inc32lite(ctr_BE, 1)), rndkey);
    init2 := quad32_xor(reverse_bytes_quad32(inc32lite(ctr_BE, 2)), rndkey);
    init3 := quad32_xor(reverse_bytes_quad32(inc32lite(ctr_BE, 3)), rndkey);
    init4 := quad32_xor(reverse_bytes_quad32(inc32lite(ctr_BE, 4)), rndkey);
    init5 := quad32_xor(reverse_bytes_quad32(inc32lite(ctr_BE, 5)), rndkey);

    /* Loop6x_preamble */

    // OpenSSL does this with "add `6<<24`,counter", followed by jc,
    // which handles wrap and control flow more efficiently
    Add64(counter, 6);
    if (counter >= 256) {
        InitPshufbMask(Ii, constp);  // # borrow $Ii for .Lbswap_mask
        VPshufb(Z2, T1, Ii);         // # byte-swap counter
        // OpenSSL uses a memory operand with VPaddd to do the addition with .Lone_lsb.  We avoid that here for now.
        //Load_two_lsb();              // # borrow $Z1, .Ltwo_lsb
        //Load_one_lsb();              // # .Lone_lsb
        ZeroXmm(Z1);
        PinsrqImm(Z1, 1, 0, constp);
        VPaddd(inout1, Z2, Z1);
        ZeroXmm(Z1);
        PinsrqImm(Z1, 2, 0, constp);
        VPaddd(inout2, Z2, Z1);
        Load128_buffer(heap0, Hkey, Xip, 0x00-0x20, Secret, hkeys_b, 0);   // # $Hkey^1
        VPaddd(inout3, inout1, Z1);
        VPshufb(inout1, inout1, Ii);
        VPaddd(inout4, inout2, Z1);
        VPshufb(inout2, inout2, Ii);
        VPxor(inout1, inout1, rndkey);
        VPaddd(inout5, inout3, Z1);
        VPshufb(inout3, inout3, Ii);
        VPxor(inout2, inout2, rndkey);
        VPaddd(T1, inout4, Z1);         // # byte-swapped next counter value
        VPshufb(inout4, inout4, Ii);
        VPshufb(inout5, inout5, Ii);
        VPshufb(T1, T1, Ii);            // # next counter value

        Sub64(counter, 256);
    } else {
        Load128_buffer(heap0, Hkey, Xip, 0x00-0x20, Secret, hkeys_b, 0);   // # $Hkey^1
        VPaddd(T1, T2, inout5); // OpenSSL uses VPaddb
        VPxor(inout1, inout1, rndkey);
        VPxor(inout2, inout2, rndkey);
    }

    Store128_buffer(heap3, rbp, T1, 0x80, Secret, scratch_b, 8);   // # save next counter value
    VPolyMul(Z1, Z3, Hkey, false, true);
    VPxor(inout3, inout3, rndkey);
    Load128_buffer(heap0, T2, key, 0x10-0x80, Secret, keys_b, 1); // # borrow $T2 for $rndkey
    VPolyMul(Z2, Z3, Hkey, true, false);
    VAESNI_enc(inout0, inout0, T2);
    Load128_buffer(heap3, Ii, rbp, 0x30, Secret, scratch_b, 3);     // # I[4]
    VPxor(inout4, inout4, rndkey);
    VPolyMul(T1, Z3, Hkey, false, false);
    VAESNI_enc(inout1, inout1, T2);
    VPxor(inout5, inout5, rndkey);
    VPolyMul(Z3, Z3, Hkey, true, true);
    VAESNI_enc(inout2, inout2, T2);
    Load128_buffer(heap0, Hkey, Xip, 0x10-0x20, Secret, hkeys_b, 1);   // # $Hkey^2
    VAESNI_enc(inout3, inout3, T2);
    VPolyAdd(Z2, Z2, Z1);
    VPolyMul(Z1, Ii, Hkey, false, false);
    VPolyAdd(Xi, Xi, Z0);      // # modulo-scheduled
    VAESNI_enc(inout4, inout4, T2);
    VPolyAdd(Z0, T1, Z1);
    //Load128_buffer(heap0, rndkey, key, 0x20-0x80, Secret, keys_b, 2);      // OpenSSL had this here.  I moved it to one of the Loop6x_step calls
    VPolyMul(T1, Ii, Hkey, false, true);
    VAESNI_enc(inout5, inout5, T2);

    /* Loop6x_step1 */

    Load128_buffer(heap0, rndkey, key, (0x10 * (1 + 1))-0x80, Secret, keys_b, 1 + 1);
    VPolyMul(T2, Ii, Hkey, true, false);
    VAESNI_enc(inout0, inout0, rndkey);
    VPolyAdd(Xi, Xi, Mem128(heap3, rbp, 0x10, Secret, scratch_b, 1));  // # modulo-scheduled [vpxor $Z3,$Xi,$Xi]
    VPolyMul(Hkey, Ii, Hkey, true, true);
    Load128_buffer(heap3, Ii, rbp, 0x40, Secret, scratch_b, 4);
    VAESNI_enc(inout1, inout1, rndkey);
    LoadBe64_buffer128(heap1, r13, in0, 5*16+8, Secret, true,  in0_b, in0_count*6 + 5);
    VAESNI_enc(inout2, inout2, rndkey);
    LoadBe64_buffer128(heap1, r12, in0, 5*16,   Secret, false, in0_b, in0_count*6 + 5);
    VAESNI_enc(inout3, inout3, rndkey);
    Store64_buffer128(heap3, rbp, r13, 2*16,   Secret, false, scratch_b, 2);  // OpenSSL is further offset by 8 (to account for return addr?)
    VAESNI_enc(inout4, inout4, rndkey);
    Store64_buffer128(heap3, rbp, r12, 2*16+8, Secret, true,  scratch_b, 2);   // OpenSSL is further offset by 8 (to account for return addr?)
    Load128_buffer(heap0, Z1, Xip, 0x30-0x20, Secret, hkeys_b, 3);  // # borrow $Z1 for $Hkey^3
    VAESNI_enc(inout5, inout5, rndkey);

    /* Loop6x_plain */

    Load128_buffer(heap0, rndkey, key, 16*(2 + 1)-0x80, Secret, keys_b, 2 + 1);
    VPolyAdd(Z2, Z2, T1);
    VPolyMul(T1, Ii, Z1, false, false);
    VAESNI_enc(inout0, inout0, rndkey);
    VPolyAdd(Z2, Z2, T2);
    VPolyMul(T2, Ii, Z1, false, true);
    VAESNI_enc(inout1, inout1, rndkey);
    VPolyAdd(Z3, Z3, Hkey);
    VPolyMul(Hkey, Ii, Z1, true, false);
    VAESNI_enc(inout2, inout2, rndkey);
    VPolyMul(Z1, Ii, Z1, true, true);
    Load128_buffer(heap3, Ii, rbp, 0x50, Secret, scratch_b, 5);
    VAESNI_enc(inout3, inout3, rndkey);
    VAESNI_enc(inout4, inout4, rndkey);
    VPolyAdd(Z0, Z0, T1);
    Load128_buffer(heap0, T1, Xip, 0x40-0x20, Secret, hkeys_b, 4);  // # borrow $T1 for $Hkey^4
    VAESNI_enc(inout5, inout5, rndkey);

    /* Loop6x_step2 */

    Load128_buffer(heap0, rndkey, key, (0x10 * (3 + 1))-0x80, Secret, keys_b, 3 + 1);
    VPolyAdd(Z2, Z2, T2);
    VPolyMul(T2, Ii, T1, false, false);
    VAESNI_enc(inout0, inout0, rndkey);
    VPolyAdd(Z2, Z2, Hkey);
    VPolyMul(Hkey, Ii, T1, false, true);
    VAESNI_enc(inout1, inout1, rndkey);
    LoadBe64_buffer128(heap1, r13, in0, 4*16+8, Secret, true,  in0_b, in0_count*6 + 4);
    VPolyAdd(Z3, Z3, Z1);
    VPolyMul(Z1, Ii, T1, true, false);
    VAESNI_enc(inout2, inout2, rndkey);
    LoadBe64_buffer128(heap1, r12, in0, 4*16,   Secret, false, in0_b, in0_count*6 + 4);
    VPolyMul(T1, Ii, T1, true, true);
    Load128_buffer(heap3, Ii, rbp, 0x60, Secret, scratch_b, 6); // # I[1]
    VAESNI_enc(inout3, inout3, rndkey);
    Store64_buffer128(heap3, rbp, r13, 3*16,   Secret, false, scratch_b, 3);  // OpenSSL is further offset by 8 (to account for return addr?)
    VAESNI_enc(inout4, inout4, rndkey);
    Store64_buffer128(heap3, rbp, r12, 3*16+8, Secret, true,  scratch_b, 3);   // OpenSSL is further offset by 8 (to account for return addr?)
    VPolyAdd(Z0, Z0, T2);
    Load128_buffer(heap0, T2, Xip, 0x60-0x20, Secret, hkeys_b, 6);  // # borrow $T1 for $Hkey^5
    VAESNI_enc(inout5, inout5, rndkey);

    /* Loop6x_step3 */

    Load128_buffer(heap0, rndkey, key, (0x10 * (4 + 1))-0x80, Secret, keys_b, 4 + 1);
    VPolyAdd(Z2, Z2, Hkey);
    VPolyMul(Hkey, Ii, T2, false, false);
    VAESNI_enc(inout0, inout0, rndkey);
    VPolyAdd(Z2, Z2, Z1);
    VPolyMul(Z1, Ii, T2, false, true);
    VAESNI_enc(inout1, inout1, rndkey);
    LoadBe64_buffer128(heap1, r13, in0, 3*16+8, Secret, true,  in0_b, in0_count*6 + 3);
    VPolyAdd(Z3, Z3, T1);
    VPolyMul(T1, Ii, T2, true, false);
    VPolyAdd(Xi, Xi, Mem128(heap3, rbp, 0x70, Secret, scratch_b, 7));  // # accumulate I[0]
    VAESNI_enc(inout2, inout2, rndkey);
    LoadBe64_buffer128(heap1, r12, in0, 3*16,   Secret, false, in0_b, in0_count*6 + 3);
    VPolyMul(T2, Ii, T2, true, true);
    VAESNI_enc(inout3, inout3, rndkey);
    Store64_buffer128(heap3, rbp, r13, 4*16,   Secret, false, scratch_b, 4);  // OpenSSL is further offset by 8 (to account for return addr?)
    VAESNI_enc(inout4, inout4, rndkey);
    Store64_buffer128(heap3, rbp, r12, 4*16+8, Secret, true,  scratch_b, 4);   // OpenSSL is further offset by 8 (to account for return addr?)
    VPolyAdd(Z0, Z0, Hkey);
    Load128_buffer(heap0, Hkey, Xip, 0x70-0x20, Secret, hkeys_b, 7);  // # $Hkey^6
    VAESNI_enc(inout5, inout5, rndkey);


    /* Loop6x_step4 */

    Load128_buffer(heap0, rndkey, key, (0x10 * (5 + 1))-0x80, Secret, keys_b, 5 + 1);
    VPolyAdd(Z2, Z2, Z1);
    VPolyMul(Z1, Xi, Hkey, false, true);
    VAESNI_enc(inout0, inout0, rndkey);
    VPolyAdd(Z2, Z2, T1);
    VPolyMul(T1, Xi, Hkey, true, false);
    VAESNI_enc(inout1, inout1, rndkey);
    LoadBe64_buffer128(heap1, r13, in0, 2*16+8, Secret, true,  in0_b, in0_count*6 + 2);
    VPolyAdd(Z3, Z3, T2);
    VPolyMul(T2, Xi, Hkey, false, false);
    VAESNI_enc(inout2, inout2, rndkey);
    LoadBe64_buffer128(heap1, r12, in0, 2*16,   Secret, false, in0_b, in0_count*6 + 2);
    VPolyMul(Xi, Xi, Hkey, true, true);
    VAESNI_enc(inout3, inout3, rndkey);
    Store64_buffer128(heap3, rbp, r13, 5*16,   Secret, false, scratch_b, 5);
    VAESNI_enc(inout4, inout4, rndkey);
    Store64_buffer128(heap3, rbp, r12, 5*16+8, Secret, true,  scratch_b, 5);   // OpenSSL is further offset by 8 (to account for return addr?)
    VPolyAdd(Z2, Z2, Z1);
    VAESNI_enc(inout5, inout5, rndkey);
    VPolyAdd(Z2, Z2, T1);

    /* Loop6x_step5 */

    Load128_buffer(heap0, rndkey, key, (0x10 * (6 + 1))-0x80, Secret, keys_b, 6 + 1);
    VLow64ToHigh(Z1, Z2);
    VPolyAdd(Z0, Z0, T2);

    ZeroXmm(Hkey);
    PinsrqImm(Hkey, 0xc200000000000000, 1, constp);

    VAESNI_enc(inout0, inout0, rndkey);
    VPolyAdd(Z3, Z3, Xi);
    VAESNI_enc(inout1, inout1, rndkey);
    VPolyAdd(Z0, Z0, Z1);
    LoadBe64_buffer128(heap1, r13, in0, 1*16+8, Secret, true,  in0_b, in0_count*6 + 1);
    VAESNI_enc(inout2, inout2, rndkey);
    LoadBe64_buffer128(heap1, r12, in0, 1*16,   Secret, false, in0_b, in0_count*6 + 1);
    VSwap(Ii, Z0); // # 1st phase
    VPolyMul(Z0, Z0, Hkey, false, true);
    Store64_buffer128(heap3, rbp, r13, 6*16,   Secret, false, scratch_b, 6);
    VAESNI_enc(inout3, inout3, rndkey);
    Store64_buffer128(heap3, rbp, r12, 6*16+8, Secret, true,  scratch_b, 6);   // OpenSSL is further offset by 8 (to account for return addr?)
    VAESNI_enc(inout4, inout4, rndkey);
    VAESNI_enc(inout5, inout5, rndkey);

    /* Loop6x_round8 */

    Load128_buffer(heap0, T1, key, 0x80-0x80, Secret, keys_b, 8); // # borrow $T1 for $rndkey

    VAESNI_enc(inout0, inout0, T1);
    Load128_buffer(heap0, rndkey, key, 0x90-0x80, Secret, keys_b, 9);
    VAESNI_enc(inout1, inout1, T1);
    VHigh64ToLow(Z2, Z2);
    VAESNI_enc(inout2, inout2, T1);
    VPolyAdd(Z3, Z3, Z2);
    VAESNI_enc(inout3, inout3, T1);
    VPolyAdd(Z0, Z0, Ii);

    LoadBe64_buffer128(heap1, r13, in0, 0*16+8, Secret, true,  in0_b, in0_count*6 + 0);
    VAESNI_enc(inout4, inout4, T1);
    LoadBe64_buffer128(heap1, r12, in0, 0*16,   Secret, false, in0_b, in0_count*6 + 0);

    VAESNI_enc(inout5, inout5, T1);

    /* Loop6x_round9 */

    Load128_buffer(heap0, T1, key, 0xa0-0x80, Secret, keys_b, 10);

    inline if (alg = AES_256) {
        VAESNI_enc(inout0, inout0, rndkey);
        VAESNI_enc(inout1, inout1, rndkey);
        VAESNI_enc(inout2, inout2, rndkey);
        VAESNI_enc(inout3, inout3, rndkey);
        VAESNI_enc(inout4, inout4, rndkey);
        VAESNI_enc(inout5, inout5, rndkey);

        VAESNI_enc(inout0, inout0, T1);
        VAESNI_enc(inout1, inout1, T1);
        VAESNI_enc(inout2, inout2, T1);
        VAESNI_enc(inout3, inout3, T1);
        VAESNI_enc(inout4, inout4, T1);
        Load128_buffer(heap0, rndkey, key, 0xb0-0x80, Secret, keys_b, 11);
        VAESNI_enc(inout5, inout5, T1);
        Load128_buffer(heap0, T1, key, 0xc0-0x80, Secret, keys_b, 12); // # Stop here for AES_196

        VAESNI_enc(inout0, inout0, rndkey);
        VAESNI_enc(inout1, inout1, rndkey);
        VAESNI_enc(inout2, inout2, rndkey);
        VAESNI_enc(inout3, inout3, rndkey);
        VAESNI_enc(inout4, inout4, rndkey);
        VAESNI_enc(inout5, inout5, rndkey);

        VAESNI_enc(inout0, inout0, T1);
        VAESNI_enc(inout1, inout1, T1);
        VAESNI_enc(inout2, inout2, T1);
        VAESNI_enc(inout3, inout3, T1);
        VAESNI_enc(inout4, inout4, T1);
        Load128_buffer(heap0, rndkey, key, 0xd0-0x80, Secret, keys_b, 13);
        VAESNI_enc(inout5, inout5, T1);
        Load128_buffer(heap0, T1, key, 0xe0-0x80, Secret, keys_b, 14); // # 256-bit key
    }

    VAESNI_enc(inout0, inout0, rndkey);
    Store128_buffer(heap3, rbp, Z3, 0x10, Secret, scratch_b, 1);  // # postpone vpxor $Z3,$Xi,$Xi
    VSwap(Xi, Z0);  // # 2nd phase
    VAESNI_enc(inout1, inout1, rndkey);
    VPolyMul(Z0, Z0, Hkey, false, true);
    VPxor(T2, T1, Mem128(heap1, inp, 0x00, Secret, in_b, count*6 + 0));
    VAESNI_enc(inout2, inout2, rndkey);
    VPxor(Ii, T1, Mem128(heap1, inp, 0x10, Secret, in_b, count*6 + 1));
    VAESNI_enc(inout3, inout3, rndkey);
    VPxor(Z1, T1, Mem128(heap1, inp, 0x20, Secret, in_b, count*6 + 2));
    VAESNI_enc(inout4, inout4, rndkey);
    VPxor(Z2, T1, Mem128(heap1, inp, 0x30, Secret, in_b, count*6 + 3));
    VAESNI_enc(inout5, inout5, rndkey);
    VPxor(Z3, T1, Mem128(heap1, inp, 0x40, Secret, in_b, count*6 + 4));
    VPxor(Hkey, T1, Mem128(heap1, inp, 0x50, Secret, in_b, count*6 + 5));
}
