include "../../../arch/x64/X64.Vale.InsBasic.vaf"
include "../../../arch/x64/X64.Vale.InsMem.vaf"

module X64.FastMul

#reset-options "--z3rlimit 30"

#verbatim{:interface}{:implementation}
open Types_s
open Arch.Types
open X64.Machine_s
open X64.Memory
open X64.Vale.State
open X64.Vale.Decls
open X64.Vale.InsBasic
open X64.Vale.InsMem
open X64.Vale.QuickCode
open X64.Vale.QuickCodes
open FastMul_helpers

open FStar.Tactics
open CanonCommSemiring
#endverbatim

#verbatim{:interface}
unfold let pow2_192 = 0x1000000000000000000000000000000000000000000000000
let _ = assert_norm (pow2 192 = pow2_192)
unfold let pow2_256 = 0x10000000000000000000000000000000000000000000000000000000000000000
let _ = assert_norm (pow2 256 = pow2_256)
unfold let pow2_320 = 0x100000000000000000000000000000000000000000000000000000000000000000000000000000000
let _ = assert_norm (pow2 320 = pow2_320)
unfold let pow2_384 = 0x1000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
let _ = assert_norm (pow2 384 = pow2_384)
unfold let pow2_448 = 0x10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
let _ = assert_norm (pow2 448 = pow2_448)

let int_canon = fun _ -> canon_semiring int_cr

let my_bool_to_nat (b:bool) : nat = if b then 1 else 0

#endverbatim

#reset-options "--z3rlimit 30"
/*

procedure{:quick exportOnly} fast_multiply(
    ghost dst_b:buffer64,
    ghost inA_b:buffer64,
    ghost inB_b:buffer64)
    lets
        dst_ptr @= rdi;
        inA_ptr @= rsi;
        inB_ptr @= rcx;

        a0 := buffer64_read(inA_b, 0, mem);
        a1 := buffer64_read(inA_b, 1, mem);
        a2 := buffer64_read(inA_b, 2, mem);
        a3 := buffer64_read(inA_b, 3, mem);

        b0 := buffer64_read(inB_b, 0, mem);
        b1 := buffer64_read(inB_b, 1, mem);
        b2 := buffer64_read(inB_b, 2, mem);
        b3 := buffer64_read(inB_b, 3, mem);

        a := a0 + pow2_64 * a1 + pow2_128 * a2 + pow2_192 * a3;
        b := b0 + pow2_64 * b1 + pow2_128 * b2 + pow2_192 * b3;
    reads
        dst_ptr; inA_ptr; inB_ptr;

    modifies
        rax; rdx; r8; r9; r10; r11; r12; r13; r14;
        mem; efl;

    requires
        buffers_disjoint(dst_b, inA_b);
        buffers_disjoint(dst_b, inB_b);

        validDstAddrs64(mem, dst_ptr, dst_b, 8);
        validSrcAddrs64(mem, inA_ptr, inA_b, 4);
        validSrcAddrs64(mem, inB_ptr, inB_b, 4);

    ensures
        let d0 := buffer64_read(dst_b, 0, mem);
        let d1 := buffer64_read(dst_b, 1, mem);
        let d2 := buffer64_read(dst_b, 2, mem);
        let d3 := buffer64_read(dst_b, 3, mem);
        let d4 := buffer64_read(dst_b, 4, mem);
        let d5 := buffer64_read(dst_b, 5, mem);
        let d6 := buffer64_read(dst_b, 6, mem);
        let d7 := buffer64_read(dst_b, 7, mem);

        let d := d0 + pow2_64 * d1 + pow2_128 * d2 + pow2_192 * d3 +
                 pow2_256 * d4 + pow2_320 * d5 + pow2_384 * d6 + pow2_448 * d7;
//        d == a * b;
        validSrcAddrs64(mem, dst_ptr, dst_b, 8);
        modifies_buffer(dst_b, old(mem), mem);
{
    xor_lemmas();

//    "movq   (%1), %%rdx; " /* A[0] */
//    "mulx   (B),  %%r8,  %%r9; " /* A[0]*B[0] */    "xorl %%r10d, %%r10d ;"                           "movq  %%r8,  (dst) ;"
//    "mulx  8(B), %%r10, %%r11; " /* A[0]*B[1] */    "adox  %%r9, %%r10 ;"                             "movq %%r10, 8(dst) ;"
//    "mulx 16(B), %%r12, %%r13; " /* A[0]*B[2] */    "adox %%r11, %%r12 ;"
//    "mulx 24(B), %%r14, %%rdx; " /* A[0]*B[3] */    "adox %%r13, %%r14 ;"                                                       "movq $0, %%rax ;"
//    /*******************************************/   "adox %%rdx, %%rax ;"

    Load64_buffer(rdx, inA_ptr,  0, inA_b, 0);     /* A[0] */
    // TODO: It would be really nice to not need the call to lemma_load_mem64, but it's the only connection between eval_operand and buffer64_read
    lemma_load_mem64(inB_b, 0, mem);
    /* The Xo64 clears the flags used for carry bits; NOTE: Original code uses xorl with r10d, maybe produces smaller code? */
    Mulx64( r9,  r8, Mem(inB_ptr,  0, inB_b, 0));  /* A[0]*B[0] */ Xor64(r10, r10);         Store64_buffer(dst_ptr,  r8, 0, dst_b, 0);

    assert overflow(efl) == false;
    ghost var old_efl := efl;
    ghost var a0b0_hi := r9;
//    assert r10 == 0;  // Passes
//    ghost var d0 := buffer64_read(dst_b, 0, mem);
//    assert d0 == a0 * b0 % pow2_64;     // Passes
//    assert not(overflow(efl));            // Passes
    lemma_load_mem64(inB_b, 1, mem);
    Mulx64(r11, r10, Mem(inB_ptr,  8, inB_b, 1));  /* A[0]*B[1] */ ghost var a0b1_lo := r10; Adox64Wrap(r10,  r9);    Store64_buffer(dst_ptr, r10, 8, dst_b, 1);
//    ghost var carry := a0b1_lo + r9 + 0 >= pow2_64;
//    assert efl == update_of(old_efl, carry);
//    assert overflow(efl) == carry;

    ghost var d0 := buffer64_read(dst_b, 0, mem);
    ghost var d1 := buffer64_read(dst_b, 1, mem);


    ghost var carry := if overflow(efl) then 1 else 0;          // BUG: With this version, the tactic fails to unify, perhaps due to the if-else
    //ghost var carry := my_bool_to_nat(overflow(efl));         // BUG: With this version, we get: (Error 230) Variable "__fname__mem#303637" not found


    //assume overflow(efl);
    //ghost var carry := 1;
    ghost var a0b0b1 := d0 + pow2_64 * d1 + pow2_128 * (r11 + carry);

//    assert pow2_64 * a0b0_hi + d0 == a0 * b0;
//    assert pow2_64 * r11 + a0b1_lo == a0 * b1;
//    assert r10 == add_wrap(add_wrap(a0b1_lo, a0b0_hi), 0);
//    assert overflow(efl) == (a0b1_lo + a0b0_hi >= pow2_64);
//    simple_helper(a0, b0, b1, d0, a0b0_hi, a0b1_lo, r11, r10, overflow(efl));
//    assert a0b0b1 == a0 * (b0 + pow2_64 * b1); // FAILS:

//    assert_by_tactic(a0b0b1 == a0 * (b0 + pow2_64 * b1), int_canon); // FAILS:
    // user tactic failed: apply_lemma: Cannot instantiate lemma CanonCommSemiring.semiring_reflect CanonCommSemiring.const_last

/*
    lemma_load_mem64(inB_b, 2, mem);
    Mulx64(r13, r12, Mem(inB_ptr, 16, inB_b, 2));  /* A[0]*B[2] */ Adox64Wrap(r12, r11);
    lemma_load_mem64(inB_b, 3, mem);
    Mulx64(rdx, r14, Mem(inB_ptr, 24, inB_b, 3));  /* A[0]*B[3] */ Adox64Wrap(r14, r13);    Mov64(rax, 0);
    /*******************************************/                  Adox64Wrap(rax, rdx);

    ghost var d0 := buffer64_read(dst_b, 0, mem);
    ghost var d1 := buffer64_read(dst_b, 1, mem);
//    assert d0 == a0 * b0 % pow2_64;

    ghost var carry := if overflow(efl) then 1 else 0;      // TODO: Should be able to prove that overflow == 0 at this point
    ghost var a0b := d0 + pow2_64 * d1 + pow2_128 * r12 + pow2_192 * r14 + pow2_256 * rax + carry;
    assert a0b == a0 * b;
*/

/*
//
//    "movq  8(A), %%rdx; " /* A[1] */
//    "mulx   (B),  %%r8,  %%r9; " /* A[1]*B[0] */    "xorl %%r10d, %%r10d ;"  "adcx 8(dst),  %%r8 ;"    "movq  %%r8,  8(dst) ;"
//    "mulx  8(B), %%r10, %%r11; " /* A[1]*B[1] */    "adox  %%r9, %%r10 ;"    "adcx %%r12, %%r10 ;"    "movq %%r10, 16(dst) ;"
//    "mulx 16(B), %%r12, %%r13; " /* A[1]*B[2] */    "adox %%r11, %%r12 ;"    "adcx %%r14, %%r12 ;"                              "movq $0, %%r8  ;"
//    "mulx 24(B), %%r14, %%rdx; " /* A[1]*B[3] */    "adox %%r13, %%r14 ;"    "adcx %%rax, %%r14 ;"                              "movq $0, %%rax ;"
//    /*******************************************/   "adox %%rdx, %%rax ;"    "adcx  %%r8, %%rax ;"

    Load64_buffer(rdx, inA_ptr,  8, inA_b, 1);     /* A[1] */
    Mulx64( r9,  r8, Mem(inB_ptr,  0, inB_b, 0));  /* A[1]*B[0] */ Xor64(r10, r10);       Adcx64Wrap(r8, Mem(dst_ptr,  8, dst_b, 1));   Store64_buffer(dst_ptr, r8,  8, dst_b, 1);  // REVIEW: Why not combine the Adcx with the Store?
    Mulx64(r11, r10, Mem(inB_ptr,  8, inB_b, 1));  /* A[1]*B[1] */ Adox64Wrap(r10,  r9);  Adcx64Wrap(r10, r12);                         Store64_buffer(dst_ptr, r10, 16, dst_b, 2);
    Mulx64(r13, r12, Mem(inB_ptr, 16, inB_b, 2));  /* A[1]*B[2] */ Adox64Wrap(r12, r11);  Adcx64Wrap(r12, r14);                         Mov64( r8, 0);
    Mulx64(rdx, r14, Mem(inB_ptr, 24, inB_b, 3));  /* A[1]*B[3] */ Adox64Wrap(r14, r13);  Adcx64Wrap(r14, rax);                         Mov64(rax, 0);
    /*******************************************/                  Adox64Wrap(rax, rdx);  Adcx64Wrap(rax, r8);

//
//
//    "movq 16(A), %%rdx; " /* A[2] */
//    "mulx   (B),  %%r8,  %%r9; " /* A[2]*B[0] */    "xorl %%r10d, %%r10d ;"  "adcx 16(dst), %%r8 ;"    "movq  %%r8, 16(dst) ;"
//    "mulx  8(B), %%r10, %%r11; " /* A[2]*B[1] */    "adox  %%r9, %%r10 ;"    "adcx %%r12, %%r10 ;"    "movq %%r10, 24(dst) ;"
//    "mulx 16(B), %%r12, %%r13; " /* A[2]*B[2] */    "adox %%r11, %%r12 ;"    "adcx %%r14, %%r12 ;"                              "movq $0, %%r8  ;"
//    "mulx 24(B), %%r14, %%rdx; " /* A[2]*B[3] */    "adox %%r13, %%r14 ;"    "adcx %%rax, %%r14 ;"                              "movq $0, %%rax ;"
//    /*******************************************/   "adox %%rdx, %%rax ;"    "adcx  %%r8, %%rax ;"

    Load64_buffer(rdx, inA_ptr, 16, inA_b, 2);     /* A[2] */
    Mulx64( r9,  r8, Mem(inB_ptr,  0, inB_b, 0));  /* A[2]*B[0] */ Xor64(r10, r10);       Adcx64Wrap(r8, Mem(dst_ptr, 16, dst_b, 2));   Store64_buffer(dst_ptr,  r8, 16, dst_b, 2);
    Mulx64(r11, r10, Mem(inB_ptr,  8, inB_b, 1));  /* A[2]*B[1] */ Adox64Wrap(r10,  r9);  Adcx64Wrap(r10, r12);                         Store64_buffer(dst_ptr, r10, 24, dst_b, 3);
    Mulx64(r13, r12, Mem(inB_ptr, 16, inB_b, 2));  /* A[2]*B[2] */ Adox64Wrap(r12, r11);  Adcx64Wrap(r12, r14);                         Mov64( r8, 0);
    Mulx64(rdx, r14, Mem(inB_ptr, 24, inB_b, 3));  /* A[2]*B[3] */ Adox64Wrap(r14, r13);  Adcx64Wrap(r14, rax);                         Mov64(rax, 0);
    /*******************************************/                  Adox64Wrap(rax, rdx);  Adcx64Wrap(rax, r8);

//
//    "movq 24(A), %%rdx; " /* A[3] */
//    "mulx   (B),  %%r8,  %%r9; " /* A[3]*B[0] */    "xorl %%r10d, %%r10d ;"  "adcx 24(dst), %%r8 ;"   "movq  %%r8, 24(dst) ;"
//    "mulx  8(B), %%r10, %%r11; " /* A[3]*B[1] */    "adox  %%r9, %%r10 ;"    "adcx %%r12, %%r10 ;"    "movq %%r10, 32(dst) ;"
//    "mulx 16(B), %%r12, %%r13; " /* A[3]*B[2] */    "adox %%r11, %%r12 ;"    "adcx %%r14, %%r12 ;"    "movq %%r12, 40(dst) ;"    "movq $0, %%r8  ;"
//    "mulx 24(B), %%r14, %%rdx; " /* A[3]*B[3] */    "adox %%r13, %%r14 ;"    "adcx %%rax, %%r14 ;"    "movq %%r14, 48(dst) ;"    "movq $0, %%rax ;"
//    /*******************************************/   "adox %%rdx, %%rax ;"    "adcx  %%r8, %%rax ;"    "movq %%rax, 56(dst) ;"

    Load64_buffer(rdx, inA_ptr, 24, inA_b, 3);     /* A[3] */
    Mulx64( r9,  r8, Mem(inB_ptr,  0, inB_b, 0));  /* A[3]*B[0] */ Xor64(r10, r10);       Adcx64Wrap(r8, Mem(dst_ptr, 24, dst_b, 2));   Store64_buffer(dst_ptr,  r8, 24, dst_b, 3);
    Mulx64(r11, r10, Mem(inB_ptr,  8, inB_b, 1));  /* A[3]*B[1] */ Adox64Wrap(r10,  r9);  Adcx64Wrap(r10, r12);                         Store64_buffer(dst_ptr, r10, 32, dst_b, 4);

    Mulx64(r13, r12, Mem(inB_ptr, 16, inB_b, 2));  /* A[3]*B[2] */ Adox64Wrap(r12, r11);  Adcx64Wrap(r12, r14);                         Store64_buffer(dst_ptr, r12, 40, dst_b, 5);   Mov64( r8, 0);
    Mulx64(rdx, r14, Mem(inB_ptr, 24, inB_b, 3));  /* A[3]*B[3] */ Adox64Wrap(r14, r13);  Adcx64Wrap(r14, rax);                         Store64_buffer(dst_ptr, r14, 48, dst_b, 6);   Mov64(rax, 0);
    /*******************************************/                  Adox64Wrap(rax, rdx);  Adcx64Wrap(rax, r8);                          Store64_buffer(dst_ptr, rax, 56, dst_b, 7);
*/
}

// fast_mul_stdcall(dst, inA, inB)
procedure{:quick} fast_mul_stdcall(
    inline win:bool,
    ghost dst_b:buffer64,
    ghost inA_b:buffer64,
    ghost inB_b:buffer64,
    ghost stack_b:buffer64)
    lets
        dst_ptr @= rdi; inA_ptr @= rsi; inB_ptr @= rcx;
        dst_in := (if win then rcx else rdi);
        inA_in := (if win then rdx else rsi);
        inB_in := (if win then r8 else rdx);
    modifies
        rax; rbx; rcx; rdx; rdi; rsi; r8; r9; r10; r11; r12; r13; r14;
        rsp; efl; mem;
    requires
        buffers_disjoint(dst_b, inA_b);
        buffers_disjoint(dst_b, inB_b);

        buffers_disjoint(stack_b, dst_b);
        buffers_disjoint(stack_b, inA_b);
        buffers_disjoint(stack_b, inB_b);

        validDstAddrs64(mem, dst_in, dst_b, 8);
        validSrcAddrs64(mem, inA_in, inA_b, 4);
        validSrcAddrs64(mem, inB_in, inB_b, 4);
        valid_stack_slots(mem, rsp, stack_b, 5, memTaint);
    ensures
        let a0 := buffer64_read(inA_b, 0, mem);
        let a1 := buffer64_read(inA_b, 1, mem);
        let a2 := buffer64_read(inA_b, 2, mem);
        let a3 := buffer64_read(inA_b, 3, mem);

        let b0 := buffer64_read(inB_b, 0, mem);
        let b1 := buffer64_read(inB_b, 1, mem);
        let b2 := buffer64_read(inB_b, 2, mem);
        let b3 := buffer64_read(inB_b, 3, mem);

        let d0 := buffer64_read(dst_b, 0, mem);
        let d1 := buffer64_read(dst_b, 1, mem);
        let d2 := buffer64_read(dst_b, 2, mem);
        let d3 := buffer64_read(dst_b, 3, mem);
        let d4 := buffer64_read(dst_b, 4, mem);
        let d5 := buffer64_read(dst_b, 5, mem);
        let d6 := buffer64_read(dst_b, 6, mem);
        let d7 := buffer64_read(dst_b, 7, mem);

        let a := a0 + pow2_64 * a1 + pow2_128 * a2 + pow2_192 * a3;
        let b := b0 + pow2_64 * b1 + pow2_128 * b2 + pow2_192 * b3;

        let d := d0 + pow2_64 * d1 + pow2_128 * d2 + pow2_192 * d3 +
                 pow2_256 * d4 + pow2_320 * d5 + pow2_384 * d6 + pow2_448 * d7;
//        d == a * b;

        //////////////////////////////////////
        //   Framing
        //////////////////////////////////////

        modifies_buffer_2(dst_b, stack_b, old(mem), mem);
        validSrcAddrs64(mem, dst_in, dst_b, 8);

        rbx == old(rbx);
        rsi == old(rsi);
        r12 == old(r12);
        r13 == old(r13);
        r14 == old(r14);

        rsp == old(rsp);
{
    // Store callee-save registers
    Push(rbx, stack_b, 4);
    Push(rsi, stack_b, 3);
    Push(r12, stack_b, 2);
    Push(r13, stack_b, 1);
    Push(r14, stack_b, 0);

    // Line up the rest of the arguments
    inline if (win) {
        Mov64(dst_ptr, rcx);
        Mov64(inA_ptr, rdx);
        Mov64(inB_ptr, r8);
    } else {
        Mov64(inB_ptr, rdx);
    }

    fast_multiply(dst_b, inA_b, inB_b);

    Pop(r14, stack_b, 0);
    Pop(r13, stack_b, 1);
    Pop(r12, stack_b, 2);
    Pop(rsi, stack_b, 3);
    Pop(rbx, stack_b, 4);
}
*/
