include "../../../arch/x64/Vale.X64.InsBasic.vaf"
include "../../../arch/x64/Vale.X64.InsMem.vaf"
include "../../../arch/x64/Vale.X64.InsVector.vaf"
include "../../../arch/x64/Vale.X64.InsAes.vaf"
include{:fstar}{:open} "Vale.Def.Opaque_s"
include{:fstar}{:open} "Vale.Def.Types_s"
include{:/*TODO*/fstar}{:open} "FStar.Seq.Base"
include{:fstar}{:open} "Vale.AES.AES_s"
include{:fstar}{:open} "Vale.X64.Machine_s"
include{:fstar}{:open} "Vale.X64.Memory"
include{:fstar}{:open} "Vale.X64.State"
include{:fstar}{:open} "Vale.X64.Decls"
include{:fstar}{:open} "Vale.X64.QuickCode"
include{:fstar}{:open} "Vale.X64.QuickCodes"
include{:fstar}{:open} "Vale.Arch.Types"
include{:fstar}{:open} "Vale.AES.AES256_helpers"
include{:fstar}{:open} "Vale.X64.CPU_Features_s"

module Vale.AES.X64.AES256

#verbatim{:interface}{:implementation}
open Vale.Def.Opaque_s
open Vale.Def.Types_s
open FStar.Seq
open Vale.AES.AES_s
open Vale.X64.Machine_s
open Vale.X64.Memory
open Vale.X64.State
open Vale.X64.Decls
open Vale.X64.InsBasic
open Vale.X64.InsMem
open Vale.X64.InsVector
open Vale.X64.InsAes
open Vale.X64.QuickCode
open Vale.X64.QuickCodes
open Vale.Arch.Types
open Vale.AES.AES256_helpers
open Vale.X64.CPU_Features_s
#endverbatim

#reset-options "--z3rlimit 20"

///////////////////////////
// KEY EXPANSION
///////////////////////////

// The next two procedures are based, in part, on the sample code in Figure 41
// in Intel's white paper: "Advanced Encryption Standard (AES) New Instructions Set"

// Given round key for round, generate round key for round + 1
procedure KeyExpansionRoundEven256(
        inline round:nat64,
        inline rcon:nat8,
        ghost dst:buffer128,
        ghost key:seq(nat32))
    {:quick}
    reads
        rdx; xmm3; memTaint;
    modifies
        mem; xmm1; xmm2; xmm4; efl;
    requires/ensures
        validDstAddrs128(mem, rdx, dst, 15, memTaint, Secret);
    requires
        aesni_enabled && avx_enabled;
        1 <= round < 14;
        (round + 1) % 2 == 0;
        rcon == aes_rcon((round + 1) / 2 - 1);
        is_aes_key_LE(AES_256, key);
        xmm1 == expand_key_256(key, #nat(round - 1));
        xmm3 == expand_key_256(key, round);
    ensures
        xmm1 == buffer128_read(dst, round + 1, mem);
        xmm1 == expand_key_256(key, round + 1);
        modifies_buffer_specific128(dst, old(mem), mem, round + 1, round + 1);
{
    AESNI_keygen_assist(xmm2, xmm3, rcon);
    Pshufd(xmm2, xmm2, 255);
    VPslldq4(xmm4, xmm1);
    Pxor(xmm1,xmm4);
    VPslldq4(xmm4, xmm1);
    Pxor(xmm1,xmm4);
    VPslldq4(xmm4, xmm1);
    Pxor(xmm1,xmm4);
    Pxor(xmm1,xmm2);
    Store128_buffer(rdx, xmm1, 16 * (round + 1), Secret, dst, round + 1);

    //assert xmm1 == simd_round_key_256(old(xmm1), old(xmm3), rcon, round + 1);
    lemma_simd_round_key(old(xmm1), old(xmm3), rcon, round + 1);
    Vale.Def.Opaque_s.reveal_opaque(expand_key_256_def);
    //assert xmm1 == round_key_256_rcon(old(xmm1), old(xmm3), rcon, round + 1);
}

// Given round key for round, generate round key for round + 1
procedure KeyExpansionRoundOdd256(
        inline round:nat64,
        inline rcon:nat8,
        ghost dst:buffer128,
        ghost key:seq(nat32))
    {:quick}
    reads
        rdx; xmm1; memTaint;
    modifies
        mem; xmm2; xmm3; xmm4; efl;
    requires/ensures
        validDstAddrs128(mem, rdx, dst, 15, memTaint, Secret);
    requires
        aesni_enabled && avx_enabled;
        1 <= round < 14;
        (round + 1) % 2 != 0;
        //rcon == aes_rcon((round + 1) / 2 - 1);
        is_aes_key_LE(AES_256, key);
        xmm3 == expand_key_256(key, #nat(round - 1));
        xmm1 == expand_key_256(key, round);
    ensures
        xmm3 == buffer128_read(dst, round + 1, mem);
        xmm3 == expand_key_256(key, round + 1);
        modifies_buffer_specific128(dst, old(mem), mem, round + 1, round + 1);
{
    AESNI_keygen_assist(xmm2, xmm1, 0);
    Pshufd(xmm2, xmm2, 0xAA);
    VPslldq4(xmm4, xmm3);
    Pxor(xmm3,xmm4);
    VPslldq4(xmm4, xmm3);
    Pxor(xmm3,xmm4);
    VPslldq4(xmm4, xmm3);
    Pxor(xmm3,xmm4);
    Pxor(xmm3,xmm2);
    Store128_buffer(rdx, xmm3, 16 * (round + 1), Secret, dst, round + 1);

    //assert xmm1 == simd_round_key_256(old(xmm1), old(xmm3), rcon, round + 1);
    lemma_simd_round_key(old(xmm3), old(xmm1), 0, round + 1);
    lemma_round_key_256_rcon_odd(old(xmm3), old(xmm1), 0, round + 1);
    Vale.Def.Opaque_s.reveal_opaque(expand_key_256_def);
}

procedure KeyExpansionRoundUnrolledRecursive256(
        ghost key:seq(nat32),
        ghost dst:buffer128,
        inline n:int)
    {:decrease n}
    {:recursive}
    {:quick exportOnly}
    reads
        rdx; memTaint;
    modifies
        mem; xmm1; xmm2; xmm3; xmm4; efl;
    requires/ensures
        validDstAddrs128(mem, rdx, dst, 15, memTaint, Secret);
    requires
        aesni_enabled && avx_enabled;
        0 < n <= 14;
        is_aes_key_LE(AES_256, key);
        xmm1 == expand_key_256(key, 0);
        xmm3 == expand_key_256(key, 1);
        xmm1 == buffer128_read(dst, 0, mem);
        xmm3 == buffer128_read(dst, 1, mem);
        rdx == buffer_addr(dst, mem);
    ensures
        modifies_buffer128(dst, old(mem), mem);
        buffer128_read(dst, n, mem) == (if (n % 2 = 0) then xmm1 else xmm3);
        buffer128_read(dst, n - 1, mem) == (if ((n-1) % 2 = 0) then xmm1 else xmm3);
        forall(j){buffer128_read(dst, j, mem)} 0 <= j <= n ==>
            buffer128_read(dst, j, mem) == expand_key_256(key, j);
{
    inline if (1 < n <= 14) {
        KeyExpansionRoundUnrolledRecursive256(key, dst, n - 1);
        let old_mem := mem;
        inline if (n % 2 = 0) {
            KeyExpansionRoundEven256(#nat64(n - 1), #nat8(aes_rcon(n / 2 - 1)), dst, key);
        }  else {
            KeyExpansionRoundOdd256(#nat64(n - 1), #nat8(aes_rcon(n / 2 - 1)), dst, key);
        }
        assert forall(j){buffer128_read(dst, j, mem)} 0 <= j < n ==>
            buffer128_read(dst, j, mem) == buffer128_read(dst, j, old_mem);
    }
}

procedure KeyExpansion256Stdcall(
        inline win:bool,
        ghost input_key_b:buffer128,
        ghost output_key_expansion_b:buffer128)
    {:public}
    {:quick}
    reads
        rcx; rsi; rdi; memTaint;
    modifies
        rdx;
        mem; xmm1; xmm2; xmm3; xmm4; efl;
    lets
        key_ptr := if win then rcx else rdi;
        key_expansion_ptr := if win then rdx else rsi;
        key := make_AES256_key(buffer128_read(input_key_b, 0, mem), buffer128_read(input_key_b, 1, mem));
    requires/ensures
        aesni_enabled && avx_enabled;
        buffers_disjoint128(input_key_b, output_key_expansion_b);
        validSrcAddrs128(mem, key_ptr, input_key_b, 2, memTaint, Secret);
        validDstAddrs128(mem, key_expansion_ptr, output_key_expansion_b, 15, memTaint, Secret);
    ensures
        modifies_buffer128(output_key_expansion_b, old(mem), mem);
        forall(j:nat){buffer128_read(output_key_expansion_b, j, mem)} j <= 14 ==>
            buffer128_read(output_key_expansion_b, j, mem) == index(key_to_round_keys_LE(AES_256, key), j);
{
    inline if (win)
    {
        Load128_buffer(xmm1, rcx, 0, Secret, input_key_b, 0);
        Load128_buffer(xmm3, rcx, 16, Secret, input_key_b, 1);
    }
    else
    {
        Load128_buffer(xmm1, rdi, 0, Secret, input_key_b, 0);
        Load128_buffer(xmm3, rdi, 16, Secret, input_key_b, 1);
        Mov64(rdx, rsi);
    }

    Store128_buffer(rdx, xmm1, 0, Secret, output_key_expansion_b, 0);
    Store128_buffer(rdx, xmm3, 16, Secret, output_key_expansion_b, 1);

    Vale.Def.Opaque_s.reveal_opaque(expand_key_256_def);
    KeyExpansionRoundUnrolledRecursive256(key, output_key_expansion_b, 14);
    lemma_expand_key_256(key, 15);
    reveal key_to_round_keys_LE;

    // Clear secrets out of registers
    Pxor(xmm1, xmm1);
    Pxor(xmm2, xmm2);
    Pxor(xmm3, xmm3);
    Pxor(xmm4, xmm4);
}

///////////////////////////
// ENCRYPTION
///////////////////////////

procedure AES256EncryptRound(
        inline n:nat,
        ghost init:quad32,
        ghost round_keys:seq(quad32),
        ghost keys_buffer:buffer128)
    {:quick}
    reads
        r8; mem; memTaint;
    modifies
        xmm0; xmm2; efl;
    requires
        aesni_enabled;
        1 <= n < 14 <= length(round_keys);
        xmm0 == rounds(init, round_keys, #nat(n - 1));
        r8 == buffer_addr(keys_buffer, mem);
        validSrcAddrs128(mem, r8, keys_buffer, 15, memTaint, Secret);
        buffer128_read(keys_buffer, n, mem) == index(round_keys, n);
    ensures
        xmm0 == rounds(init, round_keys, n);
{
    commute_sub_bytes_shift_rows(xmm0);
    Load128_buffer(xmm2, r8, 16 * n, Secret, keys_buffer, n);
    AESNI_enc(xmm0, xmm2);
}

procedure AES256EncryptBlock(
        ghost input:quad32,
        ghost key:seq(nat32),
        ghost round_keys:seq(quad32),
        ghost keys_buffer:buffer128)
    {:public}
    {:quick}
    reads
        r8; mem; memTaint;
    modifies
        xmm0; xmm2; efl;
    requires
        aesni_enabled;
        is_aes_key_LE(AES_256, key);
        length(round_keys) == 15;
        round_keys == key_to_round_keys_LE(AES_256, key);
        xmm0 == input;
        r8 == buffer_addr(keys_buffer, mem);
        validSrcAddrs128(mem, r8, keys_buffer, 15, memTaint, Secret);
        forall(i:nat) i < 15 ==> buffer128_read(keys_buffer, i, mem) == index(round_keys, i);
    ensures
        xmm0 == aes_encrypt_LE(AES_256, key, input);
{
    let init := quad32_xor(input, index(round_keys, 0));

    Load128_buffer(xmm2, r8, 0, Secret, keys_buffer, 0);
    Pxor(xmm0, xmm2);
    AES256EncryptRound(1, init, round_keys, keys_buffer);
    AES256EncryptRound(2, init, round_keys, keys_buffer);
    AES256EncryptRound(3, init, round_keys, keys_buffer);
    AES256EncryptRound(4, init, round_keys, keys_buffer);
    AES256EncryptRound(5, init, round_keys, keys_buffer);
    AES256EncryptRound(6, init, round_keys, keys_buffer);
    AES256EncryptRound(7, init, round_keys, keys_buffer);
    AES256EncryptRound(8, init, round_keys, keys_buffer);
    AES256EncryptRound(9, init, round_keys, keys_buffer);
    AES256EncryptRound(10, init, round_keys, keys_buffer);
    AES256EncryptRound(11, init, round_keys, keys_buffer);
    AES256EncryptRound(12, init, round_keys, keys_buffer);
    AES256EncryptRound(13, init, round_keys, keys_buffer);
    commute_sub_bytes_shift_rows(xmm0);
    Load128_buffer(xmm2, r8, 16 * 14, Secret, keys_buffer, 14);
    AESNI_enc_last(xmm0, xmm2);

    // Clear secrets out of registers
    Pxor(xmm2, xmm2);
}

procedure AES256EncryptBlockStdcall(
        inline win:bool,
        ghost input:quad32,
        ghost key:seq(nat32),
        ghost input_buffer:buffer128,
        ghost output_buffer:buffer128,
        ghost keys_buffer:buffer128)
    {:public}
    {:quick}
    reads
        rcx; rdx; rsi; rdi; memTaint;
    modifies
        r8;
        mem; xmm0; xmm2; efl;
    lets
        output_ptr := if win then rcx else rdi;
        input_ptr := if win then rdx else rsi;
        expanded_key_ptr := if win then r8 else rdx;
    requires
        aesni_enabled;
        is_aes_key_LE(AES_256, key);
        buffer128_read(input_buffer, 0, mem) == input;
        expanded_key_ptr == buffer_addr(keys_buffer, mem);
        validSrcAddrs128(mem, input_ptr, input_buffer, 1, memTaint, Secret);
        validDstAddrs128(mem, output_ptr, output_buffer, 1, memTaint, Secret);
        validSrcAddrs128(mem, expanded_key_ptr, keys_buffer, 15, memTaint, Secret);
        forall(i:nat) i < 15 ==>
            buffer128_read(keys_buffer, i, mem) == index(key_to_round_keys_LE(AES_256, key), i);
    ensures
        modifies_mem(loc_buffer(output_buffer), old(mem), mem);
        validSrcAddrs128(mem, output_ptr, output_buffer, 1, memTaint, Secret);
        buffer128_read(output_buffer, 0, mem) == aes_encrypt_LE(AES_256, key, input);
{
    inline if (win)
    {
        Load128_buffer(xmm0, rdx, 0, Secret, input_buffer, 0);
    }
    else
    {
        Load128_buffer(xmm0, rsi, 0, Secret, input_buffer, 0);
        Mov64(r8, rdx);
    }

    AES256EncryptBlock(input, key, key_to_round_keys_LE(AES_256, key), keys_buffer);

    inline if (win)
    {
        Store128_buffer(rcx, xmm0, 0, Secret, output_buffer, 0);
    }
    else
    {
        Store128_buffer(rdi, xmm0, 0, Secret, output_buffer, 0);
    }
}

