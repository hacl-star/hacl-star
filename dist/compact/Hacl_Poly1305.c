/* 
  This file was generated by KreMLin <https://github.com/FStarLang/kremlin>
  KreMLin invocation: /home/jonathan/Code/kremlin/krml -bundle Hacl.Spec.*,Spec.*[rename=Hacl_Spec] -bundle Hacl.Poly1305.Field32xN.Lemmas[rename=Hacl_Lemmas] -bundle Lib.*[rename=Hacl_Lib] -drop Lib.IntVector.Intrinsics -add-include "libintvector.h" -add-include "evercrypt_targetconfig.h" -drop EverCrypt.TargetConfig -bundle Test,Test.*,Hacl.Test.* -bundle EverCrypt.BCrypt -bundle EverCrypt.OpenSSL -bundle MerkleTree.Spec,MerkleTree.Spec.*,MerkleTree.New.High,MerkleTree.New.High.* -bundle Vale.Stdcalls.*,Interop,Interop.*,Fadd_stdcalls,Cpuid_stdcalls,Fswap_stdcalls,Fmul_stdcalls,Fsqr_stdcalls,Fsub_stdcalls,Poly_stdcalls,Sha_stdcalls,GCMencrypt_stdcalls,GCMencryptOpt_stdcalls,AES_stdcalls,AEShash_stdcalls,GCMencryptOpt256_stdcalls,GCMdecrypt_stdcalls[rename=Vale] -bundle Fadd_inline,Fmul_inline,Fsqr_inline,Fswap_inline[rename=Vale_Inline] -bundle FStar.Tactics.CanonCommMonoid,FStar.Tactics.CanonCommSemiring,FStar.Tactics.CanonCommSwaps[rename=Unused] -bundle FastUtil_helpers,FastHybrid_helpers,FastSqr_helpers,FastMul_helpers[rename=Unused2] -bundle Opaque_s,Map16,Test.Vale_memcpy,Fast_defs,Interop_Printer,Memcpy[rename=Unused3] -bundle X64.*,Arch.*,Words.*,Vale.*,Collections.*,Collections,SHA_helpers[rename=Unused4] -bundle Prop_s,Types_s,Words_s,Views,AES_s,Workarounds,Math.*,Interop,TypesNative_s[rename=Unused5] -bundle GF128_s,GF128,Poly1305.*,GCTR,GCTR_s,GHash_s,GCM_helpers,GHash[rename=Unused6] -bundle AES_helpers,AES256_helpers,GCM_s,GCM,Interop_assumptions[rename=Unused7] -library Vale.Stdcalls.* -static-header Vale_Inline -library Fadd_inline -library Fmul_inline -library Fswap_inline -library Fsqr_inline -no-prefix Vale.Stdcalls.* -no-prefix Fadd_inline -no-prefix Fmul_inline -no-prefix Fswap_inline -no-prefix Fsqr_inline -no-prefix EverCrypt.Vale -add-include "curve25519-inline.h" -no-prefix MerkleTree.New.Low -no-prefix MerkleTree.New.Low.Serialization -fparentheses -fno-shadow -fcurly-braces -bundle EverCrypt -bundle Hacl.Hash.MD5+Hacl.Hash.Core.MD5+Hacl.Hash.SHA1+Hacl.Hash.Core.SHA1+Hacl.Hash.SHA2+Hacl.Hash.Core.SHA2+Hacl.Hash.Core.SHA2.Constants=Hacl.Hash.*[rename=Hacl_Hash] -bundle Hacl.Impl.SHA3+Hacl.SHA3=[rename=Hacl_SHA3] -bundle Hacl.Poly1305_32+Hacl.Poly1305_128+Hacl.Poly1305_256=Hacl.Poly1305.*,Hacl.Impl.Poly1305,Hacl.Impl.Poly1305.*[rename=Hacl_Poly1305] -bundle Hacl.Impl.Chacha20=Hacl.Impl.Chacha20.*[rename=Hacl_Chacha20] -bundle Hacl.Curve25519_51+Hacl.Curve25519_64=Hacl.Impl.Curve25519.*[rename=Hacl_Curve25519] -bundle Hacl.Impl.Chacha20Poly1305=Hacl.Impl.Chacha20Poly1305.*[rename=Hacl_Chacha20Poly1305] -bundle LowStar.* -bundle Prims,C.Failure,C,C.String,C.Loops,Spec.Loops,C.Endianness,FStar.*[rename=Hacl_Kremlib] -bundle EverCrypt.Spec.* -bundle MerkleTree.New.Low+MerkleTree.New.Low.Serialization=[rename=MerkleTree] -bundle Test,Test.*,WindowsHack -bundle EverCrypt.Hash+EverCrypt.Hash.Incremental=[rename=EverCrypt_Hash] -library EverCrypt.AutoConfig,EverCrypt.OpenSSL,EverCrypt.BCrypt -minimal -add-include "kremlin/internal/types.h" -add-include "kremlin/internal/target.h" -add-include "kremlin/lowstar_endianness.h" -add-include <string.h> -tmpdir dist/compact/ -skip-compilation obj/prims.krml obj/FStar_Pervasives_Native.krml obj/FStar_Pervasives.krml obj/Prop_s.krml obj/FStar_Exn.krml obj/FStar_Squash.krml obj/FStar_Classical.krml obj/FStar_FunctionalExtensionality.krml obj/FStar_Set.krml obj/FStar_Preorder.krml obj/FStar_Monotonic_Witnessed.krml obj/FStar_Ghost.krml obj/FStar_ErasedLogic.krml obj/FStar_StrongExcludedMiddle.krml obj/FStar_PropositionalExtensionality.krml obj/FStar_PredicateExtensionality.krml obj/FStar_TSet.krml obj/FStar_Monotonic_Heap.krml obj/FStar_Heap.krml obj/FStar_ST.krml obj/FStar_All.krml obj/FStar_Map.krml obj/FStar_List_Tot_Base.krml obj/FStar_List_Tot_Properties.krml obj/FStar_List_Tot.krml obj/FStar_Seq_Base.krml obj/FStar_Mul.krml obj/FStar_Calc.krml obj/FStar_Seq_Properties.krml obj/FStar_Seq.krml obj/FStar_Math_Lib.krml obj/FStar_Math_Lemmas.krml obj/FStar_BitVector.krml obj/FStar_UInt.krml obj/FStar_UInt32.krml obj/FStar_UInt8.krml obj/FStar_Monotonic_HyperHeap.krml obj/FStar_Monotonic_HyperStack.krml obj/FStar_HyperStack.krml obj/FStar_HyperStack_ST.krml obj/FStar_Universe.krml obj/FStar_GSet.krml obj/FStar_ModifiesGen.krml obj/FStar_Range.krml obj/FStar_Reflection_Types.krml obj/FStar_Tactics_Types.krml obj/FStar_Tactics_Result.krml obj/FStar_Tactics_Effect.krml obj/FStar_Tactics_Util.krml obj/FStar_Reflection_Data.krml obj/FStar_Reflection_Const.krml obj/FStar_Char.krml obj/FStar_List.krml obj/FStar_String.krml obj/FStar_Order.krml obj/FStar_Reflection_Basic.krml obj/FStar_Reflection_Derived.krml obj/FStar_Tactics_Builtins.krml obj/FStar_Reflection_Formula.krml obj/FStar_Reflection_Derived_Lemmas.krml obj/FStar_Reflection.krml obj/FStar_Tactics_Derived.krml obj/FStar_Tactics_Logic.krml obj/FStar_Tactics.krml obj/FStar_BigOps.krml obj/LowStar_Monotonic_Buffer.krml obj/LowStar_Buffer.krml obj/LowStar_Modifies.krml obj/LowStar_ModifiesPat.krml obj/LowStar_BufferView_Down.krml obj/LowStar_BufferView_Up.krml obj/LowStar_BufferView.krml obj/BufferViewHelpers.krml obj/FStar_UInt64.krml obj/FStar_UInt16.krml obj/Words_s.krml obj/Collections_Seqs_s.krml obj/Words_Four_s.krml obj/Words_Two_s.krml obj/Words_Seq_s.krml obj/Opaque_s.krml obj/Types_s.krml obj/X64_Machine_s.krml obj/AES_s.krml obj/Math_Poly2_Defs_s.krml obj/Math_Poly2_s.krml obj/Math_Poly2_Bits_s.krml obj/Vale_Set.krml obj/FStar_HyperStack_All.krml obj/FStar_Kremlin_Endianness.krml obj/FStar_Int.krml obj/FStar_Int64.krml obj/FStar_Int63.krml obj/FStar_Int32.krml obj/FStar_Int16.krml obj/FStar_Int8.krml obj/FStar_UInt63.krml obj/FStar_Int_Cast.krml obj/FStar_UInt128.krml obj/Spec_Hash_Definitions.krml obj/Spec_Hash_Lemmas0.krml obj/Spec_Hash_PadFinish.krml obj/Spec_Loops.krml obj/Spec_SHA2_Constants.krml obj/Spec_SHA2.krml obj/X64_CryptoInstructions_s.krml obj/X64_CPU_Features_s.krml obj/X64_Bytes_Semantics_s.krml obj/FStar_Float.krml obj/FStar_BaseTypes.krml obj/X64_Taint_Semantics_s.krml obj/LowStar_ImmutableBuffer.krml obj/Util_Meta.krml obj/Words_Two.krml obj/Collections_Seqs.krml obj/TypesNative_s.krml obj/Arch_TypesNative.krml obj/Words_Seq.krml obj/Arch_Types.krml obj/Views.krml obj/Interop_Types.krml obj/Interop_Base.krml obj/X64_Bytes_Semantics.krml obj/Interop.krml obj/Fast_lemmas_internal.krml obj/Fast_defs.krml obj/FStar_Tactics_CanonCommSwaps.krml obj/FStar_Algebra_CommMonoid.krml obj/FStar_Tactics_CanonCommMonoid.krml obj/FStar_Tactics_CanonCommSemiring.krml obj/FastUtil_helpers.krml obj/FastHybrid_helpers.krml obj/Fast_lemmas_external.krml obj/Map16.krml obj/X64_Vale_Xmms.krml obj/X64_Vale_Regs.krml obj/FStar_IO.krml obj/X64_Stack_i.krml obj/X64_Stack_Sems.krml obj/X64_Memory.krml obj/X64_BufferViewStore.krml obj/X64_Memory_Sems.krml obj/X64_Vale_State.krml obj/X64_Vale_StateLemmas.krml obj/X64_Vale_Lemmas.krml obj/X64_Print_s.krml obj/X64_Vale_Decls.krml obj/X64_Vale_QuickCode.krml obj/X64_Vale_QuickCodes.krml obj/X64_Taint_Semantics.krml obj/X64_Vale_InsLemmas.krml obj/X64_Vale_InsBasic.krml obj/X64_Vale_InsMem.krml obj/X64_Vale_InsVector.krml obj/X64_Vale_InsStack.krml obj/X64_FastHybrid.krml obj/FastSqr_helpers.krml obj/X64_FastSqr.krml obj/FastMul_helpers.krml obj/X64_FastMul.krml obj/X64_FastWide.krml obj/X64_FastUtil.krml obj/Interop_Assumptions.krml obj/Interop_X64.krml obj/X64_Print_Inline_s.krml obj/X64_MemoryAdapters.krml obj/Vale_AsLowStar_ValeSig.krml obj/Vale_AsLowStar_LowStarSig.krml obj/Vale_AsLowStar_MemoryHelpers.krml obj/Vale_AsLowStar_Wrapper.krml obj/Vale_Stdcalls_Fadd.krml obj/Fadd_stdcalls.krml obj/Fsqr_inline.krml obj/X64_Stack.krml obj/X64_Vale_InsAes.krml obj/Math_Poly2_Defs.krml obj/Math_Poly2.krml obj/Math_Poly2_Lemmas.krml obj/Math_Poly2_Bits.krml obj/Math_Poly2_Words.krml obj/GF128_s.krml obj/GF128.krml obj/X64_GF128_Mul.krml obj/FStar_BV.krml obj/FStar_Reflection_Arith.krml obj/FStar_Tactics_BV.krml obj/Vale_Bv_s.krml obj/Math_Bits.krml obj/Vale_Tactics.krml obj/X64_Poly1305_Bitvectors.krml obj/Math_Lemmas_Int.krml obj/FStar_Tactics_Canon.krml obj/Poly1305_Spec_s.krml obj/X64_Poly1305_Math.krml obj/Workarounds.krml obj/GCTR_s.krml obj/GCM_helpers.krml obj/GHash_s.krml obj/OptPublic.krml obj/GHash.krml obj/X64_GHash.krml obj/GCTR.krml obj/AES_helpers.krml obj/X64_AESCTR.krml obj/X64_AESCTRplain.krml obj/AES256_helpers.krml obj/X64_AES256.krml obj/X64_AES128.krml obj/X64_AES.krml obj/X64_GCTR.krml obj/GCM_s.krml obj/GCM.krml obj/X64_GCMencrypt.krml obj/Test_Vale_memcpy.krml obj/Lib_LoopCombinators.krml obj/FStar_Int_Cast_Full.krml obj/Lib_IntTypes.krml obj/Lib_Sequence.krml obj/Spec_SHA3_Constants.krml obj/Spec_SHA1.krml obj/Spec_MD5.krml obj/Spec_Hash.krml obj/Spec_Hash_Incremental.krml obj/Spec_Hash_Lemmas.krml obj/LowStar_BufferOps.krml obj/C_Loops.krml obj/C_Endianness.krml obj/Hacl_Hash_Lemmas.krml obj/Hacl_Hash_Definitions.krml obj/Hacl_Hash_PadFinish.krml obj/Hacl_Hash_MD.krml obj/SHA_helpers.krml obj/X64_Vale_InsSha.krml obj/X64_SHA.krml obj/Vale_Stdcalls_Sha.krml obj/Simplify_Sha.krml obj/Sha_stdcalls.krml obj/Hacl_Hash_Core_SHA2_Constants.krml obj/Hacl_Hash_Core_SHA2.krml obj/Hacl_Hash_SHA2.krml obj/Hacl_Hash_Core_SHA1.krml obj/Hacl_Hash_SHA1.krml obj/Hacl_Hash_Core_MD5.krml obj/Hacl_Hash_MD5.krml obj/C.krml obj/C_String.krml obj/C_Failure.krml obj/FStar_Int128.krml obj/FStar_Int31.krml obj/FStar_UInt31.krml obj/FStar_Integers.krml obj/EverCrypt_StaticConfig.krml obj/X64_Cpuid.krml obj/X64_Cpuidstdcall.krml obj/Vale_Stdcalls_Cpuid.krml obj/Cpuid_stdcalls.krml obj/EverCrypt_TargetConfig.krml obj/EverCrypt_AutoConfig2.krml obj/EverCrypt_Helpers.krml obj/EverCrypt_Hash.krml obj/Lib_RawIntTypes.krml obj/Lib_Loops.krml obj/Lib_ByteSequence.krml obj/Hacl_Impl_Curve25519_Lemmas.krml obj/Spec_Curve25519_Lemmas.krml obj/Spec_Curve25519.krml obj/Hacl_Spec_Curve25519_Field51_Definition.krml obj/Hacl_Spec_Curve25519_Field51_Lemmas.krml obj/Hacl_Spec_Curve25519_Field51.krml obj/Lib_Buffer.krml obj/Hacl_Impl_Curve25519_Field51.krml obj/LowStar_Vector.krml obj/LowStar_Regional.krml obj/LowStar_RVector.krml obj/Hacl_Spec_Curve25519_AddAndDouble.krml obj/Hacl_Spec_Curve25519_Field64_Definition.krml obj/Hacl_Spec_Curve25519_Field64_Lemmas.krml obj/Hacl_Spec_Curve25519_Field64_Core.krml obj/Hacl_Spec_Curve25519_Field64.krml obj/Vale_Stdcalls_Fswap.krml obj/Fswap_stdcalls.krml obj/Fswap_inline.krml obj/Vale_Stdcalls_Fsqr.krml obj/Fsqr_stdcalls.krml obj/Vale_Stdcalls_Fmul.krml obj/Fmul_stdcalls.krml obj/Fmul_inline.krml obj/Vale_Stdcalls_Fsub.krml obj/Fsub_stdcalls.krml obj/Fadd_inline.krml obj/Hacl_Impl_Curve25519_Field64_Core.krml obj/Hacl_Impl_Curve25519_Field64.krml obj/Hacl_Impl_Curve25519_Fields.krml obj/Lib_ByteBuffer.krml obj/Hacl_Impl_Curve25519_AddAndDouble.krml obj/Lib_IntVector_Intrinsics.krml obj/Lib_IntVector.krml obj/X64_PolyOps.krml obj/Vale_Stdcalls_Aes.krml obj/Spec_Chacha20.krml obj/Hacl_Impl_Chacha20_Core32.krml obj/Hacl_Impl_Chacha20.krml obj/Spec_Poly1305.krml obj/Hacl_Spec_Poly1305_Vec.krml obj/Lib_Unlib.krml obj/X64_Poly1305_Util.krml obj/X64_Poly1305.krml obj/Vale_Stdcalls_Poly.krml obj/Poly_stdcalls.krml obj/FStar_Endianness.krml obj/Arch_BufferFriend.krml obj/Hacl_Impl_Poly1305_Lemmas.krml obj/Hacl_Spec_Poly1305_Field32xN.krml obj/Hacl_Poly1305_Field32xN_Lemmas.krml obj/Hacl_Spec_Poly1305_Field32xN_Lemmas.krml obj/Hacl_Impl_Poly1305_Field32xN.krml obj/Hacl_Impl_Poly1305_Fields.krml obj/Hacl_Spec_Poly1305_Equiv.krml obj/Hacl_Impl_Poly1305.krml obj/Spec_Chacha20Poly1305.krml obj/Hacl_Impl_Chacha20Poly1305_PolyCore.krml obj/Hacl_Impl_Chacha20Poly1305_Poly.krml obj/Hacl_Impl_Chacha20Poly1305.krml obj/FStar_Dyn.krml obj/EverCrypt_Vale.krml obj/EverCrypt_Specs.krml obj/EverCrypt_OpenSSL.krml obj/EverCrypt_Hacl.krml obj/EverCrypt_BCrypt.krml obj/EverCrypt_Cipher.krml obj/Hacl_Spec_Curve25519_Finv.krml obj/Hacl_Impl_Curve25519_Finv.krml obj/Hacl_Impl_Curve25519_Generic.krml obj/Hacl_Curve25519_51.krml obj/Hacl_Curve25519_64.krml obj/EverCrypt_Curve25519.krml obj/Hacl_Poly1305_32.krml obj/Poly1305_Equiv.krml obj/X64_Poly1305_CallingFromLowStar.krml obj/Hacl_Poly1305_128.krml obj/Hacl_Poly1305_256.krml obj/EverCrypt_Poly1305.krml obj/EverCrypt_HMAC.krml obj/EverCrypt_HKDF.krml obj/EverCrypt.krml obj/MerkleTree_Spec.krml obj/Gcm_simplify.krml obj/Vale_Stdcalls_GCMencrypt.krml obj/GCMencrypt_stdcalls.krml obj/MerkleTree_New_High.krml obj/LowStar_Regional_Instances.krml obj/MerkleTree_New_Low.krml obj/MerkleTree_New_Low_Serialization.krml obj/X64_Leakage_s.krml obj/X64_Leakage_Helpers.krml obj/X64_GCMdecrypt.krml obj/Vale_Stdcalls_GCMdecrypt.krml obj/GCMdecrypt_stdcalls.krml obj/X64_AESopt2.krml obj/X64_AESGCM.krml obj/X64_GCMencryptOpt.krml obj/Vale_Stdcalls_GCMencryptOpt.krml obj/GCMencryptOpt256_stdcalls.krml obj/GCMencryptOpt_stdcalls.krml obj/X64_GF128_Init.krml obj/Vale_Stdcalls_AesHash.krml obj/AEShash_stdcalls.krml obj/AES_stdcalls.krml obj/Spec_AEAD.krml obj/EverCrypt_AEAD.krml obj/MerkleTree_New_High_Correct_Base.krml obj/MerkleTree_New_High_Correct_Rhs.krml obj/MerkleTree_New_High_Correct_Path.krml obj/MerkleTree_New_High_Correct_Flushing.krml obj/MerkleTree_New_High_Correct_Insertion.krml obj/MerkleTree_New_High_Correct.krml obj/EverCrypt_Hash_Incremental.krml obj/Test_Hash.krml obj/Operator.krml obj/Spec_SHA3.krml obj/Hacl_Impl_SHA3.krml obj/TestLib.krml obj/EverCrypt_Chacha20Poly1305.krml obj/Hacl_SHA3.krml obj/Lib_PrintBuffer.krml obj/Hacl_Test_CSHAKE.krml obj/Spec_Hash_Test.krml obj/X64_Leakage_Ins_Xmm.krml obj/X64_Leakage_Ins.krml obj/X64_Leakage.krml obj/Test_Vectors_Chacha20Poly1305.krml obj/Test_Memcpy.krml obj/Lib_RandomBuffer.krml obj/Test_Vectors_Aes128.krml obj/Collections_Lists.krml obj/Hacl_Hash_Agile.krml obj/Hacl_Test_SHA3.krml obj/Test_Vectors_Curve25519.krml obj/Spec_Chacha20Poly1305_Test.krml obj/Test_Vectors_Poly1305.krml obj/Test_Args.krml obj/Vale_AsLowStar_Test.krml obj/Spec_SHA3_Test.krml obj/Test_Lowstarize.krml obj/Test_Vectors.krml obj/Test_Vectors_Aes128Gcm.krml obj/Spec_Curve25519_Test.krml obj/Test.krml obj/Spec_Chacha20_Test.krml obj/X64_AESopt.krml -silent -ccopt -Wno-unused -warn-error @4-6 -fparentheses Hacl_AES.c Hacl_Ed25519.c Lib_RandomBuffer.c Lib_PrintBuffer.c evercrypt_vale_stubs.c -o libevercrypt.a
  F* version: 28a5baa2
  KreMLin version: f534ac02
 */

#include "Hacl_Poly1305.h"

inline void Hacl_Impl_Poly1305_poly1305_init_32(uint64_t *ctx, uint8_t *k)
{
  uint64_t *acc = ctx;
  uint64_t *pre = ctx + (uint32_t)5U;
  uint8_t *kr = k;
  acc[0U] = (uint64_t)0U;
  acc[1U] = (uint64_t)0U;
  acc[2U] = (uint64_t)0U;
  acc[3U] = (uint64_t)0U;
  acc[4U] = (uint64_t)0U;
  uint64_t u0 = load64_le(kr);
  uint64_t lo = u0;
  uint64_t u = load64_le(kr + (uint32_t)8U);
  uint64_t hi = u;
  uint64_t mask0 = (uint64_t)0x0ffffffc0fffffffU;
  uint64_t mask1 = (uint64_t)0x0ffffffc0ffffffcU;
  uint64_t lo1 = lo & mask0;
  uint64_t hi1 = hi & mask1;
  uint64_t *r = pre;
  uint64_t *r5 = pre + (uint32_t)5U;
  uint64_t *rn = pre + (uint32_t)10U;
  uint64_t *rn_5 = pre + (uint32_t)15U;
  uint64_t r_vec0 = lo1;
  uint64_t r_vec1 = hi1;
  uint64_t f00 = r_vec0 & (uint64_t)0x3ffffffU;
  uint64_t f10 = r_vec0 >> (uint32_t)26U & (uint64_t)0x3ffffffU;
  uint64_t f20 = r_vec0 >> (uint32_t)52U | (r_vec1 & (uint64_t)0x3fffU) << (uint32_t)12U;
  uint64_t f30 = r_vec1 >> (uint32_t)14U & (uint64_t)0x3ffffffU;
  uint64_t f40 = r_vec1 >> (uint32_t)40U;
  uint64_t f0 = f00;
  uint64_t f1 = f10;
  uint64_t f2 = f20;
  uint64_t f3 = f30;
  uint64_t f4 = f40;
  r[0U] = f0;
  r[1U] = f1;
  r[2U] = f2;
  r[3U] = f3;
  r[4U] = f4;
  uint64_t f200 = r[0U];
  uint64_t f21 = r[1U];
  uint64_t f22 = r[2U];
  uint64_t f23 = r[3U];
  uint64_t f24 = r[4U];
  r5[0U] = f200 * (uint64_t)5U;
  r5[1U] = f21 * (uint64_t)5U;
  r5[2U] = f22 * (uint64_t)5U;
  r5[3U] = f23 * (uint64_t)5U;
  r5[4U] = f24 * (uint64_t)5U;
  rn[0U] = r[0U];
  rn[1U] = r[1U];
  rn[2U] = r[2U];
  rn[3U] = r[3U];
  rn[4U] = r[4U];
  rn_5[0U] = r5[0U];
  rn_5[1U] = r5[1U];
  rn_5[2U] = r5[2U];
  rn_5[3U] = r5[3U];
  rn_5[4U] = r5[4U];
}

inline static void
Hacl_Impl_Poly1305_poly1305_init_128(Lib_IntVector_Intrinsics_vec128 *ctx, uint8_t *k)
{
  Lib_IntVector_Intrinsics_vec128 *acc = ctx;
  Lib_IntVector_Intrinsics_vec128 *pre = ctx + (uint32_t)5U;
  uint8_t *kr = k;
  acc[0U] = Lib_IntVector_Intrinsics_vec128_zero;
  acc[1U] = Lib_IntVector_Intrinsics_vec128_zero;
  acc[2U] = Lib_IntVector_Intrinsics_vec128_zero;
  acc[3U] = Lib_IntVector_Intrinsics_vec128_zero;
  acc[4U] = Lib_IntVector_Intrinsics_vec128_zero;
  uint64_t u0 = load64_le(kr);
  uint64_t lo = u0;
  uint64_t u = load64_le(kr + (uint32_t)8U);
  uint64_t hi = u;
  uint64_t mask0 = (uint64_t)0x0ffffffc0fffffffU;
  uint64_t mask1 = (uint64_t)0x0ffffffc0ffffffcU;
  uint64_t lo1 = lo & mask0;
  uint64_t hi1 = hi & mask1;
  Lib_IntVector_Intrinsics_vec128 *r = pre;
  Lib_IntVector_Intrinsics_vec128 *r5 = pre + (uint32_t)5U;
  Lib_IntVector_Intrinsics_vec128 *rn = pre + (uint32_t)10U;
  Lib_IntVector_Intrinsics_vec128 *rn_5 = pre + (uint32_t)15U;
  Lib_IntVector_Intrinsics_vec128 r_vec0 = Lib_IntVector_Intrinsics_vec128_load64(lo1);
  Lib_IntVector_Intrinsics_vec128 r_vec1 = Lib_IntVector_Intrinsics_vec128_load64(hi1);
  Lib_IntVector_Intrinsics_vec128
  f00 =
    Lib_IntVector_Intrinsics_vec128_and(r_vec0,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  f15 =
    Lib_IntVector_Intrinsics_vec128_and(Lib_IntVector_Intrinsics_vec128_shift_right64(r_vec0,
        (uint32_t)26U),
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  f20 =
    Lib_IntVector_Intrinsics_vec128_or(Lib_IntVector_Intrinsics_vec128_shift_right64(r_vec0,
        (uint32_t)52U),
      Lib_IntVector_Intrinsics_vec128_shift_left64(Lib_IntVector_Intrinsics_vec128_and(r_vec1,
          Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3fffU)),
        (uint32_t)12U));
  Lib_IntVector_Intrinsics_vec128
  f30 =
    Lib_IntVector_Intrinsics_vec128_and(Lib_IntVector_Intrinsics_vec128_shift_right64(r_vec1,
        (uint32_t)14U),
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  f40 = Lib_IntVector_Intrinsics_vec128_shift_right64(r_vec1, (uint32_t)40U);
  Lib_IntVector_Intrinsics_vec128 f0 = f00;
  Lib_IntVector_Intrinsics_vec128 f1 = f15;
  Lib_IntVector_Intrinsics_vec128 f2 = f20;
  Lib_IntVector_Intrinsics_vec128 f3 = f30;
  Lib_IntVector_Intrinsics_vec128 f4 = f40;
  r[0U] = f0;
  r[1U] = f1;
  r[2U] = f2;
  r[3U] = f3;
  r[4U] = f4;
  Lib_IntVector_Intrinsics_vec128 f200 = r[0U];
  Lib_IntVector_Intrinsics_vec128 f210 = r[1U];
  Lib_IntVector_Intrinsics_vec128 f220 = r[2U];
  Lib_IntVector_Intrinsics_vec128 f230 = r[3U];
  Lib_IntVector_Intrinsics_vec128 f240 = r[4U];
  r5[0U] = Lib_IntVector_Intrinsics_vec128_smul64(f200, (uint64_t)5U);
  r5[1U] = Lib_IntVector_Intrinsics_vec128_smul64(f210, (uint64_t)5U);
  r5[2U] = Lib_IntVector_Intrinsics_vec128_smul64(f220, (uint64_t)5U);
  r5[3U] = Lib_IntVector_Intrinsics_vec128_smul64(f230, (uint64_t)5U);
  r5[4U] = Lib_IntVector_Intrinsics_vec128_smul64(f240, (uint64_t)5U);
  Lib_IntVector_Intrinsics_vec128 r0 = r[0U];
  Lib_IntVector_Intrinsics_vec128 r1 = r[1U];
  Lib_IntVector_Intrinsics_vec128 r2 = r[2U];
  Lib_IntVector_Intrinsics_vec128 r3 = r[3U];
  Lib_IntVector_Intrinsics_vec128 r4 = r[4U];
  Lib_IntVector_Intrinsics_vec128 r51 = r5[1U];
  Lib_IntVector_Intrinsics_vec128 r52 = r5[2U];
  Lib_IntVector_Intrinsics_vec128 r53 = r5[3U];
  Lib_IntVector_Intrinsics_vec128 r54 = r5[4U];
  Lib_IntVector_Intrinsics_vec128 f10 = r[0U];
  Lib_IntVector_Intrinsics_vec128 f11 = r[1U];
  Lib_IntVector_Intrinsics_vec128 f12 = r[2U];
  Lib_IntVector_Intrinsics_vec128 f13 = r[3U];
  Lib_IntVector_Intrinsics_vec128 f14 = r[4U];
  Lib_IntVector_Intrinsics_vec128 a0 = Lib_IntVector_Intrinsics_vec128_mul64(r0, f10);
  Lib_IntVector_Intrinsics_vec128 a1 = Lib_IntVector_Intrinsics_vec128_mul64(r1, f10);
  Lib_IntVector_Intrinsics_vec128 a2 = Lib_IntVector_Intrinsics_vec128_mul64(r2, f10);
  Lib_IntVector_Intrinsics_vec128 a3 = Lib_IntVector_Intrinsics_vec128_mul64(r3, f10);
  Lib_IntVector_Intrinsics_vec128 a4 = Lib_IntVector_Intrinsics_vec128_mul64(r4, f10);
  Lib_IntVector_Intrinsics_vec128
  a01 =
    Lib_IntVector_Intrinsics_vec128_add64(a0,
      Lib_IntVector_Intrinsics_vec128_mul64(r54, f11));
  Lib_IntVector_Intrinsics_vec128
  a11 = Lib_IntVector_Intrinsics_vec128_add64(a1, Lib_IntVector_Intrinsics_vec128_mul64(r0, f11));
  Lib_IntVector_Intrinsics_vec128
  a21 = Lib_IntVector_Intrinsics_vec128_add64(a2, Lib_IntVector_Intrinsics_vec128_mul64(r1, f11));
  Lib_IntVector_Intrinsics_vec128
  a31 = Lib_IntVector_Intrinsics_vec128_add64(a3, Lib_IntVector_Intrinsics_vec128_mul64(r2, f11));
  Lib_IntVector_Intrinsics_vec128
  a41 = Lib_IntVector_Intrinsics_vec128_add64(a4, Lib_IntVector_Intrinsics_vec128_mul64(r3, f11));
  Lib_IntVector_Intrinsics_vec128
  a02 =
    Lib_IntVector_Intrinsics_vec128_add64(a01,
      Lib_IntVector_Intrinsics_vec128_mul64(r53, f12));
  Lib_IntVector_Intrinsics_vec128
  a12 =
    Lib_IntVector_Intrinsics_vec128_add64(a11,
      Lib_IntVector_Intrinsics_vec128_mul64(r54, f12));
  Lib_IntVector_Intrinsics_vec128
  a22 =
    Lib_IntVector_Intrinsics_vec128_add64(a21,
      Lib_IntVector_Intrinsics_vec128_mul64(r0, f12));
  Lib_IntVector_Intrinsics_vec128
  a32 =
    Lib_IntVector_Intrinsics_vec128_add64(a31,
      Lib_IntVector_Intrinsics_vec128_mul64(r1, f12));
  Lib_IntVector_Intrinsics_vec128
  a42 =
    Lib_IntVector_Intrinsics_vec128_add64(a41,
      Lib_IntVector_Intrinsics_vec128_mul64(r2, f12));
  Lib_IntVector_Intrinsics_vec128
  a03 =
    Lib_IntVector_Intrinsics_vec128_add64(a02,
      Lib_IntVector_Intrinsics_vec128_mul64(r52, f13));
  Lib_IntVector_Intrinsics_vec128
  a13 =
    Lib_IntVector_Intrinsics_vec128_add64(a12,
      Lib_IntVector_Intrinsics_vec128_mul64(r53, f13));
  Lib_IntVector_Intrinsics_vec128
  a23 =
    Lib_IntVector_Intrinsics_vec128_add64(a22,
      Lib_IntVector_Intrinsics_vec128_mul64(r54, f13));
  Lib_IntVector_Intrinsics_vec128
  a33 =
    Lib_IntVector_Intrinsics_vec128_add64(a32,
      Lib_IntVector_Intrinsics_vec128_mul64(r0, f13));
  Lib_IntVector_Intrinsics_vec128
  a43 =
    Lib_IntVector_Intrinsics_vec128_add64(a42,
      Lib_IntVector_Intrinsics_vec128_mul64(r1, f13));
  Lib_IntVector_Intrinsics_vec128
  a04 =
    Lib_IntVector_Intrinsics_vec128_add64(a03,
      Lib_IntVector_Intrinsics_vec128_mul64(r51, f14));
  Lib_IntVector_Intrinsics_vec128
  a14 =
    Lib_IntVector_Intrinsics_vec128_add64(a13,
      Lib_IntVector_Intrinsics_vec128_mul64(r52, f14));
  Lib_IntVector_Intrinsics_vec128
  a24 =
    Lib_IntVector_Intrinsics_vec128_add64(a23,
      Lib_IntVector_Intrinsics_vec128_mul64(r53, f14));
  Lib_IntVector_Intrinsics_vec128
  a34 =
    Lib_IntVector_Intrinsics_vec128_add64(a33,
      Lib_IntVector_Intrinsics_vec128_mul64(r54, f14));
  Lib_IntVector_Intrinsics_vec128
  a44 =
    Lib_IntVector_Intrinsics_vec128_add64(a43,
      Lib_IntVector_Intrinsics_vec128_mul64(r0, f14));
  Lib_IntVector_Intrinsics_vec128 t0 = a04;
  Lib_IntVector_Intrinsics_vec128 t1 = a14;
  Lib_IntVector_Intrinsics_vec128 t2 = a24;
  Lib_IntVector_Intrinsics_vec128 t3 = a34;
  Lib_IntVector_Intrinsics_vec128 t4 = a44;
  Lib_IntVector_Intrinsics_vec128
  l = Lib_IntVector_Intrinsics_vec128_add64(t0, Lib_IntVector_Intrinsics_vec128_zero);
  Lib_IntVector_Intrinsics_vec128
  tmp0 =
    Lib_IntVector_Intrinsics_vec128_and(l,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c0 = Lib_IntVector_Intrinsics_vec128_shift_right64(l, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 l0 = Lib_IntVector_Intrinsics_vec128_add64(t1, c0);
  Lib_IntVector_Intrinsics_vec128
  tmp1 =
    Lib_IntVector_Intrinsics_vec128_and(l0,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c1 = Lib_IntVector_Intrinsics_vec128_shift_right64(l0, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 l1 = Lib_IntVector_Intrinsics_vec128_add64(t2, c1);
  Lib_IntVector_Intrinsics_vec128
  tmp2 =
    Lib_IntVector_Intrinsics_vec128_and(l1,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c2 = Lib_IntVector_Intrinsics_vec128_shift_right64(l1, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 l2 = Lib_IntVector_Intrinsics_vec128_add64(t3, c2);
  Lib_IntVector_Intrinsics_vec128
  tmp3 =
    Lib_IntVector_Intrinsics_vec128_and(l2,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c3 = Lib_IntVector_Intrinsics_vec128_shift_right64(l2, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 l3 = Lib_IntVector_Intrinsics_vec128_add64(t4, c3);
  Lib_IntVector_Intrinsics_vec128
  tmp4 =
    Lib_IntVector_Intrinsics_vec128_and(l3,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c4 = Lib_IntVector_Intrinsics_vec128_shift_right64(l3, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128
  l4 =
    Lib_IntVector_Intrinsics_vec128_add64(tmp0,
      Lib_IntVector_Intrinsics_vec128_smul64(c4, (uint64_t)5U));
  Lib_IntVector_Intrinsics_vec128
  tmp01 =
    Lib_IntVector_Intrinsics_vec128_and(l4,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c5 = Lib_IntVector_Intrinsics_vec128_shift_right64(l4, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 tmp11 = Lib_IntVector_Intrinsics_vec128_add64(tmp1, c5);
  Lib_IntVector_Intrinsics_vec128 o0 = tmp01;
  Lib_IntVector_Intrinsics_vec128 o1 = tmp11;
  Lib_IntVector_Intrinsics_vec128 o2 = tmp2;
  Lib_IntVector_Intrinsics_vec128 o3 = tmp3;
  Lib_IntVector_Intrinsics_vec128 o4 = tmp4;
  rn[0U] = o0;
  rn[1U] = o1;
  rn[2U] = o2;
  rn[3U] = o3;
  rn[4U] = o4;
  Lib_IntVector_Intrinsics_vec128 f201 = rn[0U];
  Lib_IntVector_Intrinsics_vec128 f21 = rn[1U];
  Lib_IntVector_Intrinsics_vec128 f22 = rn[2U];
  Lib_IntVector_Intrinsics_vec128 f23 = rn[3U];
  Lib_IntVector_Intrinsics_vec128 f24 = rn[4U];
  rn_5[0U] = Lib_IntVector_Intrinsics_vec128_smul64(f201, (uint64_t)5U);
  rn_5[1U] = Lib_IntVector_Intrinsics_vec128_smul64(f21, (uint64_t)5U);
  rn_5[2U] = Lib_IntVector_Intrinsics_vec128_smul64(f22, (uint64_t)5U);
  rn_5[3U] = Lib_IntVector_Intrinsics_vec128_smul64(f23, (uint64_t)5U);
  rn_5[4U] = Lib_IntVector_Intrinsics_vec128_smul64(f24, (uint64_t)5U);
}

inline static void
Hacl_Impl_Poly1305_poly1305_init_256(Lib_IntVector_Intrinsics_vec256 *ctx, uint8_t *k)
{
  Lib_IntVector_Intrinsics_vec256 *acc = ctx;
  Lib_IntVector_Intrinsics_vec256 *pre = ctx + (uint32_t)5U;
  uint8_t *kr = k;
  acc[0U] = Lib_IntVector_Intrinsics_vec256_zero;
  acc[1U] = Lib_IntVector_Intrinsics_vec256_zero;
  acc[2U] = Lib_IntVector_Intrinsics_vec256_zero;
  acc[3U] = Lib_IntVector_Intrinsics_vec256_zero;
  acc[4U] = Lib_IntVector_Intrinsics_vec256_zero;
  uint64_t u0 = load64_le(kr);
  uint64_t lo = u0;
  uint64_t u = load64_le(kr + (uint32_t)8U);
  uint64_t hi = u;
  uint64_t mask0 = (uint64_t)0x0ffffffc0fffffffU;
  uint64_t mask1 = (uint64_t)0x0ffffffc0ffffffcU;
  uint64_t lo1 = lo & mask0;
  uint64_t hi1 = hi & mask1;
  Lib_IntVector_Intrinsics_vec256 *r = pre;
  Lib_IntVector_Intrinsics_vec256 *r5 = pre + (uint32_t)5U;
  Lib_IntVector_Intrinsics_vec256 *rn = pre + (uint32_t)10U;
  Lib_IntVector_Intrinsics_vec256 *rn_5 = pre + (uint32_t)15U;
  Lib_IntVector_Intrinsics_vec256 r_vec0 = Lib_IntVector_Intrinsics_vec256_load64(lo1);
  Lib_IntVector_Intrinsics_vec256 r_vec1 = Lib_IntVector_Intrinsics_vec256_load64(hi1);
  Lib_IntVector_Intrinsics_vec256
  f00 =
    Lib_IntVector_Intrinsics_vec256_and(r_vec0,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  f15 =
    Lib_IntVector_Intrinsics_vec256_and(Lib_IntVector_Intrinsics_vec256_shift_right64(r_vec0,
        (uint32_t)26U),
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  f20 =
    Lib_IntVector_Intrinsics_vec256_or(Lib_IntVector_Intrinsics_vec256_shift_right64(r_vec0,
        (uint32_t)52U),
      Lib_IntVector_Intrinsics_vec256_shift_left64(Lib_IntVector_Intrinsics_vec256_and(r_vec1,
          Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3fffU)),
        (uint32_t)12U));
  Lib_IntVector_Intrinsics_vec256
  f30 =
    Lib_IntVector_Intrinsics_vec256_and(Lib_IntVector_Intrinsics_vec256_shift_right64(r_vec1,
        (uint32_t)14U),
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  f40 = Lib_IntVector_Intrinsics_vec256_shift_right64(r_vec1, (uint32_t)40U);
  Lib_IntVector_Intrinsics_vec256 f0 = f00;
  Lib_IntVector_Intrinsics_vec256 f1 = f15;
  Lib_IntVector_Intrinsics_vec256 f2 = f20;
  Lib_IntVector_Intrinsics_vec256 f3 = f30;
  Lib_IntVector_Intrinsics_vec256 f4 = f40;
  r[0U] = f0;
  r[1U] = f1;
  r[2U] = f2;
  r[3U] = f3;
  r[4U] = f4;
  Lib_IntVector_Intrinsics_vec256 f200 = r[0U];
  Lib_IntVector_Intrinsics_vec256 f210 = r[1U];
  Lib_IntVector_Intrinsics_vec256 f220 = r[2U];
  Lib_IntVector_Intrinsics_vec256 f230 = r[3U];
  Lib_IntVector_Intrinsics_vec256 f240 = r[4U];
  r5[0U] = Lib_IntVector_Intrinsics_vec256_smul64(f200, (uint64_t)5U);
  r5[1U] = Lib_IntVector_Intrinsics_vec256_smul64(f210, (uint64_t)5U);
  r5[2U] = Lib_IntVector_Intrinsics_vec256_smul64(f220, (uint64_t)5U);
  r5[3U] = Lib_IntVector_Intrinsics_vec256_smul64(f230, (uint64_t)5U);
  r5[4U] = Lib_IntVector_Intrinsics_vec256_smul64(f240, (uint64_t)5U);
  Lib_IntVector_Intrinsics_vec256 r0 = r[0U];
  Lib_IntVector_Intrinsics_vec256 r10 = r[1U];
  Lib_IntVector_Intrinsics_vec256 r20 = r[2U];
  Lib_IntVector_Intrinsics_vec256 r30 = r[3U];
  Lib_IntVector_Intrinsics_vec256 r40 = r[4U];
  Lib_IntVector_Intrinsics_vec256 r510 = r5[1U];
  Lib_IntVector_Intrinsics_vec256 r520 = r5[2U];
  Lib_IntVector_Intrinsics_vec256 r530 = r5[3U];
  Lib_IntVector_Intrinsics_vec256 r540 = r5[4U];
  Lib_IntVector_Intrinsics_vec256 f100 = r[0U];
  Lib_IntVector_Intrinsics_vec256 f110 = r[1U];
  Lib_IntVector_Intrinsics_vec256 f120 = r[2U];
  Lib_IntVector_Intrinsics_vec256 f130 = r[3U];
  Lib_IntVector_Intrinsics_vec256 f140 = r[4U];
  Lib_IntVector_Intrinsics_vec256 a00 = Lib_IntVector_Intrinsics_vec256_mul64(r0, f100);
  Lib_IntVector_Intrinsics_vec256 a10 = Lib_IntVector_Intrinsics_vec256_mul64(r10, f100);
  Lib_IntVector_Intrinsics_vec256 a20 = Lib_IntVector_Intrinsics_vec256_mul64(r20, f100);
  Lib_IntVector_Intrinsics_vec256 a30 = Lib_IntVector_Intrinsics_vec256_mul64(r30, f100);
  Lib_IntVector_Intrinsics_vec256 a40 = Lib_IntVector_Intrinsics_vec256_mul64(r40, f100);
  Lib_IntVector_Intrinsics_vec256
  a010 =
    Lib_IntVector_Intrinsics_vec256_add64(a00,
      Lib_IntVector_Intrinsics_vec256_mul64(r540, f110));
  Lib_IntVector_Intrinsics_vec256
  a110 =
    Lib_IntVector_Intrinsics_vec256_add64(a10,
      Lib_IntVector_Intrinsics_vec256_mul64(r0, f110));
  Lib_IntVector_Intrinsics_vec256
  a210 =
    Lib_IntVector_Intrinsics_vec256_add64(a20,
      Lib_IntVector_Intrinsics_vec256_mul64(r10, f110));
  Lib_IntVector_Intrinsics_vec256
  a310 =
    Lib_IntVector_Intrinsics_vec256_add64(a30,
      Lib_IntVector_Intrinsics_vec256_mul64(r20, f110));
  Lib_IntVector_Intrinsics_vec256
  a410 =
    Lib_IntVector_Intrinsics_vec256_add64(a40,
      Lib_IntVector_Intrinsics_vec256_mul64(r30, f110));
  Lib_IntVector_Intrinsics_vec256
  a020 =
    Lib_IntVector_Intrinsics_vec256_add64(a010,
      Lib_IntVector_Intrinsics_vec256_mul64(r530, f120));
  Lib_IntVector_Intrinsics_vec256
  a120 =
    Lib_IntVector_Intrinsics_vec256_add64(a110,
      Lib_IntVector_Intrinsics_vec256_mul64(r540, f120));
  Lib_IntVector_Intrinsics_vec256
  a220 =
    Lib_IntVector_Intrinsics_vec256_add64(a210,
      Lib_IntVector_Intrinsics_vec256_mul64(r0, f120));
  Lib_IntVector_Intrinsics_vec256
  a320 =
    Lib_IntVector_Intrinsics_vec256_add64(a310,
      Lib_IntVector_Intrinsics_vec256_mul64(r10, f120));
  Lib_IntVector_Intrinsics_vec256
  a420 =
    Lib_IntVector_Intrinsics_vec256_add64(a410,
      Lib_IntVector_Intrinsics_vec256_mul64(r20, f120));
  Lib_IntVector_Intrinsics_vec256
  a030 =
    Lib_IntVector_Intrinsics_vec256_add64(a020,
      Lib_IntVector_Intrinsics_vec256_mul64(r520, f130));
  Lib_IntVector_Intrinsics_vec256
  a130 =
    Lib_IntVector_Intrinsics_vec256_add64(a120,
      Lib_IntVector_Intrinsics_vec256_mul64(r530, f130));
  Lib_IntVector_Intrinsics_vec256
  a230 =
    Lib_IntVector_Intrinsics_vec256_add64(a220,
      Lib_IntVector_Intrinsics_vec256_mul64(r540, f130));
  Lib_IntVector_Intrinsics_vec256
  a330 =
    Lib_IntVector_Intrinsics_vec256_add64(a320,
      Lib_IntVector_Intrinsics_vec256_mul64(r0, f130));
  Lib_IntVector_Intrinsics_vec256
  a430 =
    Lib_IntVector_Intrinsics_vec256_add64(a420,
      Lib_IntVector_Intrinsics_vec256_mul64(r10, f130));
  Lib_IntVector_Intrinsics_vec256
  a040 =
    Lib_IntVector_Intrinsics_vec256_add64(a030,
      Lib_IntVector_Intrinsics_vec256_mul64(r510, f140));
  Lib_IntVector_Intrinsics_vec256
  a140 =
    Lib_IntVector_Intrinsics_vec256_add64(a130,
      Lib_IntVector_Intrinsics_vec256_mul64(r520, f140));
  Lib_IntVector_Intrinsics_vec256
  a240 =
    Lib_IntVector_Intrinsics_vec256_add64(a230,
      Lib_IntVector_Intrinsics_vec256_mul64(r530, f140));
  Lib_IntVector_Intrinsics_vec256
  a340 =
    Lib_IntVector_Intrinsics_vec256_add64(a330,
      Lib_IntVector_Intrinsics_vec256_mul64(r540, f140));
  Lib_IntVector_Intrinsics_vec256
  a440 =
    Lib_IntVector_Intrinsics_vec256_add64(a430,
      Lib_IntVector_Intrinsics_vec256_mul64(r0, f140));
  Lib_IntVector_Intrinsics_vec256 t00 = a040;
  Lib_IntVector_Intrinsics_vec256 t10 = a140;
  Lib_IntVector_Intrinsics_vec256 t20 = a240;
  Lib_IntVector_Intrinsics_vec256 t30 = a340;
  Lib_IntVector_Intrinsics_vec256 t40 = a440;
  Lib_IntVector_Intrinsics_vec256
  l0 = Lib_IntVector_Intrinsics_vec256_add64(t00, Lib_IntVector_Intrinsics_vec256_zero);
  Lib_IntVector_Intrinsics_vec256
  tmp00 =
    Lib_IntVector_Intrinsics_vec256_and(l0,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c00 = Lib_IntVector_Intrinsics_vec256_shift_right64(l0, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l1 = Lib_IntVector_Intrinsics_vec256_add64(t10, c00);
  Lib_IntVector_Intrinsics_vec256
  tmp10 =
    Lib_IntVector_Intrinsics_vec256_and(l1,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c10 = Lib_IntVector_Intrinsics_vec256_shift_right64(l1, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l2 = Lib_IntVector_Intrinsics_vec256_add64(t20, c10);
  Lib_IntVector_Intrinsics_vec256
  tmp20 =
    Lib_IntVector_Intrinsics_vec256_and(l2,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c20 = Lib_IntVector_Intrinsics_vec256_shift_right64(l2, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l3 = Lib_IntVector_Intrinsics_vec256_add64(t30, c20);
  Lib_IntVector_Intrinsics_vec256
  tmp30 =
    Lib_IntVector_Intrinsics_vec256_and(l3,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c30 = Lib_IntVector_Intrinsics_vec256_shift_right64(l3, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l4 = Lib_IntVector_Intrinsics_vec256_add64(t40, c30);
  Lib_IntVector_Intrinsics_vec256
  tmp40 =
    Lib_IntVector_Intrinsics_vec256_and(l4,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c40 = Lib_IntVector_Intrinsics_vec256_shift_right64(l4, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256
  l5 =
    Lib_IntVector_Intrinsics_vec256_add64(tmp00,
      Lib_IntVector_Intrinsics_vec256_smul64(c40, (uint64_t)5U));
  Lib_IntVector_Intrinsics_vec256
  tmp010 =
    Lib_IntVector_Intrinsics_vec256_and(l5,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c50 = Lib_IntVector_Intrinsics_vec256_shift_right64(l5, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 tmp11 = Lib_IntVector_Intrinsics_vec256_add64(tmp10, c50);
  Lib_IntVector_Intrinsics_vec256 o00 = tmp010;
  Lib_IntVector_Intrinsics_vec256 o10 = tmp11;
  Lib_IntVector_Intrinsics_vec256 o20 = tmp20;
  Lib_IntVector_Intrinsics_vec256 o30 = tmp30;
  Lib_IntVector_Intrinsics_vec256 o40 = tmp40;
  rn[0U] = o00;
  rn[1U] = o10;
  rn[2U] = o20;
  rn[3U] = o30;
  rn[4U] = o40;
  Lib_IntVector_Intrinsics_vec256 f201 = rn[0U];
  Lib_IntVector_Intrinsics_vec256 f211 = rn[1U];
  Lib_IntVector_Intrinsics_vec256 f221 = rn[2U];
  Lib_IntVector_Intrinsics_vec256 f231 = rn[3U];
  Lib_IntVector_Intrinsics_vec256 f241 = rn[4U];
  rn_5[0U] = Lib_IntVector_Intrinsics_vec256_smul64(f201, (uint64_t)5U);
  rn_5[1U] = Lib_IntVector_Intrinsics_vec256_smul64(f211, (uint64_t)5U);
  rn_5[2U] = Lib_IntVector_Intrinsics_vec256_smul64(f221, (uint64_t)5U);
  rn_5[3U] = Lib_IntVector_Intrinsics_vec256_smul64(f231, (uint64_t)5U);
  rn_5[4U] = Lib_IntVector_Intrinsics_vec256_smul64(f241, (uint64_t)5U);
  Lib_IntVector_Intrinsics_vec256 r00 = rn[0U];
  Lib_IntVector_Intrinsics_vec256 r1 = rn[1U];
  Lib_IntVector_Intrinsics_vec256 r2 = rn[2U];
  Lib_IntVector_Intrinsics_vec256 r3 = rn[3U];
  Lib_IntVector_Intrinsics_vec256 r4 = rn[4U];
  Lib_IntVector_Intrinsics_vec256 r51 = rn_5[1U];
  Lib_IntVector_Intrinsics_vec256 r52 = rn_5[2U];
  Lib_IntVector_Intrinsics_vec256 r53 = rn_5[3U];
  Lib_IntVector_Intrinsics_vec256 r54 = rn_5[4U];
  Lib_IntVector_Intrinsics_vec256 f10 = rn[0U];
  Lib_IntVector_Intrinsics_vec256 f11 = rn[1U];
  Lib_IntVector_Intrinsics_vec256 f12 = rn[2U];
  Lib_IntVector_Intrinsics_vec256 f13 = rn[3U];
  Lib_IntVector_Intrinsics_vec256 f14 = rn[4U];
  Lib_IntVector_Intrinsics_vec256 a0 = Lib_IntVector_Intrinsics_vec256_mul64(r00, f10);
  Lib_IntVector_Intrinsics_vec256 a1 = Lib_IntVector_Intrinsics_vec256_mul64(r1, f10);
  Lib_IntVector_Intrinsics_vec256 a2 = Lib_IntVector_Intrinsics_vec256_mul64(r2, f10);
  Lib_IntVector_Intrinsics_vec256 a3 = Lib_IntVector_Intrinsics_vec256_mul64(r3, f10);
  Lib_IntVector_Intrinsics_vec256 a4 = Lib_IntVector_Intrinsics_vec256_mul64(r4, f10);
  Lib_IntVector_Intrinsics_vec256
  a01 =
    Lib_IntVector_Intrinsics_vec256_add64(a0,
      Lib_IntVector_Intrinsics_vec256_mul64(r54, f11));
  Lib_IntVector_Intrinsics_vec256
  a11 =
    Lib_IntVector_Intrinsics_vec256_add64(a1,
      Lib_IntVector_Intrinsics_vec256_mul64(r00, f11));
  Lib_IntVector_Intrinsics_vec256
  a21 = Lib_IntVector_Intrinsics_vec256_add64(a2, Lib_IntVector_Intrinsics_vec256_mul64(r1, f11));
  Lib_IntVector_Intrinsics_vec256
  a31 = Lib_IntVector_Intrinsics_vec256_add64(a3, Lib_IntVector_Intrinsics_vec256_mul64(r2, f11));
  Lib_IntVector_Intrinsics_vec256
  a41 = Lib_IntVector_Intrinsics_vec256_add64(a4, Lib_IntVector_Intrinsics_vec256_mul64(r3, f11));
  Lib_IntVector_Intrinsics_vec256
  a02 =
    Lib_IntVector_Intrinsics_vec256_add64(a01,
      Lib_IntVector_Intrinsics_vec256_mul64(r53, f12));
  Lib_IntVector_Intrinsics_vec256
  a12 =
    Lib_IntVector_Intrinsics_vec256_add64(a11,
      Lib_IntVector_Intrinsics_vec256_mul64(r54, f12));
  Lib_IntVector_Intrinsics_vec256
  a22 =
    Lib_IntVector_Intrinsics_vec256_add64(a21,
      Lib_IntVector_Intrinsics_vec256_mul64(r00, f12));
  Lib_IntVector_Intrinsics_vec256
  a32 =
    Lib_IntVector_Intrinsics_vec256_add64(a31,
      Lib_IntVector_Intrinsics_vec256_mul64(r1, f12));
  Lib_IntVector_Intrinsics_vec256
  a42 =
    Lib_IntVector_Intrinsics_vec256_add64(a41,
      Lib_IntVector_Intrinsics_vec256_mul64(r2, f12));
  Lib_IntVector_Intrinsics_vec256
  a03 =
    Lib_IntVector_Intrinsics_vec256_add64(a02,
      Lib_IntVector_Intrinsics_vec256_mul64(r52, f13));
  Lib_IntVector_Intrinsics_vec256
  a13 =
    Lib_IntVector_Intrinsics_vec256_add64(a12,
      Lib_IntVector_Intrinsics_vec256_mul64(r53, f13));
  Lib_IntVector_Intrinsics_vec256
  a23 =
    Lib_IntVector_Intrinsics_vec256_add64(a22,
      Lib_IntVector_Intrinsics_vec256_mul64(r54, f13));
  Lib_IntVector_Intrinsics_vec256
  a33 =
    Lib_IntVector_Intrinsics_vec256_add64(a32,
      Lib_IntVector_Intrinsics_vec256_mul64(r00, f13));
  Lib_IntVector_Intrinsics_vec256
  a43 =
    Lib_IntVector_Intrinsics_vec256_add64(a42,
      Lib_IntVector_Intrinsics_vec256_mul64(r1, f13));
  Lib_IntVector_Intrinsics_vec256
  a04 =
    Lib_IntVector_Intrinsics_vec256_add64(a03,
      Lib_IntVector_Intrinsics_vec256_mul64(r51, f14));
  Lib_IntVector_Intrinsics_vec256
  a14 =
    Lib_IntVector_Intrinsics_vec256_add64(a13,
      Lib_IntVector_Intrinsics_vec256_mul64(r52, f14));
  Lib_IntVector_Intrinsics_vec256
  a24 =
    Lib_IntVector_Intrinsics_vec256_add64(a23,
      Lib_IntVector_Intrinsics_vec256_mul64(r53, f14));
  Lib_IntVector_Intrinsics_vec256
  a34 =
    Lib_IntVector_Intrinsics_vec256_add64(a33,
      Lib_IntVector_Intrinsics_vec256_mul64(r54, f14));
  Lib_IntVector_Intrinsics_vec256
  a44 =
    Lib_IntVector_Intrinsics_vec256_add64(a43,
      Lib_IntVector_Intrinsics_vec256_mul64(r00, f14));
  Lib_IntVector_Intrinsics_vec256 t0 = a04;
  Lib_IntVector_Intrinsics_vec256 t1 = a14;
  Lib_IntVector_Intrinsics_vec256 t2 = a24;
  Lib_IntVector_Intrinsics_vec256 t3 = a34;
  Lib_IntVector_Intrinsics_vec256 t4 = a44;
  Lib_IntVector_Intrinsics_vec256
  l = Lib_IntVector_Intrinsics_vec256_add64(t0, Lib_IntVector_Intrinsics_vec256_zero);
  Lib_IntVector_Intrinsics_vec256
  tmp0 =
    Lib_IntVector_Intrinsics_vec256_and(l,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c0 = Lib_IntVector_Intrinsics_vec256_shift_right64(l, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l6 = Lib_IntVector_Intrinsics_vec256_add64(t1, c0);
  Lib_IntVector_Intrinsics_vec256
  tmp1 =
    Lib_IntVector_Intrinsics_vec256_and(l6,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c1 = Lib_IntVector_Intrinsics_vec256_shift_right64(l6, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l7 = Lib_IntVector_Intrinsics_vec256_add64(t2, c1);
  Lib_IntVector_Intrinsics_vec256
  tmp2 =
    Lib_IntVector_Intrinsics_vec256_and(l7,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c2 = Lib_IntVector_Intrinsics_vec256_shift_right64(l7, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l8 = Lib_IntVector_Intrinsics_vec256_add64(t3, c2);
  Lib_IntVector_Intrinsics_vec256
  tmp3 =
    Lib_IntVector_Intrinsics_vec256_and(l8,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c3 = Lib_IntVector_Intrinsics_vec256_shift_right64(l8, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l9 = Lib_IntVector_Intrinsics_vec256_add64(t4, c3);
  Lib_IntVector_Intrinsics_vec256
  tmp4 =
    Lib_IntVector_Intrinsics_vec256_and(l9,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c4 = Lib_IntVector_Intrinsics_vec256_shift_right64(l9, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256
  l10 =
    Lib_IntVector_Intrinsics_vec256_add64(tmp0,
      Lib_IntVector_Intrinsics_vec256_smul64(c4, (uint64_t)5U));
  Lib_IntVector_Intrinsics_vec256
  tmp01 =
    Lib_IntVector_Intrinsics_vec256_and(l10,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c5 = Lib_IntVector_Intrinsics_vec256_shift_right64(l10, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 tmp110 = Lib_IntVector_Intrinsics_vec256_add64(tmp1, c5);
  Lib_IntVector_Intrinsics_vec256 o0 = tmp01;
  Lib_IntVector_Intrinsics_vec256 o1 = tmp110;
  Lib_IntVector_Intrinsics_vec256 o2 = tmp2;
  Lib_IntVector_Intrinsics_vec256 o3 = tmp3;
  Lib_IntVector_Intrinsics_vec256 o4 = tmp4;
  rn[0U] = o0;
  rn[1U] = o1;
  rn[2U] = o2;
  rn[3U] = o3;
  rn[4U] = o4;
  Lib_IntVector_Intrinsics_vec256 f202 = rn[0U];
  Lib_IntVector_Intrinsics_vec256 f21 = rn[1U];
  Lib_IntVector_Intrinsics_vec256 f22 = rn[2U];
  Lib_IntVector_Intrinsics_vec256 f23 = rn[3U];
  Lib_IntVector_Intrinsics_vec256 f24 = rn[4U];
  rn_5[0U] = Lib_IntVector_Intrinsics_vec256_smul64(f202, (uint64_t)5U);
  rn_5[1U] = Lib_IntVector_Intrinsics_vec256_smul64(f21, (uint64_t)5U);
  rn_5[2U] = Lib_IntVector_Intrinsics_vec256_smul64(f22, (uint64_t)5U);
  rn_5[3U] = Lib_IntVector_Intrinsics_vec256_smul64(f23, (uint64_t)5U);
  rn_5[4U] = Lib_IntVector_Intrinsics_vec256_smul64(f24, (uint64_t)5U);
}

inline void Hacl_Impl_Poly1305_poly1305_update_32(uint64_t *ctx, uint32_t len1, uint8_t *text)
{
  uint64_t *pre = ctx + (uint32_t)5U;
  uint64_t *acc = ctx;
  uint32_t nb = len1 / (uint32_t)16U;
  uint32_t rem1 = len1 % (uint32_t)16U;
  for (uint32_t i = (uint32_t)0U; i < nb; i = i + (uint32_t)1U)
  {
    uint8_t *block = text + i * (uint32_t)16U;
    uint64_t e[5U] = { 0U };
    uint64_t u0 = load64_le(block);
    uint64_t lo = u0;
    uint64_t u = load64_le(block + (uint32_t)8U);
    uint64_t hi = u;
    uint64_t f0 = lo;
    uint64_t f1 = hi;
    uint64_t f010 = f0 & (uint64_t)0x3ffffffU;
    uint64_t f110 = f0 >> (uint32_t)26U & (uint64_t)0x3ffffffU;
    uint64_t f20 = f0 >> (uint32_t)52U | (f1 & (uint64_t)0x3fffU) << (uint32_t)12U;
    uint64_t f30 = f1 >> (uint32_t)14U & (uint64_t)0x3ffffffU;
    uint64_t f40 = f1 >> (uint32_t)40U;
    uint64_t f01 = f010;
    uint64_t f111 = f110;
    uint64_t f2 = f20;
    uint64_t f3 = f30;
    uint64_t f41 = f40;
    e[0U] = f01;
    e[1U] = f111;
    e[2U] = f2;
    e[3U] = f3;
    e[4U] = f41;
    uint64_t b = (uint64_t)0x1000000U;
    uint64_t mask = b;
    uint64_t f4 = e[4U];
    e[4U] = f4 | mask;
    uint64_t *r = pre;
    uint64_t *r5 = pre + (uint32_t)5U;
    uint64_t r0 = r[0U];
    uint64_t r1 = r[1U];
    uint64_t r2 = r[2U];
    uint64_t r3 = r[3U];
    uint64_t r4 = r[4U];
    uint64_t r51 = r5[1U];
    uint64_t r52 = r5[2U];
    uint64_t r53 = r5[3U];
    uint64_t r54 = r5[4U];
    uint64_t f10 = e[0U];
    uint64_t f11 = e[1U];
    uint64_t f12 = e[2U];
    uint64_t f13 = e[3U];
    uint64_t f14 = e[4U];
    uint64_t a0 = acc[0U];
    uint64_t a1 = acc[1U];
    uint64_t a2 = acc[2U];
    uint64_t a3 = acc[3U];
    uint64_t a4 = acc[4U];
    uint64_t a01 = a0 + f10;
    uint64_t a11 = a1 + f11;
    uint64_t a21 = a2 + f12;
    uint64_t a31 = a3 + f13;
    uint64_t a41 = a4 + f14;
    uint64_t a02 = r0 * a01;
    uint64_t a12 = r1 * a01;
    uint64_t a22 = r2 * a01;
    uint64_t a32 = r3 * a01;
    uint64_t a42 = r4 * a01;
    uint64_t a03 = a02 + r54 * a11;
    uint64_t a13 = a12 + r0 * a11;
    uint64_t a23 = a22 + r1 * a11;
    uint64_t a33 = a32 + r2 * a11;
    uint64_t a43 = a42 + r3 * a11;
    uint64_t a04 = a03 + r53 * a21;
    uint64_t a14 = a13 + r54 * a21;
    uint64_t a24 = a23 + r0 * a21;
    uint64_t a34 = a33 + r1 * a21;
    uint64_t a44 = a43 + r2 * a21;
    uint64_t a05 = a04 + r52 * a31;
    uint64_t a15 = a14 + r53 * a31;
    uint64_t a25 = a24 + r54 * a31;
    uint64_t a35 = a34 + r0 * a31;
    uint64_t a45 = a44 + r1 * a31;
    uint64_t a06 = a05 + r51 * a41;
    uint64_t a16 = a15 + r52 * a41;
    uint64_t a26 = a25 + r53 * a41;
    uint64_t a36 = a35 + r54 * a41;
    uint64_t a46 = a45 + r0 * a41;
    uint64_t t0 = a06;
    uint64_t t1 = a16;
    uint64_t t2 = a26;
    uint64_t t3 = a36;
    uint64_t t4 = a46;
    uint64_t l = t0 + (uint64_t)0U;
    uint64_t tmp0 = l & (uint64_t)0x3ffffffU;
    uint64_t c0 = l >> (uint32_t)26U;
    uint64_t l0 = t1 + c0;
    uint64_t tmp1 = l0 & (uint64_t)0x3ffffffU;
    uint64_t c1 = l0 >> (uint32_t)26U;
    uint64_t l1 = t2 + c1;
    uint64_t tmp2 = l1 & (uint64_t)0x3ffffffU;
    uint64_t c2 = l1 >> (uint32_t)26U;
    uint64_t l2 = t3 + c2;
    uint64_t tmp3 = l2 & (uint64_t)0x3ffffffU;
    uint64_t c3 = l2 >> (uint32_t)26U;
    uint64_t l3 = t4 + c3;
    uint64_t tmp4 = l3 & (uint64_t)0x3ffffffU;
    uint64_t c4 = l3 >> (uint32_t)26U;
    uint64_t l4 = tmp0 + c4 * (uint64_t)5U;
    uint64_t tmp01 = l4 & (uint64_t)0x3ffffffU;
    uint64_t c5 = l4 >> (uint32_t)26U;
    uint64_t tmp11 = tmp1 + c5;
    uint64_t o0 = tmp01;
    uint64_t o1 = tmp11;
    uint64_t o2 = tmp2;
    uint64_t o3 = tmp3;
    uint64_t o4 = tmp4;
    acc[0U] = o0;
    acc[1U] = o1;
    acc[2U] = o2;
    acc[3U] = o3;
    acc[4U] = o4;
  }
  uint8_t *b = text + nb * (uint32_t)16U;
  if (rem1 > (uint32_t)0U)
  {
    uint64_t e[5U] = { 0U };
    uint8_t tmp[16U] = { 0U };
    memcpy(tmp, b, rem1 * sizeof b[0U]);
    uint64_t u0 = load64_le(tmp);
    uint64_t lo = u0;
    uint64_t u = load64_le(tmp + (uint32_t)8U);
    uint64_t hi = u;
    uint64_t f0 = lo;
    uint64_t f1 = hi;
    uint64_t f010 = f0 & (uint64_t)0x3ffffffU;
    uint64_t f110 = f0 >> (uint32_t)26U & (uint64_t)0x3ffffffU;
    uint64_t f20 = f0 >> (uint32_t)52U | (f1 & (uint64_t)0x3fffU) << (uint32_t)12U;
    uint64_t f30 = f1 >> (uint32_t)14U & (uint64_t)0x3ffffffU;
    uint64_t f40 = f1 >> (uint32_t)40U;
    uint64_t f01 = f010;
    uint64_t f111 = f110;
    uint64_t f2 = f20;
    uint64_t f3 = f30;
    uint64_t f4 = f40;
    e[0U] = f01;
    e[1U] = f111;
    e[2U] = f2;
    e[3U] = f3;
    e[4U] = f4;
    uint64_t b1 = (uint64_t)1U << rem1 * (uint32_t)8U % (uint32_t)26U;
    uint64_t mask = b1;
    uint64_t fi = e[rem1 * (uint32_t)8U / (uint32_t)26U];
    e[rem1 * (uint32_t)8U / (uint32_t)26U] = fi | mask;
    uint64_t *r = pre;
    uint64_t *r5 = pre + (uint32_t)5U;
    uint64_t r0 = r[0U];
    uint64_t r1 = r[1U];
    uint64_t r2 = r[2U];
    uint64_t r3 = r[3U];
    uint64_t r4 = r[4U];
    uint64_t r51 = r5[1U];
    uint64_t r52 = r5[2U];
    uint64_t r53 = r5[3U];
    uint64_t r54 = r5[4U];
    uint64_t f10 = e[0U];
    uint64_t f11 = e[1U];
    uint64_t f12 = e[2U];
    uint64_t f13 = e[3U];
    uint64_t f14 = e[4U];
    uint64_t a0 = acc[0U];
    uint64_t a1 = acc[1U];
    uint64_t a2 = acc[2U];
    uint64_t a3 = acc[3U];
    uint64_t a4 = acc[4U];
    uint64_t a01 = a0 + f10;
    uint64_t a11 = a1 + f11;
    uint64_t a21 = a2 + f12;
    uint64_t a31 = a3 + f13;
    uint64_t a41 = a4 + f14;
    uint64_t a02 = r0 * a01;
    uint64_t a12 = r1 * a01;
    uint64_t a22 = r2 * a01;
    uint64_t a32 = r3 * a01;
    uint64_t a42 = r4 * a01;
    uint64_t a03 = a02 + r54 * a11;
    uint64_t a13 = a12 + r0 * a11;
    uint64_t a23 = a22 + r1 * a11;
    uint64_t a33 = a32 + r2 * a11;
    uint64_t a43 = a42 + r3 * a11;
    uint64_t a04 = a03 + r53 * a21;
    uint64_t a14 = a13 + r54 * a21;
    uint64_t a24 = a23 + r0 * a21;
    uint64_t a34 = a33 + r1 * a21;
    uint64_t a44 = a43 + r2 * a21;
    uint64_t a05 = a04 + r52 * a31;
    uint64_t a15 = a14 + r53 * a31;
    uint64_t a25 = a24 + r54 * a31;
    uint64_t a35 = a34 + r0 * a31;
    uint64_t a45 = a44 + r1 * a31;
    uint64_t a06 = a05 + r51 * a41;
    uint64_t a16 = a15 + r52 * a41;
    uint64_t a26 = a25 + r53 * a41;
    uint64_t a36 = a35 + r54 * a41;
    uint64_t a46 = a45 + r0 * a41;
    uint64_t t0 = a06;
    uint64_t t1 = a16;
    uint64_t t2 = a26;
    uint64_t t3 = a36;
    uint64_t t4 = a46;
    uint64_t l = t0 + (uint64_t)0U;
    uint64_t tmp0 = l & (uint64_t)0x3ffffffU;
    uint64_t c0 = l >> (uint32_t)26U;
    uint64_t l0 = t1 + c0;
    uint64_t tmp1 = l0 & (uint64_t)0x3ffffffU;
    uint64_t c1 = l0 >> (uint32_t)26U;
    uint64_t l1 = t2 + c1;
    uint64_t tmp2 = l1 & (uint64_t)0x3ffffffU;
    uint64_t c2 = l1 >> (uint32_t)26U;
    uint64_t l2 = t3 + c2;
    uint64_t tmp3 = l2 & (uint64_t)0x3ffffffU;
    uint64_t c3 = l2 >> (uint32_t)26U;
    uint64_t l3 = t4 + c3;
    uint64_t tmp4 = l3 & (uint64_t)0x3ffffffU;
    uint64_t c4 = l3 >> (uint32_t)26U;
    uint64_t l4 = tmp0 + c4 * (uint64_t)5U;
    uint64_t tmp01 = l4 & (uint64_t)0x3ffffffU;
    uint64_t c5 = l4 >> (uint32_t)26U;
    uint64_t tmp11 = tmp1 + c5;
    uint64_t o0 = tmp01;
    uint64_t o1 = tmp11;
    uint64_t o2 = tmp2;
    uint64_t o3 = tmp3;
    uint64_t o4 = tmp4;
    acc[0U] = o0;
    acc[1U] = o1;
    acc[2U] = o2;
    acc[3U] = o3;
    acc[4U] = o4;
  }
}

inline static void
Hacl_Impl_Poly1305_poly1305_update_128(
  Lib_IntVector_Intrinsics_vec128 *ctx,
  uint32_t len1,
  uint8_t *text
)
{
  Lib_IntVector_Intrinsics_vec128 *pre = ctx + (uint32_t)5U;
  Lib_IntVector_Intrinsics_vec128 *acc = ctx;
  uint32_t sz_block = (uint32_t)32U;
  uint32_t len0 = len1 / sz_block * sz_block;
  uint8_t *t0 = text;
  uint32_t bs = (uint32_t)32U;
  uint32_t nb0 = len0 / bs;
  for (uint32_t i = (uint32_t)0U; i < nb0; i = i + (uint32_t)1U)
  {
    uint8_t *block = t0 + i * bs;
    KRML_CHECK_SIZE(sizeof (Lib_IntVector_Intrinsics_vec128), (uint32_t)5U);
    Lib_IntVector_Intrinsics_vec128 e[5U];
    for (uint32_t _i = 0U; _i < (uint32_t)5U; ++_i)
      e[_i] = Lib_IntVector_Intrinsics_vec128_zero;
    Lib_IntVector_Intrinsics_vec128 b1 = Lib_IntVector_Intrinsics_vec128_load_le(block);
    Lib_IntVector_Intrinsics_vec128
    b2 = Lib_IntVector_Intrinsics_vec128_load_le(block + (uint32_t)16U);
    Lib_IntVector_Intrinsics_vec128 lo = Lib_IntVector_Intrinsics_vec128_interleave_low64(b1, b2);
    Lib_IntVector_Intrinsics_vec128 hi = Lib_IntVector_Intrinsics_vec128_interleave_high64(b1, b2);
    Lib_IntVector_Intrinsics_vec128
    f00 =
      Lib_IntVector_Intrinsics_vec128_and(lo,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    f15 =
      Lib_IntVector_Intrinsics_vec128_and(Lib_IntVector_Intrinsics_vec128_shift_right64(lo,
          (uint32_t)26U),
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    f25 =
      Lib_IntVector_Intrinsics_vec128_or(Lib_IntVector_Intrinsics_vec128_shift_right64(lo,
          (uint32_t)52U),
        Lib_IntVector_Intrinsics_vec128_shift_left64(Lib_IntVector_Intrinsics_vec128_and(hi,
            Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3fffU)),
          (uint32_t)12U));
    Lib_IntVector_Intrinsics_vec128
    f30 =
      Lib_IntVector_Intrinsics_vec128_and(Lib_IntVector_Intrinsics_vec128_shift_right64(hi,
          (uint32_t)14U),
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    f40 = Lib_IntVector_Intrinsics_vec128_shift_right64(hi, (uint32_t)40U);
    Lib_IntVector_Intrinsics_vec128 f0 = f00;
    Lib_IntVector_Intrinsics_vec128 f1 = f15;
    Lib_IntVector_Intrinsics_vec128 f2 = f25;
    Lib_IntVector_Intrinsics_vec128 f3 = f30;
    Lib_IntVector_Intrinsics_vec128 f41 = f40;
    e[0U] = f0;
    e[1U] = f1;
    e[2U] = f2;
    e[3U] = f3;
    e[4U] = f41;
    uint64_t b = (uint64_t)0x1000000U;
    Lib_IntVector_Intrinsics_vec128 mask = Lib_IntVector_Intrinsics_vec128_load64(b);
    Lib_IntVector_Intrinsics_vec128 f4 = e[4U];
    e[4U] = Lib_IntVector_Intrinsics_vec128_or(f4, mask);
    Lib_IntVector_Intrinsics_vec128 *rn = pre + (uint32_t)10U;
    Lib_IntVector_Intrinsics_vec128 *rn5 = pre + (uint32_t)15U;
    Lib_IntVector_Intrinsics_vec128 r0 = rn[0U];
    Lib_IntVector_Intrinsics_vec128 r1 = rn[1U];
    Lib_IntVector_Intrinsics_vec128 r2 = rn[2U];
    Lib_IntVector_Intrinsics_vec128 r3 = rn[3U];
    Lib_IntVector_Intrinsics_vec128 r4 = rn[4U];
    Lib_IntVector_Intrinsics_vec128 r51 = rn5[1U];
    Lib_IntVector_Intrinsics_vec128 r52 = rn5[2U];
    Lib_IntVector_Intrinsics_vec128 r53 = rn5[3U];
    Lib_IntVector_Intrinsics_vec128 r54 = rn5[4U];
    Lib_IntVector_Intrinsics_vec128 f10 = acc[0U];
    Lib_IntVector_Intrinsics_vec128 f110 = acc[1U];
    Lib_IntVector_Intrinsics_vec128 f120 = acc[2U];
    Lib_IntVector_Intrinsics_vec128 f130 = acc[3U];
    Lib_IntVector_Intrinsics_vec128 f140 = acc[4U];
    Lib_IntVector_Intrinsics_vec128 a0 = Lib_IntVector_Intrinsics_vec128_mul64(r0, f10);
    Lib_IntVector_Intrinsics_vec128 a1 = Lib_IntVector_Intrinsics_vec128_mul64(r1, f10);
    Lib_IntVector_Intrinsics_vec128 a2 = Lib_IntVector_Intrinsics_vec128_mul64(r2, f10);
    Lib_IntVector_Intrinsics_vec128 a3 = Lib_IntVector_Intrinsics_vec128_mul64(r3, f10);
    Lib_IntVector_Intrinsics_vec128 a4 = Lib_IntVector_Intrinsics_vec128_mul64(r4, f10);
    Lib_IntVector_Intrinsics_vec128
    a01 =
      Lib_IntVector_Intrinsics_vec128_add64(a0,
        Lib_IntVector_Intrinsics_vec128_mul64(r54, f110));
    Lib_IntVector_Intrinsics_vec128
    a11 =
      Lib_IntVector_Intrinsics_vec128_add64(a1,
        Lib_IntVector_Intrinsics_vec128_mul64(r0, f110));
    Lib_IntVector_Intrinsics_vec128
    a21 =
      Lib_IntVector_Intrinsics_vec128_add64(a2,
        Lib_IntVector_Intrinsics_vec128_mul64(r1, f110));
    Lib_IntVector_Intrinsics_vec128
    a31 =
      Lib_IntVector_Intrinsics_vec128_add64(a3,
        Lib_IntVector_Intrinsics_vec128_mul64(r2, f110));
    Lib_IntVector_Intrinsics_vec128
    a41 =
      Lib_IntVector_Intrinsics_vec128_add64(a4,
        Lib_IntVector_Intrinsics_vec128_mul64(r3, f110));
    Lib_IntVector_Intrinsics_vec128
    a02 =
      Lib_IntVector_Intrinsics_vec128_add64(a01,
        Lib_IntVector_Intrinsics_vec128_mul64(r53, f120));
    Lib_IntVector_Intrinsics_vec128
    a12 =
      Lib_IntVector_Intrinsics_vec128_add64(a11,
        Lib_IntVector_Intrinsics_vec128_mul64(r54, f120));
    Lib_IntVector_Intrinsics_vec128
    a22 =
      Lib_IntVector_Intrinsics_vec128_add64(a21,
        Lib_IntVector_Intrinsics_vec128_mul64(r0, f120));
    Lib_IntVector_Intrinsics_vec128
    a32 =
      Lib_IntVector_Intrinsics_vec128_add64(a31,
        Lib_IntVector_Intrinsics_vec128_mul64(r1, f120));
    Lib_IntVector_Intrinsics_vec128
    a42 =
      Lib_IntVector_Intrinsics_vec128_add64(a41,
        Lib_IntVector_Intrinsics_vec128_mul64(r2, f120));
    Lib_IntVector_Intrinsics_vec128
    a03 =
      Lib_IntVector_Intrinsics_vec128_add64(a02,
        Lib_IntVector_Intrinsics_vec128_mul64(r52, f130));
    Lib_IntVector_Intrinsics_vec128
    a13 =
      Lib_IntVector_Intrinsics_vec128_add64(a12,
        Lib_IntVector_Intrinsics_vec128_mul64(r53, f130));
    Lib_IntVector_Intrinsics_vec128
    a23 =
      Lib_IntVector_Intrinsics_vec128_add64(a22,
        Lib_IntVector_Intrinsics_vec128_mul64(r54, f130));
    Lib_IntVector_Intrinsics_vec128
    a33 =
      Lib_IntVector_Intrinsics_vec128_add64(a32,
        Lib_IntVector_Intrinsics_vec128_mul64(r0, f130));
    Lib_IntVector_Intrinsics_vec128
    a43 =
      Lib_IntVector_Intrinsics_vec128_add64(a42,
        Lib_IntVector_Intrinsics_vec128_mul64(r1, f130));
    Lib_IntVector_Intrinsics_vec128
    a04 =
      Lib_IntVector_Intrinsics_vec128_add64(a03,
        Lib_IntVector_Intrinsics_vec128_mul64(r51, f140));
    Lib_IntVector_Intrinsics_vec128
    a14 =
      Lib_IntVector_Intrinsics_vec128_add64(a13,
        Lib_IntVector_Intrinsics_vec128_mul64(r52, f140));
    Lib_IntVector_Intrinsics_vec128
    a24 =
      Lib_IntVector_Intrinsics_vec128_add64(a23,
        Lib_IntVector_Intrinsics_vec128_mul64(r53, f140));
    Lib_IntVector_Intrinsics_vec128
    a34 =
      Lib_IntVector_Intrinsics_vec128_add64(a33,
        Lib_IntVector_Intrinsics_vec128_mul64(r54, f140));
    Lib_IntVector_Intrinsics_vec128
    a44 =
      Lib_IntVector_Intrinsics_vec128_add64(a43,
        Lib_IntVector_Intrinsics_vec128_mul64(r0, f140));
    Lib_IntVector_Intrinsics_vec128 t01 = a04;
    Lib_IntVector_Intrinsics_vec128 t1 = a14;
    Lib_IntVector_Intrinsics_vec128 t2 = a24;
    Lib_IntVector_Intrinsics_vec128 t3 = a34;
    Lib_IntVector_Intrinsics_vec128 t4 = a44;
    Lib_IntVector_Intrinsics_vec128
    l = Lib_IntVector_Intrinsics_vec128_add64(t01, Lib_IntVector_Intrinsics_vec128_zero);
    Lib_IntVector_Intrinsics_vec128
    tmp0 =
      Lib_IntVector_Intrinsics_vec128_and(l,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    c0 = Lib_IntVector_Intrinsics_vec128_shift_right64(l, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec128 l0 = Lib_IntVector_Intrinsics_vec128_add64(t1, c0);
    Lib_IntVector_Intrinsics_vec128
    tmp1 =
      Lib_IntVector_Intrinsics_vec128_and(l0,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    c1 = Lib_IntVector_Intrinsics_vec128_shift_right64(l0, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec128 l1 = Lib_IntVector_Intrinsics_vec128_add64(t2, c1);
    Lib_IntVector_Intrinsics_vec128
    tmp2 =
      Lib_IntVector_Intrinsics_vec128_and(l1,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    c2 = Lib_IntVector_Intrinsics_vec128_shift_right64(l1, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec128 l2 = Lib_IntVector_Intrinsics_vec128_add64(t3, c2);
    Lib_IntVector_Intrinsics_vec128
    tmp3 =
      Lib_IntVector_Intrinsics_vec128_and(l2,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    c3 = Lib_IntVector_Intrinsics_vec128_shift_right64(l2, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec128 l3 = Lib_IntVector_Intrinsics_vec128_add64(t4, c3);
    Lib_IntVector_Intrinsics_vec128
    tmp4 =
      Lib_IntVector_Intrinsics_vec128_and(l3,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    c4 = Lib_IntVector_Intrinsics_vec128_shift_right64(l3, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec128
    l4 =
      Lib_IntVector_Intrinsics_vec128_add64(tmp0,
        Lib_IntVector_Intrinsics_vec128_smul64(c4, (uint64_t)5U));
    Lib_IntVector_Intrinsics_vec128
    tmp01 =
      Lib_IntVector_Intrinsics_vec128_and(l4,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    c5 = Lib_IntVector_Intrinsics_vec128_shift_right64(l4, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec128 tmp11 = Lib_IntVector_Intrinsics_vec128_add64(tmp1, c5);
    Lib_IntVector_Intrinsics_vec128 o00 = tmp01;
    Lib_IntVector_Intrinsics_vec128 o10 = tmp11;
    Lib_IntVector_Intrinsics_vec128 o20 = tmp2;
    Lib_IntVector_Intrinsics_vec128 o30 = tmp3;
    Lib_IntVector_Intrinsics_vec128 o40 = tmp4;
    acc[0U] = o00;
    acc[1U] = o10;
    acc[2U] = o20;
    acc[3U] = o30;
    acc[4U] = o40;
    Lib_IntVector_Intrinsics_vec128 f100 = acc[0U];
    Lib_IntVector_Intrinsics_vec128 f11 = acc[1U];
    Lib_IntVector_Intrinsics_vec128 f12 = acc[2U];
    Lib_IntVector_Intrinsics_vec128 f13 = acc[3U];
    Lib_IntVector_Intrinsics_vec128 f14 = acc[4U];
    Lib_IntVector_Intrinsics_vec128 f20 = e[0U];
    Lib_IntVector_Intrinsics_vec128 f21 = e[1U];
    Lib_IntVector_Intrinsics_vec128 f22 = e[2U];
    Lib_IntVector_Intrinsics_vec128 f23 = e[3U];
    Lib_IntVector_Intrinsics_vec128 f24 = e[4U];
    Lib_IntVector_Intrinsics_vec128 o0 = Lib_IntVector_Intrinsics_vec128_add64(f100, f20);
    Lib_IntVector_Intrinsics_vec128 o1 = Lib_IntVector_Intrinsics_vec128_add64(f11, f21);
    Lib_IntVector_Intrinsics_vec128 o2 = Lib_IntVector_Intrinsics_vec128_add64(f12, f22);
    Lib_IntVector_Intrinsics_vec128 o3 = Lib_IntVector_Intrinsics_vec128_add64(f13, f23);
    Lib_IntVector_Intrinsics_vec128 o4 = Lib_IntVector_Intrinsics_vec128_add64(f14, f24);
    acc[0U] = o0;
    acc[1U] = o1;
    acc[2U] = o2;
    acc[3U] = o3;
    acc[4U] = o4;
  }
  Lib_IntVector_Intrinsics_vec128 *r = pre;
  Lib_IntVector_Intrinsics_vec128 *r25 = pre + (uint32_t)10U;
  Lib_IntVector_Intrinsics_vec128 a00 = acc[0U];
  Lib_IntVector_Intrinsics_vec128 a10 = acc[1U];
  Lib_IntVector_Intrinsics_vec128 a20 = acc[2U];
  Lib_IntVector_Intrinsics_vec128 a30 = acc[3U];
  Lib_IntVector_Intrinsics_vec128 a40 = acc[4U];
  Lib_IntVector_Intrinsics_vec128 r10 = r[0U];
  Lib_IntVector_Intrinsics_vec128 r11 = r[1U];
  Lib_IntVector_Intrinsics_vec128 r12 = r[2U];
  Lib_IntVector_Intrinsics_vec128 r13 = r[3U];
  Lib_IntVector_Intrinsics_vec128 r14 = r[4U];
  Lib_IntVector_Intrinsics_vec128 r20 = r25[0U];
  Lib_IntVector_Intrinsics_vec128 r21 = r25[1U];
  Lib_IntVector_Intrinsics_vec128 r22 = r25[2U];
  Lib_IntVector_Intrinsics_vec128 r23 = r25[3U];
  Lib_IntVector_Intrinsics_vec128 r24 = r25[4U];
  Lib_IntVector_Intrinsics_vec128
  r201 = Lib_IntVector_Intrinsics_vec128_interleave_low64(r20, r10);
  Lib_IntVector_Intrinsics_vec128
  r211 = Lib_IntVector_Intrinsics_vec128_interleave_low64(r21, r11);
  Lib_IntVector_Intrinsics_vec128
  r221 = Lib_IntVector_Intrinsics_vec128_interleave_low64(r22, r12);
  Lib_IntVector_Intrinsics_vec128
  r231 = Lib_IntVector_Intrinsics_vec128_interleave_low64(r23, r13);
  Lib_IntVector_Intrinsics_vec128
  r241 = Lib_IntVector_Intrinsics_vec128_interleave_low64(r24, r14);
  Lib_IntVector_Intrinsics_vec128
  r250 = Lib_IntVector_Intrinsics_vec128_smul64(r201, (uint64_t)5U);
  Lib_IntVector_Intrinsics_vec128
  r251 = Lib_IntVector_Intrinsics_vec128_smul64(r211, (uint64_t)5U);
  Lib_IntVector_Intrinsics_vec128
  r252 = Lib_IntVector_Intrinsics_vec128_smul64(r221, (uint64_t)5U);
  Lib_IntVector_Intrinsics_vec128
  r253 = Lib_IntVector_Intrinsics_vec128_smul64(r231, (uint64_t)5U);
  Lib_IntVector_Intrinsics_vec128
  r254 = Lib_IntVector_Intrinsics_vec128_smul64(r241, (uint64_t)5U);
  Lib_IntVector_Intrinsics_vec128 a010 = Lib_IntVector_Intrinsics_vec128_mul64(r201, a00);
  Lib_IntVector_Intrinsics_vec128 a110 = Lib_IntVector_Intrinsics_vec128_mul64(r211, a00);
  Lib_IntVector_Intrinsics_vec128 a210 = Lib_IntVector_Intrinsics_vec128_mul64(r221, a00);
  Lib_IntVector_Intrinsics_vec128 a310 = Lib_IntVector_Intrinsics_vec128_mul64(r231, a00);
  Lib_IntVector_Intrinsics_vec128 a410 = Lib_IntVector_Intrinsics_vec128_mul64(r241, a00);
  Lib_IntVector_Intrinsics_vec128
  a020 =
    Lib_IntVector_Intrinsics_vec128_add64(a010,
      Lib_IntVector_Intrinsics_vec128_mul64(r254, a10));
  Lib_IntVector_Intrinsics_vec128
  a120 =
    Lib_IntVector_Intrinsics_vec128_add64(a110,
      Lib_IntVector_Intrinsics_vec128_mul64(r201, a10));
  Lib_IntVector_Intrinsics_vec128
  a220 =
    Lib_IntVector_Intrinsics_vec128_add64(a210,
      Lib_IntVector_Intrinsics_vec128_mul64(r211, a10));
  Lib_IntVector_Intrinsics_vec128
  a320 =
    Lib_IntVector_Intrinsics_vec128_add64(a310,
      Lib_IntVector_Intrinsics_vec128_mul64(r221, a10));
  Lib_IntVector_Intrinsics_vec128
  a420 =
    Lib_IntVector_Intrinsics_vec128_add64(a410,
      Lib_IntVector_Intrinsics_vec128_mul64(r231, a10));
  Lib_IntVector_Intrinsics_vec128
  a030 =
    Lib_IntVector_Intrinsics_vec128_add64(a020,
      Lib_IntVector_Intrinsics_vec128_mul64(r253, a20));
  Lib_IntVector_Intrinsics_vec128
  a130 =
    Lib_IntVector_Intrinsics_vec128_add64(a120,
      Lib_IntVector_Intrinsics_vec128_mul64(r254, a20));
  Lib_IntVector_Intrinsics_vec128
  a230 =
    Lib_IntVector_Intrinsics_vec128_add64(a220,
      Lib_IntVector_Intrinsics_vec128_mul64(r201, a20));
  Lib_IntVector_Intrinsics_vec128
  a330 =
    Lib_IntVector_Intrinsics_vec128_add64(a320,
      Lib_IntVector_Intrinsics_vec128_mul64(r211, a20));
  Lib_IntVector_Intrinsics_vec128
  a430 =
    Lib_IntVector_Intrinsics_vec128_add64(a420,
      Lib_IntVector_Intrinsics_vec128_mul64(r221, a20));
  Lib_IntVector_Intrinsics_vec128
  a040 =
    Lib_IntVector_Intrinsics_vec128_add64(a030,
      Lib_IntVector_Intrinsics_vec128_mul64(r252, a30));
  Lib_IntVector_Intrinsics_vec128
  a140 =
    Lib_IntVector_Intrinsics_vec128_add64(a130,
      Lib_IntVector_Intrinsics_vec128_mul64(r253, a30));
  Lib_IntVector_Intrinsics_vec128
  a240 =
    Lib_IntVector_Intrinsics_vec128_add64(a230,
      Lib_IntVector_Intrinsics_vec128_mul64(r254, a30));
  Lib_IntVector_Intrinsics_vec128
  a340 =
    Lib_IntVector_Intrinsics_vec128_add64(a330,
      Lib_IntVector_Intrinsics_vec128_mul64(r201, a30));
  Lib_IntVector_Intrinsics_vec128
  a440 =
    Lib_IntVector_Intrinsics_vec128_add64(a430,
      Lib_IntVector_Intrinsics_vec128_mul64(r211, a30));
  Lib_IntVector_Intrinsics_vec128
  a050 =
    Lib_IntVector_Intrinsics_vec128_add64(a040,
      Lib_IntVector_Intrinsics_vec128_mul64(r251, a40));
  Lib_IntVector_Intrinsics_vec128
  a150 =
    Lib_IntVector_Intrinsics_vec128_add64(a140,
      Lib_IntVector_Intrinsics_vec128_mul64(r252, a40));
  Lib_IntVector_Intrinsics_vec128
  a250 =
    Lib_IntVector_Intrinsics_vec128_add64(a240,
      Lib_IntVector_Intrinsics_vec128_mul64(r253, a40));
  Lib_IntVector_Intrinsics_vec128
  a350 =
    Lib_IntVector_Intrinsics_vec128_add64(a340,
      Lib_IntVector_Intrinsics_vec128_mul64(r254, a40));
  Lib_IntVector_Intrinsics_vec128
  a450 =
    Lib_IntVector_Intrinsics_vec128_add64(a440,
      Lib_IntVector_Intrinsics_vec128_mul64(r201, a40));
  Lib_IntVector_Intrinsics_vec128 t010 = a050;
  Lib_IntVector_Intrinsics_vec128 t10 = a150;
  Lib_IntVector_Intrinsics_vec128 t20 = a250;
  Lib_IntVector_Intrinsics_vec128 t30 = a350;
  Lib_IntVector_Intrinsics_vec128 t40 = a450;
  Lib_IntVector_Intrinsics_vec128
  l0 = Lib_IntVector_Intrinsics_vec128_add64(t010, Lib_IntVector_Intrinsics_vec128_zero);
  Lib_IntVector_Intrinsics_vec128
  tmp00 =
    Lib_IntVector_Intrinsics_vec128_and(l0,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c00 = Lib_IntVector_Intrinsics_vec128_shift_right64(l0, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 l1 = Lib_IntVector_Intrinsics_vec128_add64(t10, c00);
  Lib_IntVector_Intrinsics_vec128
  tmp10 =
    Lib_IntVector_Intrinsics_vec128_and(l1,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c10 = Lib_IntVector_Intrinsics_vec128_shift_right64(l1, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 l2 = Lib_IntVector_Intrinsics_vec128_add64(t20, c10);
  Lib_IntVector_Intrinsics_vec128
  tmp20 =
    Lib_IntVector_Intrinsics_vec128_and(l2,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c20 = Lib_IntVector_Intrinsics_vec128_shift_right64(l2, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 l3 = Lib_IntVector_Intrinsics_vec128_add64(t30, c20);
  Lib_IntVector_Intrinsics_vec128
  tmp30 =
    Lib_IntVector_Intrinsics_vec128_and(l3,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c30 = Lib_IntVector_Intrinsics_vec128_shift_right64(l3, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 l4 = Lib_IntVector_Intrinsics_vec128_add64(t40, c30);
  Lib_IntVector_Intrinsics_vec128
  tmp40 =
    Lib_IntVector_Intrinsics_vec128_and(l4,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c40 = Lib_IntVector_Intrinsics_vec128_shift_right64(l4, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128
  l5 =
    Lib_IntVector_Intrinsics_vec128_add64(tmp00,
      Lib_IntVector_Intrinsics_vec128_smul64(c40, (uint64_t)5U));
  Lib_IntVector_Intrinsics_vec128
  tmp010 =
    Lib_IntVector_Intrinsics_vec128_and(l5,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c50 = Lib_IntVector_Intrinsics_vec128_shift_right64(l5, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 tmp11 = Lib_IntVector_Intrinsics_vec128_add64(tmp10, c50);
  Lib_IntVector_Intrinsics_vec128 o00 = tmp010;
  Lib_IntVector_Intrinsics_vec128 o10 = tmp11;
  Lib_IntVector_Intrinsics_vec128 o20 = tmp20;
  Lib_IntVector_Intrinsics_vec128 o30 = tmp30;
  Lib_IntVector_Intrinsics_vec128 o40 = tmp40;
  Lib_IntVector_Intrinsics_vec128
  o01 =
    Lib_IntVector_Intrinsics_vec128_add64(o00,
      Lib_IntVector_Intrinsics_vec128_interleave_high64(o00, o00));
  Lib_IntVector_Intrinsics_vec128
  o11 =
    Lib_IntVector_Intrinsics_vec128_add64(o10,
      Lib_IntVector_Intrinsics_vec128_interleave_high64(o10, o10));
  Lib_IntVector_Intrinsics_vec128
  o21 =
    Lib_IntVector_Intrinsics_vec128_add64(o20,
      Lib_IntVector_Intrinsics_vec128_interleave_high64(o20, o20));
  Lib_IntVector_Intrinsics_vec128
  o31 =
    Lib_IntVector_Intrinsics_vec128_add64(o30,
      Lib_IntVector_Intrinsics_vec128_interleave_high64(o30, o30));
  Lib_IntVector_Intrinsics_vec128
  o41 =
    Lib_IntVector_Intrinsics_vec128_add64(o40,
      Lib_IntVector_Intrinsics_vec128_interleave_high64(o40, o40));
  Lib_IntVector_Intrinsics_vec128
  l6 = Lib_IntVector_Intrinsics_vec128_add64(o01, Lib_IntVector_Intrinsics_vec128_zero);
  Lib_IntVector_Intrinsics_vec128
  tmp02 =
    Lib_IntVector_Intrinsics_vec128_and(l6,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c01 = Lib_IntVector_Intrinsics_vec128_shift_right64(l6, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 l7 = Lib_IntVector_Intrinsics_vec128_add64(o11, c01);
  Lib_IntVector_Intrinsics_vec128
  tmp12 =
    Lib_IntVector_Intrinsics_vec128_and(l7,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c11 = Lib_IntVector_Intrinsics_vec128_shift_right64(l7, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 l8 = Lib_IntVector_Intrinsics_vec128_add64(o21, c11);
  Lib_IntVector_Intrinsics_vec128
  tmp21 =
    Lib_IntVector_Intrinsics_vec128_and(l8,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c21 = Lib_IntVector_Intrinsics_vec128_shift_right64(l8, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 l9 = Lib_IntVector_Intrinsics_vec128_add64(o31, c21);
  Lib_IntVector_Intrinsics_vec128
  tmp31 =
    Lib_IntVector_Intrinsics_vec128_and(l9,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c31 = Lib_IntVector_Intrinsics_vec128_shift_right64(l9, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 l10 = Lib_IntVector_Intrinsics_vec128_add64(o41, c31);
  Lib_IntVector_Intrinsics_vec128
  tmp41 =
    Lib_IntVector_Intrinsics_vec128_and(l10,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c41 = Lib_IntVector_Intrinsics_vec128_shift_right64(l10, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128
  l11 =
    Lib_IntVector_Intrinsics_vec128_add64(tmp02,
      Lib_IntVector_Intrinsics_vec128_smul64(c41, (uint64_t)5U));
  Lib_IntVector_Intrinsics_vec128
  tmp0_ =
    Lib_IntVector_Intrinsics_vec128_and(l11,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c51 = Lib_IntVector_Intrinsics_vec128_shift_right64(l11, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 o02 = tmp0_;
  Lib_IntVector_Intrinsics_vec128 o12 = Lib_IntVector_Intrinsics_vec128_add64(tmp12, c51);
  Lib_IntVector_Intrinsics_vec128 o22 = tmp21;
  Lib_IntVector_Intrinsics_vec128 o32 = tmp31;
  Lib_IntVector_Intrinsics_vec128 o42 = tmp41;
  acc[0U] = o02;
  acc[1U] = o12;
  acc[2U] = o22;
  acc[3U] = o32;
  acc[4U] = o42;
  uint32_t len11 = len1 - len0;
  uint8_t *t1 = text + len0;
  uint32_t nb = len11 / (uint32_t)16U;
  uint32_t rem1 = len11 % (uint32_t)16U;
  for (uint32_t i = (uint32_t)0U; i < nb; i = i + (uint32_t)1U)
  {
    uint8_t *block = t1 + i * (uint32_t)16U;
    KRML_CHECK_SIZE(sizeof (Lib_IntVector_Intrinsics_vec128), (uint32_t)5U);
    Lib_IntVector_Intrinsics_vec128 e[5U];
    for (uint32_t _i = 0U; _i < (uint32_t)5U; ++_i)
      e[_i] = Lib_IntVector_Intrinsics_vec128_zero;
    uint64_t u0 = load64_le(block);
    uint64_t lo = u0;
    uint64_t u = load64_le(block + (uint32_t)8U);
    uint64_t hi = u;
    Lib_IntVector_Intrinsics_vec128 f0 = Lib_IntVector_Intrinsics_vec128_load64(lo);
    Lib_IntVector_Intrinsics_vec128 f1 = Lib_IntVector_Intrinsics_vec128_load64(hi);
    Lib_IntVector_Intrinsics_vec128
    f010 =
      Lib_IntVector_Intrinsics_vec128_and(f0,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    f110 =
      Lib_IntVector_Intrinsics_vec128_and(Lib_IntVector_Intrinsics_vec128_shift_right64(f0,
          (uint32_t)26U),
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    f20 =
      Lib_IntVector_Intrinsics_vec128_or(Lib_IntVector_Intrinsics_vec128_shift_right64(f0,
          (uint32_t)52U),
        Lib_IntVector_Intrinsics_vec128_shift_left64(Lib_IntVector_Intrinsics_vec128_and(f1,
            Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3fffU)),
          (uint32_t)12U));
    Lib_IntVector_Intrinsics_vec128
    f30 =
      Lib_IntVector_Intrinsics_vec128_and(Lib_IntVector_Intrinsics_vec128_shift_right64(f1,
          (uint32_t)14U),
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    f40 = Lib_IntVector_Intrinsics_vec128_shift_right64(f1, (uint32_t)40U);
    Lib_IntVector_Intrinsics_vec128 f01 = f010;
    Lib_IntVector_Intrinsics_vec128 f111 = f110;
    Lib_IntVector_Intrinsics_vec128 f2 = f20;
    Lib_IntVector_Intrinsics_vec128 f3 = f30;
    Lib_IntVector_Intrinsics_vec128 f41 = f40;
    e[0U] = f01;
    e[1U] = f111;
    e[2U] = f2;
    e[3U] = f3;
    e[4U] = f41;
    uint64_t b = (uint64_t)0x1000000U;
    Lib_IntVector_Intrinsics_vec128 mask = Lib_IntVector_Intrinsics_vec128_load64(b);
    Lib_IntVector_Intrinsics_vec128 f4 = e[4U];
    e[4U] = Lib_IntVector_Intrinsics_vec128_or(f4, mask);
    Lib_IntVector_Intrinsics_vec128 *r6 = pre;
    Lib_IntVector_Intrinsics_vec128 *r5 = pre + (uint32_t)5U;
    Lib_IntVector_Intrinsics_vec128 r0 = r6[0U];
    Lib_IntVector_Intrinsics_vec128 r1 = r6[1U];
    Lib_IntVector_Intrinsics_vec128 r2 = r6[2U];
    Lib_IntVector_Intrinsics_vec128 r3 = r6[3U];
    Lib_IntVector_Intrinsics_vec128 r4 = r6[4U];
    Lib_IntVector_Intrinsics_vec128 r51 = r5[1U];
    Lib_IntVector_Intrinsics_vec128 r52 = r5[2U];
    Lib_IntVector_Intrinsics_vec128 r53 = r5[3U];
    Lib_IntVector_Intrinsics_vec128 r54 = r5[4U];
    Lib_IntVector_Intrinsics_vec128 f10 = e[0U];
    Lib_IntVector_Intrinsics_vec128 f11 = e[1U];
    Lib_IntVector_Intrinsics_vec128 f12 = e[2U];
    Lib_IntVector_Intrinsics_vec128 f13 = e[3U];
    Lib_IntVector_Intrinsics_vec128 f14 = e[4U];
    Lib_IntVector_Intrinsics_vec128 a0 = acc[0U];
    Lib_IntVector_Intrinsics_vec128 a1 = acc[1U];
    Lib_IntVector_Intrinsics_vec128 a2 = acc[2U];
    Lib_IntVector_Intrinsics_vec128 a3 = acc[3U];
    Lib_IntVector_Intrinsics_vec128 a4 = acc[4U];
    Lib_IntVector_Intrinsics_vec128 a01 = Lib_IntVector_Intrinsics_vec128_add64(a0, f10);
    Lib_IntVector_Intrinsics_vec128 a11 = Lib_IntVector_Intrinsics_vec128_add64(a1, f11);
    Lib_IntVector_Intrinsics_vec128 a21 = Lib_IntVector_Intrinsics_vec128_add64(a2, f12);
    Lib_IntVector_Intrinsics_vec128 a31 = Lib_IntVector_Intrinsics_vec128_add64(a3, f13);
    Lib_IntVector_Intrinsics_vec128 a41 = Lib_IntVector_Intrinsics_vec128_add64(a4, f14);
    Lib_IntVector_Intrinsics_vec128 a02 = Lib_IntVector_Intrinsics_vec128_mul64(r0, a01);
    Lib_IntVector_Intrinsics_vec128 a12 = Lib_IntVector_Intrinsics_vec128_mul64(r1, a01);
    Lib_IntVector_Intrinsics_vec128 a22 = Lib_IntVector_Intrinsics_vec128_mul64(r2, a01);
    Lib_IntVector_Intrinsics_vec128 a32 = Lib_IntVector_Intrinsics_vec128_mul64(r3, a01);
    Lib_IntVector_Intrinsics_vec128 a42 = Lib_IntVector_Intrinsics_vec128_mul64(r4, a01);
    Lib_IntVector_Intrinsics_vec128
    a03 =
      Lib_IntVector_Intrinsics_vec128_add64(a02,
        Lib_IntVector_Intrinsics_vec128_mul64(r54, a11));
    Lib_IntVector_Intrinsics_vec128
    a13 =
      Lib_IntVector_Intrinsics_vec128_add64(a12,
        Lib_IntVector_Intrinsics_vec128_mul64(r0, a11));
    Lib_IntVector_Intrinsics_vec128
    a23 =
      Lib_IntVector_Intrinsics_vec128_add64(a22,
        Lib_IntVector_Intrinsics_vec128_mul64(r1, a11));
    Lib_IntVector_Intrinsics_vec128
    a33 =
      Lib_IntVector_Intrinsics_vec128_add64(a32,
        Lib_IntVector_Intrinsics_vec128_mul64(r2, a11));
    Lib_IntVector_Intrinsics_vec128
    a43 =
      Lib_IntVector_Intrinsics_vec128_add64(a42,
        Lib_IntVector_Intrinsics_vec128_mul64(r3, a11));
    Lib_IntVector_Intrinsics_vec128
    a04 =
      Lib_IntVector_Intrinsics_vec128_add64(a03,
        Lib_IntVector_Intrinsics_vec128_mul64(r53, a21));
    Lib_IntVector_Intrinsics_vec128
    a14 =
      Lib_IntVector_Intrinsics_vec128_add64(a13,
        Lib_IntVector_Intrinsics_vec128_mul64(r54, a21));
    Lib_IntVector_Intrinsics_vec128
    a24 =
      Lib_IntVector_Intrinsics_vec128_add64(a23,
        Lib_IntVector_Intrinsics_vec128_mul64(r0, a21));
    Lib_IntVector_Intrinsics_vec128
    a34 =
      Lib_IntVector_Intrinsics_vec128_add64(a33,
        Lib_IntVector_Intrinsics_vec128_mul64(r1, a21));
    Lib_IntVector_Intrinsics_vec128
    a44 =
      Lib_IntVector_Intrinsics_vec128_add64(a43,
        Lib_IntVector_Intrinsics_vec128_mul64(r2, a21));
    Lib_IntVector_Intrinsics_vec128
    a05 =
      Lib_IntVector_Intrinsics_vec128_add64(a04,
        Lib_IntVector_Intrinsics_vec128_mul64(r52, a31));
    Lib_IntVector_Intrinsics_vec128
    a15 =
      Lib_IntVector_Intrinsics_vec128_add64(a14,
        Lib_IntVector_Intrinsics_vec128_mul64(r53, a31));
    Lib_IntVector_Intrinsics_vec128
    a25 =
      Lib_IntVector_Intrinsics_vec128_add64(a24,
        Lib_IntVector_Intrinsics_vec128_mul64(r54, a31));
    Lib_IntVector_Intrinsics_vec128
    a35 =
      Lib_IntVector_Intrinsics_vec128_add64(a34,
        Lib_IntVector_Intrinsics_vec128_mul64(r0, a31));
    Lib_IntVector_Intrinsics_vec128
    a45 =
      Lib_IntVector_Intrinsics_vec128_add64(a44,
        Lib_IntVector_Intrinsics_vec128_mul64(r1, a31));
    Lib_IntVector_Intrinsics_vec128
    a06 =
      Lib_IntVector_Intrinsics_vec128_add64(a05,
        Lib_IntVector_Intrinsics_vec128_mul64(r51, a41));
    Lib_IntVector_Intrinsics_vec128
    a16 =
      Lib_IntVector_Intrinsics_vec128_add64(a15,
        Lib_IntVector_Intrinsics_vec128_mul64(r52, a41));
    Lib_IntVector_Intrinsics_vec128
    a26 =
      Lib_IntVector_Intrinsics_vec128_add64(a25,
        Lib_IntVector_Intrinsics_vec128_mul64(r53, a41));
    Lib_IntVector_Intrinsics_vec128
    a36 =
      Lib_IntVector_Intrinsics_vec128_add64(a35,
        Lib_IntVector_Intrinsics_vec128_mul64(r54, a41));
    Lib_IntVector_Intrinsics_vec128
    a46 =
      Lib_IntVector_Intrinsics_vec128_add64(a45,
        Lib_IntVector_Intrinsics_vec128_mul64(r0, a41));
    Lib_IntVector_Intrinsics_vec128 t01 = a06;
    Lib_IntVector_Intrinsics_vec128 t11 = a16;
    Lib_IntVector_Intrinsics_vec128 t2 = a26;
    Lib_IntVector_Intrinsics_vec128 t3 = a36;
    Lib_IntVector_Intrinsics_vec128 t4 = a46;
    Lib_IntVector_Intrinsics_vec128
    l = Lib_IntVector_Intrinsics_vec128_add64(t01, Lib_IntVector_Intrinsics_vec128_zero);
    Lib_IntVector_Intrinsics_vec128
    tmp0 =
      Lib_IntVector_Intrinsics_vec128_and(l,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    c0 = Lib_IntVector_Intrinsics_vec128_shift_right64(l, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec128 l12 = Lib_IntVector_Intrinsics_vec128_add64(t11, c0);
    Lib_IntVector_Intrinsics_vec128
    tmp1 =
      Lib_IntVector_Intrinsics_vec128_and(l12,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    c1 = Lib_IntVector_Intrinsics_vec128_shift_right64(l12, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec128 l13 = Lib_IntVector_Intrinsics_vec128_add64(t2, c1);
    Lib_IntVector_Intrinsics_vec128
    tmp2 =
      Lib_IntVector_Intrinsics_vec128_and(l13,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    c2 = Lib_IntVector_Intrinsics_vec128_shift_right64(l13, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec128 l14 = Lib_IntVector_Intrinsics_vec128_add64(t3, c2);
    Lib_IntVector_Intrinsics_vec128
    tmp3 =
      Lib_IntVector_Intrinsics_vec128_and(l14,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    c3 = Lib_IntVector_Intrinsics_vec128_shift_right64(l14, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec128 l15 = Lib_IntVector_Intrinsics_vec128_add64(t4, c3);
    Lib_IntVector_Intrinsics_vec128
    tmp4 =
      Lib_IntVector_Intrinsics_vec128_and(l15,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    c4 = Lib_IntVector_Intrinsics_vec128_shift_right64(l15, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec128
    l16 =
      Lib_IntVector_Intrinsics_vec128_add64(tmp0,
        Lib_IntVector_Intrinsics_vec128_smul64(c4, (uint64_t)5U));
    Lib_IntVector_Intrinsics_vec128
    tmp01 =
      Lib_IntVector_Intrinsics_vec128_and(l16,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    c5 = Lib_IntVector_Intrinsics_vec128_shift_right64(l16, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec128 tmp110 = Lib_IntVector_Intrinsics_vec128_add64(tmp1, c5);
    Lib_IntVector_Intrinsics_vec128 o0 = tmp01;
    Lib_IntVector_Intrinsics_vec128 o1 = tmp110;
    Lib_IntVector_Intrinsics_vec128 o2 = tmp2;
    Lib_IntVector_Intrinsics_vec128 o3 = tmp3;
    Lib_IntVector_Intrinsics_vec128 o4 = tmp4;
    acc[0U] = o0;
    acc[1U] = o1;
    acc[2U] = o2;
    acc[3U] = o3;
    acc[4U] = o4;
  }
  uint8_t *b = t1 + nb * (uint32_t)16U;
  if (rem1 > (uint32_t)0U)
  {
    KRML_CHECK_SIZE(sizeof (Lib_IntVector_Intrinsics_vec128), (uint32_t)5U);
    Lib_IntVector_Intrinsics_vec128 e[5U];
    for (uint32_t _i = 0U; _i < (uint32_t)5U; ++_i)
      e[_i] = Lib_IntVector_Intrinsics_vec128_zero;
    uint8_t tmp[16U] = { 0U };
    memcpy(tmp, b, rem1 * sizeof b[0U]);
    uint64_t u0 = load64_le(tmp);
    uint64_t lo = u0;
    uint64_t u = load64_le(tmp + (uint32_t)8U);
    uint64_t hi = u;
    Lib_IntVector_Intrinsics_vec128 f0 = Lib_IntVector_Intrinsics_vec128_load64(lo);
    Lib_IntVector_Intrinsics_vec128 f1 = Lib_IntVector_Intrinsics_vec128_load64(hi);
    Lib_IntVector_Intrinsics_vec128
    f010 =
      Lib_IntVector_Intrinsics_vec128_and(f0,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    f110 =
      Lib_IntVector_Intrinsics_vec128_and(Lib_IntVector_Intrinsics_vec128_shift_right64(f0,
          (uint32_t)26U),
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    f20 =
      Lib_IntVector_Intrinsics_vec128_or(Lib_IntVector_Intrinsics_vec128_shift_right64(f0,
          (uint32_t)52U),
        Lib_IntVector_Intrinsics_vec128_shift_left64(Lib_IntVector_Intrinsics_vec128_and(f1,
            Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3fffU)),
          (uint32_t)12U));
    Lib_IntVector_Intrinsics_vec128
    f30 =
      Lib_IntVector_Intrinsics_vec128_and(Lib_IntVector_Intrinsics_vec128_shift_right64(f1,
          (uint32_t)14U),
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    f40 = Lib_IntVector_Intrinsics_vec128_shift_right64(f1, (uint32_t)40U);
    Lib_IntVector_Intrinsics_vec128 f01 = f010;
    Lib_IntVector_Intrinsics_vec128 f111 = f110;
    Lib_IntVector_Intrinsics_vec128 f2 = f20;
    Lib_IntVector_Intrinsics_vec128 f3 = f30;
    Lib_IntVector_Intrinsics_vec128 f4 = f40;
    e[0U] = f01;
    e[1U] = f111;
    e[2U] = f2;
    e[3U] = f3;
    e[4U] = f4;
    uint64_t b1 = (uint64_t)1U << rem1 * (uint32_t)8U % (uint32_t)26U;
    Lib_IntVector_Intrinsics_vec128 mask = Lib_IntVector_Intrinsics_vec128_load64(b1);
    Lib_IntVector_Intrinsics_vec128 fi = e[rem1 * (uint32_t)8U / (uint32_t)26U];
    e[rem1 * (uint32_t)8U / (uint32_t)26U] = Lib_IntVector_Intrinsics_vec128_or(fi, mask);
    Lib_IntVector_Intrinsics_vec128 *r6 = pre;
    Lib_IntVector_Intrinsics_vec128 *r5 = pre + (uint32_t)5U;
    Lib_IntVector_Intrinsics_vec128 r0 = r6[0U];
    Lib_IntVector_Intrinsics_vec128 r1 = r6[1U];
    Lib_IntVector_Intrinsics_vec128 r2 = r6[2U];
    Lib_IntVector_Intrinsics_vec128 r3 = r6[3U];
    Lib_IntVector_Intrinsics_vec128 r4 = r6[4U];
    Lib_IntVector_Intrinsics_vec128 r51 = r5[1U];
    Lib_IntVector_Intrinsics_vec128 r52 = r5[2U];
    Lib_IntVector_Intrinsics_vec128 r53 = r5[3U];
    Lib_IntVector_Intrinsics_vec128 r54 = r5[4U];
    Lib_IntVector_Intrinsics_vec128 f10 = e[0U];
    Lib_IntVector_Intrinsics_vec128 f11 = e[1U];
    Lib_IntVector_Intrinsics_vec128 f12 = e[2U];
    Lib_IntVector_Intrinsics_vec128 f13 = e[3U];
    Lib_IntVector_Intrinsics_vec128 f14 = e[4U];
    Lib_IntVector_Intrinsics_vec128 a0 = acc[0U];
    Lib_IntVector_Intrinsics_vec128 a1 = acc[1U];
    Lib_IntVector_Intrinsics_vec128 a2 = acc[2U];
    Lib_IntVector_Intrinsics_vec128 a3 = acc[3U];
    Lib_IntVector_Intrinsics_vec128 a4 = acc[4U];
    Lib_IntVector_Intrinsics_vec128 a01 = Lib_IntVector_Intrinsics_vec128_add64(a0, f10);
    Lib_IntVector_Intrinsics_vec128 a11 = Lib_IntVector_Intrinsics_vec128_add64(a1, f11);
    Lib_IntVector_Intrinsics_vec128 a21 = Lib_IntVector_Intrinsics_vec128_add64(a2, f12);
    Lib_IntVector_Intrinsics_vec128 a31 = Lib_IntVector_Intrinsics_vec128_add64(a3, f13);
    Lib_IntVector_Intrinsics_vec128 a41 = Lib_IntVector_Intrinsics_vec128_add64(a4, f14);
    Lib_IntVector_Intrinsics_vec128 a02 = Lib_IntVector_Intrinsics_vec128_mul64(r0, a01);
    Lib_IntVector_Intrinsics_vec128 a12 = Lib_IntVector_Intrinsics_vec128_mul64(r1, a01);
    Lib_IntVector_Intrinsics_vec128 a22 = Lib_IntVector_Intrinsics_vec128_mul64(r2, a01);
    Lib_IntVector_Intrinsics_vec128 a32 = Lib_IntVector_Intrinsics_vec128_mul64(r3, a01);
    Lib_IntVector_Intrinsics_vec128 a42 = Lib_IntVector_Intrinsics_vec128_mul64(r4, a01);
    Lib_IntVector_Intrinsics_vec128
    a03 =
      Lib_IntVector_Intrinsics_vec128_add64(a02,
        Lib_IntVector_Intrinsics_vec128_mul64(r54, a11));
    Lib_IntVector_Intrinsics_vec128
    a13 =
      Lib_IntVector_Intrinsics_vec128_add64(a12,
        Lib_IntVector_Intrinsics_vec128_mul64(r0, a11));
    Lib_IntVector_Intrinsics_vec128
    a23 =
      Lib_IntVector_Intrinsics_vec128_add64(a22,
        Lib_IntVector_Intrinsics_vec128_mul64(r1, a11));
    Lib_IntVector_Intrinsics_vec128
    a33 =
      Lib_IntVector_Intrinsics_vec128_add64(a32,
        Lib_IntVector_Intrinsics_vec128_mul64(r2, a11));
    Lib_IntVector_Intrinsics_vec128
    a43 =
      Lib_IntVector_Intrinsics_vec128_add64(a42,
        Lib_IntVector_Intrinsics_vec128_mul64(r3, a11));
    Lib_IntVector_Intrinsics_vec128
    a04 =
      Lib_IntVector_Intrinsics_vec128_add64(a03,
        Lib_IntVector_Intrinsics_vec128_mul64(r53, a21));
    Lib_IntVector_Intrinsics_vec128
    a14 =
      Lib_IntVector_Intrinsics_vec128_add64(a13,
        Lib_IntVector_Intrinsics_vec128_mul64(r54, a21));
    Lib_IntVector_Intrinsics_vec128
    a24 =
      Lib_IntVector_Intrinsics_vec128_add64(a23,
        Lib_IntVector_Intrinsics_vec128_mul64(r0, a21));
    Lib_IntVector_Intrinsics_vec128
    a34 =
      Lib_IntVector_Intrinsics_vec128_add64(a33,
        Lib_IntVector_Intrinsics_vec128_mul64(r1, a21));
    Lib_IntVector_Intrinsics_vec128
    a44 =
      Lib_IntVector_Intrinsics_vec128_add64(a43,
        Lib_IntVector_Intrinsics_vec128_mul64(r2, a21));
    Lib_IntVector_Intrinsics_vec128
    a05 =
      Lib_IntVector_Intrinsics_vec128_add64(a04,
        Lib_IntVector_Intrinsics_vec128_mul64(r52, a31));
    Lib_IntVector_Intrinsics_vec128
    a15 =
      Lib_IntVector_Intrinsics_vec128_add64(a14,
        Lib_IntVector_Intrinsics_vec128_mul64(r53, a31));
    Lib_IntVector_Intrinsics_vec128
    a25 =
      Lib_IntVector_Intrinsics_vec128_add64(a24,
        Lib_IntVector_Intrinsics_vec128_mul64(r54, a31));
    Lib_IntVector_Intrinsics_vec128
    a35 =
      Lib_IntVector_Intrinsics_vec128_add64(a34,
        Lib_IntVector_Intrinsics_vec128_mul64(r0, a31));
    Lib_IntVector_Intrinsics_vec128
    a45 =
      Lib_IntVector_Intrinsics_vec128_add64(a44,
        Lib_IntVector_Intrinsics_vec128_mul64(r1, a31));
    Lib_IntVector_Intrinsics_vec128
    a06 =
      Lib_IntVector_Intrinsics_vec128_add64(a05,
        Lib_IntVector_Intrinsics_vec128_mul64(r51, a41));
    Lib_IntVector_Intrinsics_vec128
    a16 =
      Lib_IntVector_Intrinsics_vec128_add64(a15,
        Lib_IntVector_Intrinsics_vec128_mul64(r52, a41));
    Lib_IntVector_Intrinsics_vec128
    a26 =
      Lib_IntVector_Intrinsics_vec128_add64(a25,
        Lib_IntVector_Intrinsics_vec128_mul64(r53, a41));
    Lib_IntVector_Intrinsics_vec128
    a36 =
      Lib_IntVector_Intrinsics_vec128_add64(a35,
        Lib_IntVector_Intrinsics_vec128_mul64(r54, a41));
    Lib_IntVector_Intrinsics_vec128
    a46 =
      Lib_IntVector_Intrinsics_vec128_add64(a45,
        Lib_IntVector_Intrinsics_vec128_mul64(r0, a41));
    Lib_IntVector_Intrinsics_vec128 t01 = a06;
    Lib_IntVector_Intrinsics_vec128 t11 = a16;
    Lib_IntVector_Intrinsics_vec128 t2 = a26;
    Lib_IntVector_Intrinsics_vec128 t3 = a36;
    Lib_IntVector_Intrinsics_vec128 t4 = a46;
    Lib_IntVector_Intrinsics_vec128
    l = Lib_IntVector_Intrinsics_vec128_add64(t01, Lib_IntVector_Intrinsics_vec128_zero);
    Lib_IntVector_Intrinsics_vec128
    tmp0 =
      Lib_IntVector_Intrinsics_vec128_and(l,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    c0 = Lib_IntVector_Intrinsics_vec128_shift_right64(l, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec128 l12 = Lib_IntVector_Intrinsics_vec128_add64(t11, c0);
    Lib_IntVector_Intrinsics_vec128
    tmp1 =
      Lib_IntVector_Intrinsics_vec128_and(l12,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    c1 = Lib_IntVector_Intrinsics_vec128_shift_right64(l12, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec128 l13 = Lib_IntVector_Intrinsics_vec128_add64(t2, c1);
    Lib_IntVector_Intrinsics_vec128
    tmp2 =
      Lib_IntVector_Intrinsics_vec128_and(l13,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    c2 = Lib_IntVector_Intrinsics_vec128_shift_right64(l13, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec128 l14 = Lib_IntVector_Intrinsics_vec128_add64(t3, c2);
    Lib_IntVector_Intrinsics_vec128
    tmp3 =
      Lib_IntVector_Intrinsics_vec128_and(l14,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    c3 = Lib_IntVector_Intrinsics_vec128_shift_right64(l14, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec128 l15 = Lib_IntVector_Intrinsics_vec128_add64(t4, c3);
    Lib_IntVector_Intrinsics_vec128
    tmp4 =
      Lib_IntVector_Intrinsics_vec128_and(l15,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    c4 = Lib_IntVector_Intrinsics_vec128_shift_right64(l15, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec128
    l16 =
      Lib_IntVector_Intrinsics_vec128_add64(tmp0,
        Lib_IntVector_Intrinsics_vec128_smul64(c4, (uint64_t)5U));
    Lib_IntVector_Intrinsics_vec128
    tmp01 =
      Lib_IntVector_Intrinsics_vec128_and(l16,
        Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec128
    c5 = Lib_IntVector_Intrinsics_vec128_shift_right64(l16, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec128 tmp110 = Lib_IntVector_Intrinsics_vec128_add64(tmp1, c5);
    Lib_IntVector_Intrinsics_vec128 o0 = tmp01;
    Lib_IntVector_Intrinsics_vec128 o1 = tmp110;
    Lib_IntVector_Intrinsics_vec128 o2 = tmp2;
    Lib_IntVector_Intrinsics_vec128 o3 = tmp3;
    Lib_IntVector_Intrinsics_vec128 o4 = tmp4;
    acc[0U] = o0;
    acc[1U] = o1;
    acc[2U] = o2;
    acc[3U] = o3;
    acc[4U] = o4;
  }
}

inline static void
Hacl_Impl_Poly1305_poly1305_update_256(
  Lib_IntVector_Intrinsics_vec256 *ctx,
  uint32_t len1,
  uint8_t *text
)
{
  Lib_IntVector_Intrinsics_vec256 *pre = ctx + (uint32_t)5U;
  Lib_IntVector_Intrinsics_vec256 *acc = ctx;
  uint32_t sz_block = (uint32_t)64U;
  uint32_t len0 = len1 / sz_block * sz_block;
  uint8_t *t0 = text;
  uint32_t bs = (uint32_t)64U;
  uint32_t nb0 = len0 / bs;
  for (uint32_t i = (uint32_t)0U; i < nb0; i = i + (uint32_t)1U)
  {
    uint8_t *block = t0 + i * bs;
    KRML_CHECK_SIZE(sizeof (Lib_IntVector_Intrinsics_vec256), (uint32_t)5U);
    Lib_IntVector_Intrinsics_vec256 e[5U];
    for (uint32_t _i = 0U; _i < (uint32_t)5U; ++_i)
      e[_i] = Lib_IntVector_Intrinsics_vec256_zero;
    Lib_IntVector_Intrinsics_vec256 lo0 = Lib_IntVector_Intrinsics_vec256_load_le(block);
    Lib_IntVector_Intrinsics_vec256
    hi0 = Lib_IntVector_Intrinsics_vec256_load_le(block + (uint32_t)32U);
    Lib_IntVector_Intrinsics_vec256
    lo1 = Lib_IntVector_Intrinsics_vec256_interleave_low128(lo0, hi0);
    Lib_IntVector_Intrinsics_vec256
    hi1 = Lib_IntVector_Intrinsics_vec256_interleave_high128(lo0, hi0);
    Lib_IntVector_Intrinsics_vec256 lo2 = lo1;
    Lib_IntVector_Intrinsics_vec256 hi2 = hi1;
    Lib_IntVector_Intrinsics_vec256
    lo = Lib_IntVector_Intrinsics_vec256_interleave_low64(lo2, hi2);
    Lib_IntVector_Intrinsics_vec256
    hi = Lib_IntVector_Intrinsics_vec256_interleave_high64(lo2, hi2);
    Lib_IntVector_Intrinsics_vec256
    f00 =
      Lib_IntVector_Intrinsics_vec256_and(lo,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    f15 =
      Lib_IntVector_Intrinsics_vec256_and(Lib_IntVector_Intrinsics_vec256_shift_right64(lo,
          (uint32_t)26U),
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    f25 =
      Lib_IntVector_Intrinsics_vec256_or(Lib_IntVector_Intrinsics_vec256_shift_right64(lo,
          (uint32_t)52U),
        Lib_IntVector_Intrinsics_vec256_shift_left64(Lib_IntVector_Intrinsics_vec256_and(hi,
            Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3fffU)),
          (uint32_t)12U));
    Lib_IntVector_Intrinsics_vec256
    f30 =
      Lib_IntVector_Intrinsics_vec256_and(Lib_IntVector_Intrinsics_vec256_shift_right64(hi,
          (uint32_t)14U),
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    f40 = Lib_IntVector_Intrinsics_vec256_shift_right64(hi, (uint32_t)40U);
    Lib_IntVector_Intrinsics_vec256 f0 = f00;
    Lib_IntVector_Intrinsics_vec256 f1 = f15;
    Lib_IntVector_Intrinsics_vec256 f2 = f25;
    Lib_IntVector_Intrinsics_vec256 f3 = f30;
    Lib_IntVector_Intrinsics_vec256 f41 = f40;
    e[0U] = f0;
    e[1U] = f1;
    e[2U] = f2;
    e[3U] = f3;
    e[4U] = f41;
    uint64_t b = (uint64_t)0x1000000U;
    Lib_IntVector_Intrinsics_vec256 mask = Lib_IntVector_Intrinsics_vec256_load64(b);
    Lib_IntVector_Intrinsics_vec256 f4 = e[4U];
    e[4U] = Lib_IntVector_Intrinsics_vec256_or(f4, mask);
    Lib_IntVector_Intrinsics_vec256 *rn = pre + (uint32_t)10U;
    Lib_IntVector_Intrinsics_vec256 *rn5 = pre + (uint32_t)15U;
    Lib_IntVector_Intrinsics_vec256 r0 = rn[0U];
    Lib_IntVector_Intrinsics_vec256 r1 = rn[1U];
    Lib_IntVector_Intrinsics_vec256 r2 = rn[2U];
    Lib_IntVector_Intrinsics_vec256 r3 = rn[3U];
    Lib_IntVector_Intrinsics_vec256 r4 = rn[4U];
    Lib_IntVector_Intrinsics_vec256 r51 = rn5[1U];
    Lib_IntVector_Intrinsics_vec256 r52 = rn5[2U];
    Lib_IntVector_Intrinsics_vec256 r53 = rn5[3U];
    Lib_IntVector_Intrinsics_vec256 r54 = rn5[4U];
    Lib_IntVector_Intrinsics_vec256 f10 = acc[0U];
    Lib_IntVector_Intrinsics_vec256 f110 = acc[1U];
    Lib_IntVector_Intrinsics_vec256 f120 = acc[2U];
    Lib_IntVector_Intrinsics_vec256 f130 = acc[3U];
    Lib_IntVector_Intrinsics_vec256 f140 = acc[4U];
    Lib_IntVector_Intrinsics_vec256 a0 = Lib_IntVector_Intrinsics_vec256_mul64(r0, f10);
    Lib_IntVector_Intrinsics_vec256 a1 = Lib_IntVector_Intrinsics_vec256_mul64(r1, f10);
    Lib_IntVector_Intrinsics_vec256 a2 = Lib_IntVector_Intrinsics_vec256_mul64(r2, f10);
    Lib_IntVector_Intrinsics_vec256 a3 = Lib_IntVector_Intrinsics_vec256_mul64(r3, f10);
    Lib_IntVector_Intrinsics_vec256 a4 = Lib_IntVector_Intrinsics_vec256_mul64(r4, f10);
    Lib_IntVector_Intrinsics_vec256
    a01 =
      Lib_IntVector_Intrinsics_vec256_add64(a0,
        Lib_IntVector_Intrinsics_vec256_mul64(r54, f110));
    Lib_IntVector_Intrinsics_vec256
    a11 =
      Lib_IntVector_Intrinsics_vec256_add64(a1,
        Lib_IntVector_Intrinsics_vec256_mul64(r0, f110));
    Lib_IntVector_Intrinsics_vec256
    a21 =
      Lib_IntVector_Intrinsics_vec256_add64(a2,
        Lib_IntVector_Intrinsics_vec256_mul64(r1, f110));
    Lib_IntVector_Intrinsics_vec256
    a31 =
      Lib_IntVector_Intrinsics_vec256_add64(a3,
        Lib_IntVector_Intrinsics_vec256_mul64(r2, f110));
    Lib_IntVector_Intrinsics_vec256
    a41 =
      Lib_IntVector_Intrinsics_vec256_add64(a4,
        Lib_IntVector_Intrinsics_vec256_mul64(r3, f110));
    Lib_IntVector_Intrinsics_vec256
    a02 =
      Lib_IntVector_Intrinsics_vec256_add64(a01,
        Lib_IntVector_Intrinsics_vec256_mul64(r53, f120));
    Lib_IntVector_Intrinsics_vec256
    a12 =
      Lib_IntVector_Intrinsics_vec256_add64(a11,
        Lib_IntVector_Intrinsics_vec256_mul64(r54, f120));
    Lib_IntVector_Intrinsics_vec256
    a22 =
      Lib_IntVector_Intrinsics_vec256_add64(a21,
        Lib_IntVector_Intrinsics_vec256_mul64(r0, f120));
    Lib_IntVector_Intrinsics_vec256
    a32 =
      Lib_IntVector_Intrinsics_vec256_add64(a31,
        Lib_IntVector_Intrinsics_vec256_mul64(r1, f120));
    Lib_IntVector_Intrinsics_vec256
    a42 =
      Lib_IntVector_Intrinsics_vec256_add64(a41,
        Lib_IntVector_Intrinsics_vec256_mul64(r2, f120));
    Lib_IntVector_Intrinsics_vec256
    a03 =
      Lib_IntVector_Intrinsics_vec256_add64(a02,
        Lib_IntVector_Intrinsics_vec256_mul64(r52, f130));
    Lib_IntVector_Intrinsics_vec256
    a13 =
      Lib_IntVector_Intrinsics_vec256_add64(a12,
        Lib_IntVector_Intrinsics_vec256_mul64(r53, f130));
    Lib_IntVector_Intrinsics_vec256
    a23 =
      Lib_IntVector_Intrinsics_vec256_add64(a22,
        Lib_IntVector_Intrinsics_vec256_mul64(r54, f130));
    Lib_IntVector_Intrinsics_vec256
    a33 =
      Lib_IntVector_Intrinsics_vec256_add64(a32,
        Lib_IntVector_Intrinsics_vec256_mul64(r0, f130));
    Lib_IntVector_Intrinsics_vec256
    a43 =
      Lib_IntVector_Intrinsics_vec256_add64(a42,
        Lib_IntVector_Intrinsics_vec256_mul64(r1, f130));
    Lib_IntVector_Intrinsics_vec256
    a04 =
      Lib_IntVector_Intrinsics_vec256_add64(a03,
        Lib_IntVector_Intrinsics_vec256_mul64(r51, f140));
    Lib_IntVector_Intrinsics_vec256
    a14 =
      Lib_IntVector_Intrinsics_vec256_add64(a13,
        Lib_IntVector_Intrinsics_vec256_mul64(r52, f140));
    Lib_IntVector_Intrinsics_vec256
    a24 =
      Lib_IntVector_Intrinsics_vec256_add64(a23,
        Lib_IntVector_Intrinsics_vec256_mul64(r53, f140));
    Lib_IntVector_Intrinsics_vec256
    a34 =
      Lib_IntVector_Intrinsics_vec256_add64(a33,
        Lib_IntVector_Intrinsics_vec256_mul64(r54, f140));
    Lib_IntVector_Intrinsics_vec256
    a44 =
      Lib_IntVector_Intrinsics_vec256_add64(a43,
        Lib_IntVector_Intrinsics_vec256_mul64(r0, f140));
    Lib_IntVector_Intrinsics_vec256 t01 = a04;
    Lib_IntVector_Intrinsics_vec256 t1 = a14;
    Lib_IntVector_Intrinsics_vec256 t2 = a24;
    Lib_IntVector_Intrinsics_vec256 t3 = a34;
    Lib_IntVector_Intrinsics_vec256 t4 = a44;
    Lib_IntVector_Intrinsics_vec256
    l = Lib_IntVector_Intrinsics_vec256_add64(t01, Lib_IntVector_Intrinsics_vec256_zero);
    Lib_IntVector_Intrinsics_vec256
    tmp0 =
      Lib_IntVector_Intrinsics_vec256_and(l,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    c0 = Lib_IntVector_Intrinsics_vec256_shift_right64(l, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec256 l0 = Lib_IntVector_Intrinsics_vec256_add64(t1, c0);
    Lib_IntVector_Intrinsics_vec256
    tmp1 =
      Lib_IntVector_Intrinsics_vec256_and(l0,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    c1 = Lib_IntVector_Intrinsics_vec256_shift_right64(l0, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec256 l1 = Lib_IntVector_Intrinsics_vec256_add64(t2, c1);
    Lib_IntVector_Intrinsics_vec256
    tmp2 =
      Lib_IntVector_Intrinsics_vec256_and(l1,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    c2 = Lib_IntVector_Intrinsics_vec256_shift_right64(l1, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec256 l2 = Lib_IntVector_Intrinsics_vec256_add64(t3, c2);
    Lib_IntVector_Intrinsics_vec256
    tmp3 =
      Lib_IntVector_Intrinsics_vec256_and(l2,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    c3 = Lib_IntVector_Intrinsics_vec256_shift_right64(l2, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec256 l3 = Lib_IntVector_Intrinsics_vec256_add64(t4, c3);
    Lib_IntVector_Intrinsics_vec256
    tmp4 =
      Lib_IntVector_Intrinsics_vec256_and(l3,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    c4 = Lib_IntVector_Intrinsics_vec256_shift_right64(l3, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec256
    l4 =
      Lib_IntVector_Intrinsics_vec256_add64(tmp0,
        Lib_IntVector_Intrinsics_vec256_smul64(c4, (uint64_t)5U));
    Lib_IntVector_Intrinsics_vec256
    tmp01 =
      Lib_IntVector_Intrinsics_vec256_and(l4,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    c5 = Lib_IntVector_Intrinsics_vec256_shift_right64(l4, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec256 tmp11 = Lib_IntVector_Intrinsics_vec256_add64(tmp1, c5);
    Lib_IntVector_Intrinsics_vec256 o00 = tmp01;
    Lib_IntVector_Intrinsics_vec256 o10 = tmp11;
    Lib_IntVector_Intrinsics_vec256 o20 = tmp2;
    Lib_IntVector_Intrinsics_vec256 o30 = tmp3;
    Lib_IntVector_Intrinsics_vec256 o40 = tmp4;
    acc[0U] = o00;
    acc[1U] = o10;
    acc[2U] = o20;
    acc[3U] = o30;
    acc[4U] = o40;
    Lib_IntVector_Intrinsics_vec256 f100 = acc[0U];
    Lib_IntVector_Intrinsics_vec256 f11 = acc[1U];
    Lib_IntVector_Intrinsics_vec256 f12 = acc[2U];
    Lib_IntVector_Intrinsics_vec256 f13 = acc[3U];
    Lib_IntVector_Intrinsics_vec256 f14 = acc[4U];
    Lib_IntVector_Intrinsics_vec256 f20 = e[0U];
    Lib_IntVector_Intrinsics_vec256 f21 = e[1U];
    Lib_IntVector_Intrinsics_vec256 f22 = e[2U];
    Lib_IntVector_Intrinsics_vec256 f23 = e[3U];
    Lib_IntVector_Intrinsics_vec256 f24 = e[4U];
    Lib_IntVector_Intrinsics_vec256 o0 = Lib_IntVector_Intrinsics_vec256_add64(f100, f20);
    Lib_IntVector_Intrinsics_vec256 o1 = Lib_IntVector_Intrinsics_vec256_add64(f11, f21);
    Lib_IntVector_Intrinsics_vec256 o2 = Lib_IntVector_Intrinsics_vec256_add64(f12, f22);
    Lib_IntVector_Intrinsics_vec256 o3 = Lib_IntVector_Intrinsics_vec256_add64(f13, f23);
    Lib_IntVector_Intrinsics_vec256 o4 = Lib_IntVector_Intrinsics_vec256_add64(f14, f24);
    acc[0U] = o0;
    acc[1U] = o1;
    acc[2U] = o2;
    acc[3U] = o3;
    acc[4U] = o4;
  }
  Lib_IntVector_Intrinsics_vec256 *r = pre;
  Lib_IntVector_Intrinsics_vec256 *r_5 = pre + (uint32_t)5U;
  Lib_IntVector_Intrinsics_vec256 *r45 = pre + (uint32_t)10U;
  Lib_IntVector_Intrinsics_vec256 a00 = acc[0U];
  Lib_IntVector_Intrinsics_vec256 a10 = acc[1U];
  Lib_IntVector_Intrinsics_vec256 a20 = acc[2U];
  Lib_IntVector_Intrinsics_vec256 a30 = acc[3U];
  Lib_IntVector_Intrinsics_vec256 a40 = acc[4U];
  Lib_IntVector_Intrinsics_vec256 r10 = r[0U];
  Lib_IntVector_Intrinsics_vec256 r11 = r[1U];
  Lib_IntVector_Intrinsics_vec256 r12 = r[2U];
  Lib_IntVector_Intrinsics_vec256 r13 = r[3U];
  Lib_IntVector_Intrinsics_vec256 r14 = r[4U];
  Lib_IntVector_Intrinsics_vec256 r151 = r_5[1U];
  Lib_IntVector_Intrinsics_vec256 r152 = r_5[2U];
  Lib_IntVector_Intrinsics_vec256 r153 = r_5[3U];
  Lib_IntVector_Intrinsics_vec256 r154 = r_5[4U];
  Lib_IntVector_Intrinsics_vec256 r40 = r45[0U];
  Lib_IntVector_Intrinsics_vec256 r41 = r45[1U];
  Lib_IntVector_Intrinsics_vec256 r42 = r45[2U];
  Lib_IntVector_Intrinsics_vec256 r43 = r45[3U];
  Lib_IntVector_Intrinsics_vec256 r44 = r45[4U];
  Lib_IntVector_Intrinsics_vec256 a010 = Lib_IntVector_Intrinsics_vec256_mul64(r10, r10);
  Lib_IntVector_Intrinsics_vec256 a110 = Lib_IntVector_Intrinsics_vec256_mul64(r11, r10);
  Lib_IntVector_Intrinsics_vec256 a210 = Lib_IntVector_Intrinsics_vec256_mul64(r12, r10);
  Lib_IntVector_Intrinsics_vec256 a310 = Lib_IntVector_Intrinsics_vec256_mul64(r13, r10);
  Lib_IntVector_Intrinsics_vec256 a410 = Lib_IntVector_Intrinsics_vec256_mul64(r14, r10);
  Lib_IntVector_Intrinsics_vec256
  a020 =
    Lib_IntVector_Intrinsics_vec256_add64(a010,
      Lib_IntVector_Intrinsics_vec256_mul64(r154, r11));
  Lib_IntVector_Intrinsics_vec256
  a120 =
    Lib_IntVector_Intrinsics_vec256_add64(a110,
      Lib_IntVector_Intrinsics_vec256_mul64(r10, r11));
  Lib_IntVector_Intrinsics_vec256
  a220 =
    Lib_IntVector_Intrinsics_vec256_add64(a210,
      Lib_IntVector_Intrinsics_vec256_mul64(r11, r11));
  Lib_IntVector_Intrinsics_vec256
  a320 =
    Lib_IntVector_Intrinsics_vec256_add64(a310,
      Lib_IntVector_Intrinsics_vec256_mul64(r12, r11));
  Lib_IntVector_Intrinsics_vec256
  a420 =
    Lib_IntVector_Intrinsics_vec256_add64(a410,
      Lib_IntVector_Intrinsics_vec256_mul64(r13, r11));
  Lib_IntVector_Intrinsics_vec256
  a030 =
    Lib_IntVector_Intrinsics_vec256_add64(a020,
      Lib_IntVector_Intrinsics_vec256_mul64(r153, r12));
  Lib_IntVector_Intrinsics_vec256
  a130 =
    Lib_IntVector_Intrinsics_vec256_add64(a120,
      Lib_IntVector_Intrinsics_vec256_mul64(r154, r12));
  Lib_IntVector_Intrinsics_vec256
  a230 =
    Lib_IntVector_Intrinsics_vec256_add64(a220,
      Lib_IntVector_Intrinsics_vec256_mul64(r10, r12));
  Lib_IntVector_Intrinsics_vec256
  a330 =
    Lib_IntVector_Intrinsics_vec256_add64(a320,
      Lib_IntVector_Intrinsics_vec256_mul64(r11, r12));
  Lib_IntVector_Intrinsics_vec256
  a430 =
    Lib_IntVector_Intrinsics_vec256_add64(a420,
      Lib_IntVector_Intrinsics_vec256_mul64(r12, r12));
  Lib_IntVector_Intrinsics_vec256
  a040 =
    Lib_IntVector_Intrinsics_vec256_add64(a030,
      Lib_IntVector_Intrinsics_vec256_mul64(r152, r13));
  Lib_IntVector_Intrinsics_vec256
  a140 =
    Lib_IntVector_Intrinsics_vec256_add64(a130,
      Lib_IntVector_Intrinsics_vec256_mul64(r153, r13));
  Lib_IntVector_Intrinsics_vec256
  a240 =
    Lib_IntVector_Intrinsics_vec256_add64(a230,
      Lib_IntVector_Intrinsics_vec256_mul64(r154, r13));
  Lib_IntVector_Intrinsics_vec256
  a340 =
    Lib_IntVector_Intrinsics_vec256_add64(a330,
      Lib_IntVector_Intrinsics_vec256_mul64(r10, r13));
  Lib_IntVector_Intrinsics_vec256
  a440 =
    Lib_IntVector_Intrinsics_vec256_add64(a430,
      Lib_IntVector_Intrinsics_vec256_mul64(r11, r13));
  Lib_IntVector_Intrinsics_vec256
  a050 =
    Lib_IntVector_Intrinsics_vec256_add64(a040,
      Lib_IntVector_Intrinsics_vec256_mul64(r151, r14));
  Lib_IntVector_Intrinsics_vec256
  a150 =
    Lib_IntVector_Intrinsics_vec256_add64(a140,
      Lib_IntVector_Intrinsics_vec256_mul64(r152, r14));
  Lib_IntVector_Intrinsics_vec256
  a250 =
    Lib_IntVector_Intrinsics_vec256_add64(a240,
      Lib_IntVector_Intrinsics_vec256_mul64(r153, r14));
  Lib_IntVector_Intrinsics_vec256
  a350 =
    Lib_IntVector_Intrinsics_vec256_add64(a340,
      Lib_IntVector_Intrinsics_vec256_mul64(r154, r14));
  Lib_IntVector_Intrinsics_vec256
  a450 =
    Lib_IntVector_Intrinsics_vec256_add64(a440,
      Lib_IntVector_Intrinsics_vec256_mul64(r10, r14));
  Lib_IntVector_Intrinsics_vec256 t010 = a050;
  Lib_IntVector_Intrinsics_vec256 t10 = a150;
  Lib_IntVector_Intrinsics_vec256 t20 = a250;
  Lib_IntVector_Intrinsics_vec256 t30 = a350;
  Lib_IntVector_Intrinsics_vec256 t40 = a450;
  Lib_IntVector_Intrinsics_vec256
  l0 = Lib_IntVector_Intrinsics_vec256_add64(t010, Lib_IntVector_Intrinsics_vec256_zero);
  Lib_IntVector_Intrinsics_vec256
  tmp00 =
    Lib_IntVector_Intrinsics_vec256_and(l0,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c00 = Lib_IntVector_Intrinsics_vec256_shift_right64(l0, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l1 = Lib_IntVector_Intrinsics_vec256_add64(t10, c00);
  Lib_IntVector_Intrinsics_vec256
  tmp10 =
    Lib_IntVector_Intrinsics_vec256_and(l1,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c10 = Lib_IntVector_Intrinsics_vec256_shift_right64(l1, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l2 = Lib_IntVector_Intrinsics_vec256_add64(t20, c10);
  Lib_IntVector_Intrinsics_vec256
  tmp20 =
    Lib_IntVector_Intrinsics_vec256_and(l2,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c20 = Lib_IntVector_Intrinsics_vec256_shift_right64(l2, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l3 = Lib_IntVector_Intrinsics_vec256_add64(t30, c20);
  Lib_IntVector_Intrinsics_vec256
  tmp30 =
    Lib_IntVector_Intrinsics_vec256_and(l3,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c30 = Lib_IntVector_Intrinsics_vec256_shift_right64(l3, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l4 = Lib_IntVector_Intrinsics_vec256_add64(t40, c30);
  Lib_IntVector_Intrinsics_vec256
  tmp40 =
    Lib_IntVector_Intrinsics_vec256_and(l4,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c40 = Lib_IntVector_Intrinsics_vec256_shift_right64(l4, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256
  l5 =
    Lib_IntVector_Intrinsics_vec256_add64(tmp00,
      Lib_IntVector_Intrinsics_vec256_smul64(c40, (uint64_t)5U));
  Lib_IntVector_Intrinsics_vec256
  tmp010 =
    Lib_IntVector_Intrinsics_vec256_and(l5,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c50 = Lib_IntVector_Intrinsics_vec256_shift_right64(l5, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 tmp11 = Lib_IntVector_Intrinsics_vec256_add64(tmp10, c50);
  Lib_IntVector_Intrinsics_vec256 r20 = tmp010;
  Lib_IntVector_Intrinsics_vec256 r21 = tmp11;
  Lib_IntVector_Intrinsics_vec256 r22 = tmp20;
  Lib_IntVector_Intrinsics_vec256 r23 = tmp30;
  Lib_IntVector_Intrinsics_vec256 r24 = tmp40;
  Lib_IntVector_Intrinsics_vec256 a011 = Lib_IntVector_Intrinsics_vec256_mul64(r10, r20);
  Lib_IntVector_Intrinsics_vec256 a111 = Lib_IntVector_Intrinsics_vec256_mul64(r11, r20);
  Lib_IntVector_Intrinsics_vec256 a211 = Lib_IntVector_Intrinsics_vec256_mul64(r12, r20);
  Lib_IntVector_Intrinsics_vec256 a311 = Lib_IntVector_Intrinsics_vec256_mul64(r13, r20);
  Lib_IntVector_Intrinsics_vec256 a411 = Lib_IntVector_Intrinsics_vec256_mul64(r14, r20);
  Lib_IntVector_Intrinsics_vec256
  a021 =
    Lib_IntVector_Intrinsics_vec256_add64(a011,
      Lib_IntVector_Intrinsics_vec256_mul64(r154, r21));
  Lib_IntVector_Intrinsics_vec256
  a121 =
    Lib_IntVector_Intrinsics_vec256_add64(a111,
      Lib_IntVector_Intrinsics_vec256_mul64(r10, r21));
  Lib_IntVector_Intrinsics_vec256
  a221 =
    Lib_IntVector_Intrinsics_vec256_add64(a211,
      Lib_IntVector_Intrinsics_vec256_mul64(r11, r21));
  Lib_IntVector_Intrinsics_vec256
  a321 =
    Lib_IntVector_Intrinsics_vec256_add64(a311,
      Lib_IntVector_Intrinsics_vec256_mul64(r12, r21));
  Lib_IntVector_Intrinsics_vec256
  a421 =
    Lib_IntVector_Intrinsics_vec256_add64(a411,
      Lib_IntVector_Intrinsics_vec256_mul64(r13, r21));
  Lib_IntVector_Intrinsics_vec256
  a031 =
    Lib_IntVector_Intrinsics_vec256_add64(a021,
      Lib_IntVector_Intrinsics_vec256_mul64(r153, r22));
  Lib_IntVector_Intrinsics_vec256
  a131 =
    Lib_IntVector_Intrinsics_vec256_add64(a121,
      Lib_IntVector_Intrinsics_vec256_mul64(r154, r22));
  Lib_IntVector_Intrinsics_vec256
  a231 =
    Lib_IntVector_Intrinsics_vec256_add64(a221,
      Lib_IntVector_Intrinsics_vec256_mul64(r10, r22));
  Lib_IntVector_Intrinsics_vec256
  a331 =
    Lib_IntVector_Intrinsics_vec256_add64(a321,
      Lib_IntVector_Intrinsics_vec256_mul64(r11, r22));
  Lib_IntVector_Intrinsics_vec256
  a431 =
    Lib_IntVector_Intrinsics_vec256_add64(a421,
      Lib_IntVector_Intrinsics_vec256_mul64(r12, r22));
  Lib_IntVector_Intrinsics_vec256
  a041 =
    Lib_IntVector_Intrinsics_vec256_add64(a031,
      Lib_IntVector_Intrinsics_vec256_mul64(r152, r23));
  Lib_IntVector_Intrinsics_vec256
  a141 =
    Lib_IntVector_Intrinsics_vec256_add64(a131,
      Lib_IntVector_Intrinsics_vec256_mul64(r153, r23));
  Lib_IntVector_Intrinsics_vec256
  a241 =
    Lib_IntVector_Intrinsics_vec256_add64(a231,
      Lib_IntVector_Intrinsics_vec256_mul64(r154, r23));
  Lib_IntVector_Intrinsics_vec256
  a341 =
    Lib_IntVector_Intrinsics_vec256_add64(a331,
      Lib_IntVector_Intrinsics_vec256_mul64(r10, r23));
  Lib_IntVector_Intrinsics_vec256
  a441 =
    Lib_IntVector_Intrinsics_vec256_add64(a431,
      Lib_IntVector_Intrinsics_vec256_mul64(r11, r23));
  Lib_IntVector_Intrinsics_vec256
  a051 =
    Lib_IntVector_Intrinsics_vec256_add64(a041,
      Lib_IntVector_Intrinsics_vec256_mul64(r151, r24));
  Lib_IntVector_Intrinsics_vec256
  a151 =
    Lib_IntVector_Intrinsics_vec256_add64(a141,
      Lib_IntVector_Intrinsics_vec256_mul64(r152, r24));
  Lib_IntVector_Intrinsics_vec256
  a251 =
    Lib_IntVector_Intrinsics_vec256_add64(a241,
      Lib_IntVector_Intrinsics_vec256_mul64(r153, r24));
  Lib_IntVector_Intrinsics_vec256
  a351 =
    Lib_IntVector_Intrinsics_vec256_add64(a341,
      Lib_IntVector_Intrinsics_vec256_mul64(r154, r24));
  Lib_IntVector_Intrinsics_vec256
  a451 =
    Lib_IntVector_Intrinsics_vec256_add64(a441,
      Lib_IntVector_Intrinsics_vec256_mul64(r10, r24));
  Lib_IntVector_Intrinsics_vec256 t011 = a051;
  Lib_IntVector_Intrinsics_vec256 t12 = a151;
  Lib_IntVector_Intrinsics_vec256 t21 = a251;
  Lib_IntVector_Intrinsics_vec256 t31 = a351;
  Lib_IntVector_Intrinsics_vec256 t41 = a451;
  Lib_IntVector_Intrinsics_vec256
  l6 = Lib_IntVector_Intrinsics_vec256_add64(t011, Lib_IntVector_Intrinsics_vec256_zero);
  Lib_IntVector_Intrinsics_vec256
  tmp02 =
    Lib_IntVector_Intrinsics_vec256_and(l6,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c01 = Lib_IntVector_Intrinsics_vec256_shift_right64(l6, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l7 = Lib_IntVector_Intrinsics_vec256_add64(t12, c01);
  Lib_IntVector_Intrinsics_vec256
  tmp12 =
    Lib_IntVector_Intrinsics_vec256_and(l7,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c11 = Lib_IntVector_Intrinsics_vec256_shift_right64(l7, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l8 = Lib_IntVector_Intrinsics_vec256_add64(t21, c11);
  Lib_IntVector_Intrinsics_vec256
  tmp21 =
    Lib_IntVector_Intrinsics_vec256_and(l8,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c21 = Lib_IntVector_Intrinsics_vec256_shift_right64(l8, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l9 = Lib_IntVector_Intrinsics_vec256_add64(t31, c21);
  Lib_IntVector_Intrinsics_vec256
  tmp31 =
    Lib_IntVector_Intrinsics_vec256_and(l9,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c31 = Lib_IntVector_Intrinsics_vec256_shift_right64(l9, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l10 = Lib_IntVector_Intrinsics_vec256_add64(t41, c31);
  Lib_IntVector_Intrinsics_vec256
  tmp41 =
    Lib_IntVector_Intrinsics_vec256_and(l10,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c41 = Lib_IntVector_Intrinsics_vec256_shift_right64(l10, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256
  l11 =
    Lib_IntVector_Intrinsics_vec256_add64(tmp02,
      Lib_IntVector_Intrinsics_vec256_smul64(c41, (uint64_t)5U));
  Lib_IntVector_Intrinsics_vec256
  tmp011 =
    Lib_IntVector_Intrinsics_vec256_and(l11,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c51 = Lib_IntVector_Intrinsics_vec256_shift_right64(l11, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 tmp110 = Lib_IntVector_Intrinsics_vec256_add64(tmp12, c51);
  Lib_IntVector_Intrinsics_vec256 r30 = tmp011;
  Lib_IntVector_Intrinsics_vec256 r31 = tmp110;
  Lib_IntVector_Intrinsics_vec256 r32 = tmp21;
  Lib_IntVector_Intrinsics_vec256 r33 = tmp31;
  Lib_IntVector_Intrinsics_vec256 r34 = tmp41;
  Lib_IntVector_Intrinsics_vec256
  v12120 = Lib_IntVector_Intrinsics_vec256_interleave_low64(r20, r10);
  Lib_IntVector_Intrinsics_vec256
  v34340 = Lib_IntVector_Intrinsics_vec256_interleave_low64(r40, r30);
  Lib_IntVector_Intrinsics_vec256
  r12340 = Lib_IntVector_Intrinsics_vec256_interleave_low128(v34340, v12120);
  Lib_IntVector_Intrinsics_vec256
  v12121 = Lib_IntVector_Intrinsics_vec256_interleave_low64(r21, r11);
  Lib_IntVector_Intrinsics_vec256
  v34341 = Lib_IntVector_Intrinsics_vec256_interleave_low64(r41, r31);
  Lib_IntVector_Intrinsics_vec256
  r12341 = Lib_IntVector_Intrinsics_vec256_interleave_low128(v34341, v12121);
  Lib_IntVector_Intrinsics_vec256
  v12122 = Lib_IntVector_Intrinsics_vec256_interleave_low64(r22, r12);
  Lib_IntVector_Intrinsics_vec256
  v34342 = Lib_IntVector_Intrinsics_vec256_interleave_low64(r42, r32);
  Lib_IntVector_Intrinsics_vec256
  r12342 = Lib_IntVector_Intrinsics_vec256_interleave_low128(v34342, v12122);
  Lib_IntVector_Intrinsics_vec256
  v12123 = Lib_IntVector_Intrinsics_vec256_interleave_low64(r23, r13);
  Lib_IntVector_Intrinsics_vec256
  v34343 = Lib_IntVector_Intrinsics_vec256_interleave_low64(r43, r33);
  Lib_IntVector_Intrinsics_vec256
  r12343 = Lib_IntVector_Intrinsics_vec256_interleave_low128(v34343, v12123);
  Lib_IntVector_Intrinsics_vec256
  v12124 = Lib_IntVector_Intrinsics_vec256_interleave_low64(r24, r14);
  Lib_IntVector_Intrinsics_vec256
  v34344 = Lib_IntVector_Intrinsics_vec256_interleave_low64(r44, r34);
  Lib_IntVector_Intrinsics_vec256
  r12344 = Lib_IntVector_Intrinsics_vec256_interleave_low128(v34344, v12124);
  Lib_IntVector_Intrinsics_vec256
  r123450 = Lib_IntVector_Intrinsics_vec256_smul64(r12340, (uint64_t)5U);
  Lib_IntVector_Intrinsics_vec256
  r123451 = Lib_IntVector_Intrinsics_vec256_smul64(r12341, (uint64_t)5U);
  Lib_IntVector_Intrinsics_vec256
  r123452 = Lib_IntVector_Intrinsics_vec256_smul64(r12342, (uint64_t)5U);
  Lib_IntVector_Intrinsics_vec256
  r123453 = Lib_IntVector_Intrinsics_vec256_smul64(r12343, (uint64_t)5U);
  Lib_IntVector_Intrinsics_vec256
  r123454 = Lib_IntVector_Intrinsics_vec256_smul64(r12344, (uint64_t)5U);
  Lib_IntVector_Intrinsics_vec256 a012 = Lib_IntVector_Intrinsics_vec256_mul64(r12340, a00);
  Lib_IntVector_Intrinsics_vec256 a112 = Lib_IntVector_Intrinsics_vec256_mul64(r12341, a00);
  Lib_IntVector_Intrinsics_vec256 a212 = Lib_IntVector_Intrinsics_vec256_mul64(r12342, a00);
  Lib_IntVector_Intrinsics_vec256 a312 = Lib_IntVector_Intrinsics_vec256_mul64(r12343, a00);
  Lib_IntVector_Intrinsics_vec256 a412 = Lib_IntVector_Intrinsics_vec256_mul64(r12344, a00);
  Lib_IntVector_Intrinsics_vec256
  a022 =
    Lib_IntVector_Intrinsics_vec256_add64(a012,
      Lib_IntVector_Intrinsics_vec256_mul64(r123454, a10));
  Lib_IntVector_Intrinsics_vec256
  a122 =
    Lib_IntVector_Intrinsics_vec256_add64(a112,
      Lib_IntVector_Intrinsics_vec256_mul64(r12340, a10));
  Lib_IntVector_Intrinsics_vec256
  a222 =
    Lib_IntVector_Intrinsics_vec256_add64(a212,
      Lib_IntVector_Intrinsics_vec256_mul64(r12341, a10));
  Lib_IntVector_Intrinsics_vec256
  a322 =
    Lib_IntVector_Intrinsics_vec256_add64(a312,
      Lib_IntVector_Intrinsics_vec256_mul64(r12342, a10));
  Lib_IntVector_Intrinsics_vec256
  a422 =
    Lib_IntVector_Intrinsics_vec256_add64(a412,
      Lib_IntVector_Intrinsics_vec256_mul64(r12343, a10));
  Lib_IntVector_Intrinsics_vec256
  a032 =
    Lib_IntVector_Intrinsics_vec256_add64(a022,
      Lib_IntVector_Intrinsics_vec256_mul64(r123453, a20));
  Lib_IntVector_Intrinsics_vec256
  a132 =
    Lib_IntVector_Intrinsics_vec256_add64(a122,
      Lib_IntVector_Intrinsics_vec256_mul64(r123454, a20));
  Lib_IntVector_Intrinsics_vec256
  a232 =
    Lib_IntVector_Intrinsics_vec256_add64(a222,
      Lib_IntVector_Intrinsics_vec256_mul64(r12340, a20));
  Lib_IntVector_Intrinsics_vec256
  a332 =
    Lib_IntVector_Intrinsics_vec256_add64(a322,
      Lib_IntVector_Intrinsics_vec256_mul64(r12341, a20));
  Lib_IntVector_Intrinsics_vec256
  a432 =
    Lib_IntVector_Intrinsics_vec256_add64(a422,
      Lib_IntVector_Intrinsics_vec256_mul64(r12342, a20));
  Lib_IntVector_Intrinsics_vec256
  a042 =
    Lib_IntVector_Intrinsics_vec256_add64(a032,
      Lib_IntVector_Intrinsics_vec256_mul64(r123452, a30));
  Lib_IntVector_Intrinsics_vec256
  a142 =
    Lib_IntVector_Intrinsics_vec256_add64(a132,
      Lib_IntVector_Intrinsics_vec256_mul64(r123453, a30));
  Lib_IntVector_Intrinsics_vec256
  a242 =
    Lib_IntVector_Intrinsics_vec256_add64(a232,
      Lib_IntVector_Intrinsics_vec256_mul64(r123454, a30));
  Lib_IntVector_Intrinsics_vec256
  a342 =
    Lib_IntVector_Intrinsics_vec256_add64(a332,
      Lib_IntVector_Intrinsics_vec256_mul64(r12340, a30));
  Lib_IntVector_Intrinsics_vec256
  a442 =
    Lib_IntVector_Intrinsics_vec256_add64(a432,
      Lib_IntVector_Intrinsics_vec256_mul64(r12341, a30));
  Lib_IntVector_Intrinsics_vec256
  a052 =
    Lib_IntVector_Intrinsics_vec256_add64(a042,
      Lib_IntVector_Intrinsics_vec256_mul64(r123451, a40));
  Lib_IntVector_Intrinsics_vec256
  a152 =
    Lib_IntVector_Intrinsics_vec256_add64(a142,
      Lib_IntVector_Intrinsics_vec256_mul64(r123452, a40));
  Lib_IntVector_Intrinsics_vec256
  a252 =
    Lib_IntVector_Intrinsics_vec256_add64(a242,
      Lib_IntVector_Intrinsics_vec256_mul64(r123453, a40));
  Lib_IntVector_Intrinsics_vec256
  a352 =
    Lib_IntVector_Intrinsics_vec256_add64(a342,
      Lib_IntVector_Intrinsics_vec256_mul64(r123454, a40));
  Lib_IntVector_Intrinsics_vec256
  a452 =
    Lib_IntVector_Intrinsics_vec256_add64(a442,
      Lib_IntVector_Intrinsics_vec256_mul64(r12340, a40));
  Lib_IntVector_Intrinsics_vec256 t012 = a052;
  Lib_IntVector_Intrinsics_vec256 t13 = a152;
  Lib_IntVector_Intrinsics_vec256 t22 = a252;
  Lib_IntVector_Intrinsics_vec256 t32 = a352;
  Lib_IntVector_Intrinsics_vec256 t42 = a452;
  Lib_IntVector_Intrinsics_vec256
  l12 = Lib_IntVector_Intrinsics_vec256_add64(t012, Lib_IntVector_Intrinsics_vec256_zero);
  Lib_IntVector_Intrinsics_vec256
  tmp03 =
    Lib_IntVector_Intrinsics_vec256_and(l12,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c02 = Lib_IntVector_Intrinsics_vec256_shift_right64(l12, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l13 = Lib_IntVector_Intrinsics_vec256_add64(t13, c02);
  Lib_IntVector_Intrinsics_vec256
  tmp13 =
    Lib_IntVector_Intrinsics_vec256_and(l13,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c12 = Lib_IntVector_Intrinsics_vec256_shift_right64(l13, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l14 = Lib_IntVector_Intrinsics_vec256_add64(t22, c12);
  Lib_IntVector_Intrinsics_vec256
  tmp22 =
    Lib_IntVector_Intrinsics_vec256_and(l14,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c22 = Lib_IntVector_Intrinsics_vec256_shift_right64(l14, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l15 = Lib_IntVector_Intrinsics_vec256_add64(t32, c22);
  Lib_IntVector_Intrinsics_vec256
  tmp32 =
    Lib_IntVector_Intrinsics_vec256_and(l15,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c32 = Lib_IntVector_Intrinsics_vec256_shift_right64(l15, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l16 = Lib_IntVector_Intrinsics_vec256_add64(t42, c32);
  Lib_IntVector_Intrinsics_vec256
  tmp42 =
    Lib_IntVector_Intrinsics_vec256_and(l16,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c42 = Lib_IntVector_Intrinsics_vec256_shift_right64(l16, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256
  l17 =
    Lib_IntVector_Intrinsics_vec256_add64(tmp03,
      Lib_IntVector_Intrinsics_vec256_smul64(c42, (uint64_t)5U));
  Lib_IntVector_Intrinsics_vec256
  tmp012 =
    Lib_IntVector_Intrinsics_vec256_and(l17,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c52 = Lib_IntVector_Intrinsics_vec256_shift_right64(l17, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 tmp111 = Lib_IntVector_Intrinsics_vec256_add64(tmp13, c52);
  Lib_IntVector_Intrinsics_vec256 o00 = tmp012;
  Lib_IntVector_Intrinsics_vec256 o10 = tmp111;
  Lib_IntVector_Intrinsics_vec256 o20 = tmp22;
  Lib_IntVector_Intrinsics_vec256 o30 = tmp32;
  Lib_IntVector_Intrinsics_vec256 o40 = tmp42;
  Lib_IntVector_Intrinsics_vec256
  v00 = Lib_IntVector_Intrinsics_vec256_interleave_high128(o00, o00);
  Lib_IntVector_Intrinsics_vec256 v10 = Lib_IntVector_Intrinsics_vec256_add64(o00, v00);
  Lib_IntVector_Intrinsics_vec256
  v20 =
    Lib_IntVector_Intrinsics_vec256_add64(v10,
      Lib_IntVector_Intrinsics_vec256_shuffle64(v10,
        (uint32_t)1U,
        (uint32_t)1U,
        (uint32_t)1U,
        (uint32_t)1U));
  Lib_IntVector_Intrinsics_vec256
  v01 = Lib_IntVector_Intrinsics_vec256_interleave_high128(o10, o10);
  Lib_IntVector_Intrinsics_vec256 v11 = Lib_IntVector_Intrinsics_vec256_add64(o10, v01);
  Lib_IntVector_Intrinsics_vec256
  v21 =
    Lib_IntVector_Intrinsics_vec256_add64(v11,
      Lib_IntVector_Intrinsics_vec256_shuffle64(v11,
        (uint32_t)1U,
        (uint32_t)1U,
        (uint32_t)1U,
        (uint32_t)1U));
  Lib_IntVector_Intrinsics_vec256
  v02 = Lib_IntVector_Intrinsics_vec256_interleave_high128(o20, o20);
  Lib_IntVector_Intrinsics_vec256 v12 = Lib_IntVector_Intrinsics_vec256_add64(o20, v02);
  Lib_IntVector_Intrinsics_vec256
  v22 =
    Lib_IntVector_Intrinsics_vec256_add64(v12,
      Lib_IntVector_Intrinsics_vec256_shuffle64(v12,
        (uint32_t)1U,
        (uint32_t)1U,
        (uint32_t)1U,
        (uint32_t)1U));
  Lib_IntVector_Intrinsics_vec256
  v03 = Lib_IntVector_Intrinsics_vec256_interleave_high128(o30, o30);
  Lib_IntVector_Intrinsics_vec256 v13 = Lib_IntVector_Intrinsics_vec256_add64(o30, v03);
  Lib_IntVector_Intrinsics_vec256
  v23 =
    Lib_IntVector_Intrinsics_vec256_add64(v13,
      Lib_IntVector_Intrinsics_vec256_shuffle64(v13,
        (uint32_t)1U,
        (uint32_t)1U,
        (uint32_t)1U,
        (uint32_t)1U));
  Lib_IntVector_Intrinsics_vec256
  v04 = Lib_IntVector_Intrinsics_vec256_interleave_high128(o40, o40);
  Lib_IntVector_Intrinsics_vec256 v14 = Lib_IntVector_Intrinsics_vec256_add64(o40, v04);
  Lib_IntVector_Intrinsics_vec256
  v24 =
    Lib_IntVector_Intrinsics_vec256_add64(v14,
      Lib_IntVector_Intrinsics_vec256_shuffle64(v14,
        (uint32_t)1U,
        (uint32_t)1U,
        (uint32_t)1U,
        (uint32_t)1U));
  Lib_IntVector_Intrinsics_vec256
  l18 = Lib_IntVector_Intrinsics_vec256_add64(v20, Lib_IntVector_Intrinsics_vec256_zero);
  Lib_IntVector_Intrinsics_vec256
  tmp04 =
    Lib_IntVector_Intrinsics_vec256_and(l18,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c03 = Lib_IntVector_Intrinsics_vec256_shift_right64(l18, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l19 = Lib_IntVector_Intrinsics_vec256_add64(v21, c03);
  Lib_IntVector_Intrinsics_vec256
  tmp14 =
    Lib_IntVector_Intrinsics_vec256_and(l19,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c13 = Lib_IntVector_Intrinsics_vec256_shift_right64(l19, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l20 = Lib_IntVector_Intrinsics_vec256_add64(v22, c13);
  Lib_IntVector_Intrinsics_vec256
  tmp23 =
    Lib_IntVector_Intrinsics_vec256_and(l20,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c23 = Lib_IntVector_Intrinsics_vec256_shift_right64(l20, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l21 = Lib_IntVector_Intrinsics_vec256_add64(v23, c23);
  Lib_IntVector_Intrinsics_vec256
  tmp33 =
    Lib_IntVector_Intrinsics_vec256_and(l21,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c33 = Lib_IntVector_Intrinsics_vec256_shift_right64(l21, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l22 = Lib_IntVector_Intrinsics_vec256_add64(v24, c33);
  Lib_IntVector_Intrinsics_vec256
  tmp43 =
    Lib_IntVector_Intrinsics_vec256_and(l22,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c43 = Lib_IntVector_Intrinsics_vec256_shift_right64(l22, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256
  l23 =
    Lib_IntVector_Intrinsics_vec256_add64(tmp04,
      Lib_IntVector_Intrinsics_vec256_smul64(c43, (uint64_t)5U));
  Lib_IntVector_Intrinsics_vec256
  tmp0_ =
    Lib_IntVector_Intrinsics_vec256_and(l23,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c53 = Lib_IntVector_Intrinsics_vec256_shift_right64(l23, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 o01 = tmp0_;
  Lib_IntVector_Intrinsics_vec256 o11 = Lib_IntVector_Intrinsics_vec256_add64(tmp14, c53);
  Lib_IntVector_Intrinsics_vec256 o21 = tmp23;
  Lib_IntVector_Intrinsics_vec256 o31 = tmp33;
  Lib_IntVector_Intrinsics_vec256 o41 = tmp43;
  acc[0U] = o01;
  acc[1U] = o11;
  acc[2U] = o21;
  acc[3U] = o31;
  acc[4U] = o41;
  uint32_t len11 = len1 - len0;
  uint8_t *t1 = text + len0;
  uint32_t nb = len11 / (uint32_t)16U;
  uint32_t rem1 = len11 % (uint32_t)16U;
  for (uint32_t i = (uint32_t)0U; i < nb; i = i + (uint32_t)1U)
  {
    uint8_t *block = t1 + i * (uint32_t)16U;
    KRML_CHECK_SIZE(sizeof (Lib_IntVector_Intrinsics_vec256), (uint32_t)5U);
    Lib_IntVector_Intrinsics_vec256 e[5U];
    for (uint32_t _i = 0U; _i < (uint32_t)5U; ++_i)
      e[_i] = Lib_IntVector_Intrinsics_vec256_zero;
    uint64_t u0 = load64_le(block);
    uint64_t lo = u0;
    uint64_t u = load64_le(block + (uint32_t)8U);
    uint64_t hi = u;
    Lib_IntVector_Intrinsics_vec256 f0 = Lib_IntVector_Intrinsics_vec256_load64(lo);
    Lib_IntVector_Intrinsics_vec256 f1 = Lib_IntVector_Intrinsics_vec256_load64(hi);
    Lib_IntVector_Intrinsics_vec256
    f010 =
      Lib_IntVector_Intrinsics_vec256_and(f0,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    f110 =
      Lib_IntVector_Intrinsics_vec256_and(Lib_IntVector_Intrinsics_vec256_shift_right64(f0,
          (uint32_t)26U),
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    f20 =
      Lib_IntVector_Intrinsics_vec256_or(Lib_IntVector_Intrinsics_vec256_shift_right64(f0,
          (uint32_t)52U),
        Lib_IntVector_Intrinsics_vec256_shift_left64(Lib_IntVector_Intrinsics_vec256_and(f1,
            Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3fffU)),
          (uint32_t)12U));
    Lib_IntVector_Intrinsics_vec256
    f30 =
      Lib_IntVector_Intrinsics_vec256_and(Lib_IntVector_Intrinsics_vec256_shift_right64(f1,
          (uint32_t)14U),
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    f40 = Lib_IntVector_Intrinsics_vec256_shift_right64(f1, (uint32_t)40U);
    Lib_IntVector_Intrinsics_vec256 f01 = f010;
    Lib_IntVector_Intrinsics_vec256 f111 = f110;
    Lib_IntVector_Intrinsics_vec256 f2 = f20;
    Lib_IntVector_Intrinsics_vec256 f3 = f30;
    Lib_IntVector_Intrinsics_vec256 f41 = f40;
    e[0U] = f01;
    e[1U] = f111;
    e[2U] = f2;
    e[3U] = f3;
    e[4U] = f41;
    uint64_t b = (uint64_t)0x1000000U;
    Lib_IntVector_Intrinsics_vec256 mask = Lib_IntVector_Intrinsics_vec256_load64(b);
    Lib_IntVector_Intrinsics_vec256 f4 = e[4U];
    e[4U] = Lib_IntVector_Intrinsics_vec256_or(f4, mask);
    Lib_IntVector_Intrinsics_vec256 *r6 = pre;
    Lib_IntVector_Intrinsics_vec256 *r5 = pre + (uint32_t)5U;
    Lib_IntVector_Intrinsics_vec256 r0 = r6[0U];
    Lib_IntVector_Intrinsics_vec256 r1 = r6[1U];
    Lib_IntVector_Intrinsics_vec256 r2 = r6[2U];
    Lib_IntVector_Intrinsics_vec256 r3 = r6[3U];
    Lib_IntVector_Intrinsics_vec256 r4 = r6[4U];
    Lib_IntVector_Intrinsics_vec256 r51 = r5[1U];
    Lib_IntVector_Intrinsics_vec256 r52 = r5[2U];
    Lib_IntVector_Intrinsics_vec256 r53 = r5[3U];
    Lib_IntVector_Intrinsics_vec256 r54 = r5[4U];
    Lib_IntVector_Intrinsics_vec256 f10 = e[0U];
    Lib_IntVector_Intrinsics_vec256 f11 = e[1U];
    Lib_IntVector_Intrinsics_vec256 f12 = e[2U];
    Lib_IntVector_Intrinsics_vec256 f13 = e[3U];
    Lib_IntVector_Intrinsics_vec256 f14 = e[4U];
    Lib_IntVector_Intrinsics_vec256 a0 = acc[0U];
    Lib_IntVector_Intrinsics_vec256 a1 = acc[1U];
    Lib_IntVector_Intrinsics_vec256 a2 = acc[2U];
    Lib_IntVector_Intrinsics_vec256 a3 = acc[3U];
    Lib_IntVector_Intrinsics_vec256 a4 = acc[4U];
    Lib_IntVector_Intrinsics_vec256 a01 = Lib_IntVector_Intrinsics_vec256_add64(a0, f10);
    Lib_IntVector_Intrinsics_vec256 a11 = Lib_IntVector_Intrinsics_vec256_add64(a1, f11);
    Lib_IntVector_Intrinsics_vec256 a21 = Lib_IntVector_Intrinsics_vec256_add64(a2, f12);
    Lib_IntVector_Intrinsics_vec256 a31 = Lib_IntVector_Intrinsics_vec256_add64(a3, f13);
    Lib_IntVector_Intrinsics_vec256 a41 = Lib_IntVector_Intrinsics_vec256_add64(a4, f14);
    Lib_IntVector_Intrinsics_vec256 a02 = Lib_IntVector_Intrinsics_vec256_mul64(r0, a01);
    Lib_IntVector_Intrinsics_vec256 a12 = Lib_IntVector_Intrinsics_vec256_mul64(r1, a01);
    Lib_IntVector_Intrinsics_vec256 a22 = Lib_IntVector_Intrinsics_vec256_mul64(r2, a01);
    Lib_IntVector_Intrinsics_vec256 a32 = Lib_IntVector_Intrinsics_vec256_mul64(r3, a01);
    Lib_IntVector_Intrinsics_vec256 a42 = Lib_IntVector_Intrinsics_vec256_mul64(r4, a01);
    Lib_IntVector_Intrinsics_vec256
    a03 =
      Lib_IntVector_Intrinsics_vec256_add64(a02,
        Lib_IntVector_Intrinsics_vec256_mul64(r54, a11));
    Lib_IntVector_Intrinsics_vec256
    a13 =
      Lib_IntVector_Intrinsics_vec256_add64(a12,
        Lib_IntVector_Intrinsics_vec256_mul64(r0, a11));
    Lib_IntVector_Intrinsics_vec256
    a23 =
      Lib_IntVector_Intrinsics_vec256_add64(a22,
        Lib_IntVector_Intrinsics_vec256_mul64(r1, a11));
    Lib_IntVector_Intrinsics_vec256
    a33 =
      Lib_IntVector_Intrinsics_vec256_add64(a32,
        Lib_IntVector_Intrinsics_vec256_mul64(r2, a11));
    Lib_IntVector_Intrinsics_vec256
    a43 =
      Lib_IntVector_Intrinsics_vec256_add64(a42,
        Lib_IntVector_Intrinsics_vec256_mul64(r3, a11));
    Lib_IntVector_Intrinsics_vec256
    a04 =
      Lib_IntVector_Intrinsics_vec256_add64(a03,
        Lib_IntVector_Intrinsics_vec256_mul64(r53, a21));
    Lib_IntVector_Intrinsics_vec256
    a14 =
      Lib_IntVector_Intrinsics_vec256_add64(a13,
        Lib_IntVector_Intrinsics_vec256_mul64(r54, a21));
    Lib_IntVector_Intrinsics_vec256
    a24 =
      Lib_IntVector_Intrinsics_vec256_add64(a23,
        Lib_IntVector_Intrinsics_vec256_mul64(r0, a21));
    Lib_IntVector_Intrinsics_vec256
    a34 =
      Lib_IntVector_Intrinsics_vec256_add64(a33,
        Lib_IntVector_Intrinsics_vec256_mul64(r1, a21));
    Lib_IntVector_Intrinsics_vec256
    a44 =
      Lib_IntVector_Intrinsics_vec256_add64(a43,
        Lib_IntVector_Intrinsics_vec256_mul64(r2, a21));
    Lib_IntVector_Intrinsics_vec256
    a05 =
      Lib_IntVector_Intrinsics_vec256_add64(a04,
        Lib_IntVector_Intrinsics_vec256_mul64(r52, a31));
    Lib_IntVector_Intrinsics_vec256
    a15 =
      Lib_IntVector_Intrinsics_vec256_add64(a14,
        Lib_IntVector_Intrinsics_vec256_mul64(r53, a31));
    Lib_IntVector_Intrinsics_vec256
    a25 =
      Lib_IntVector_Intrinsics_vec256_add64(a24,
        Lib_IntVector_Intrinsics_vec256_mul64(r54, a31));
    Lib_IntVector_Intrinsics_vec256
    a35 =
      Lib_IntVector_Intrinsics_vec256_add64(a34,
        Lib_IntVector_Intrinsics_vec256_mul64(r0, a31));
    Lib_IntVector_Intrinsics_vec256
    a45 =
      Lib_IntVector_Intrinsics_vec256_add64(a44,
        Lib_IntVector_Intrinsics_vec256_mul64(r1, a31));
    Lib_IntVector_Intrinsics_vec256
    a06 =
      Lib_IntVector_Intrinsics_vec256_add64(a05,
        Lib_IntVector_Intrinsics_vec256_mul64(r51, a41));
    Lib_IntVector_Intrinsics_vec256
    a16 =
      Lib_IntVector_Intrinsics_vec256_add64(a15,
        Lib_IntVector_Intrinsics_vec256_mul64(r52, a41));
    Lib_IntVector_Intrinsics_vec256
    a26 =
      Lib_IntVector_Intrinsics_vec256_add64(a25,
        Lib_IntVector_Intrinsics_vec256_mul64(r53, a41));
    Lib_IntVector_Intrinsics_vec256
    a36 =
      Lib_IntVector_Intrinsics_vec256_add64(a35,
        Lib_IntVector_Intrinsics_vec256_mul64(r54, a41));
    Lib_IntVector_Intrinsics_vec256
    a46 =
      Lib_IntVector_Intrinsics_vec256_add64(a45,
        Lib_IntVector_Intrinsics_vec256_mul64(r0, a41));
    Lib_IntVector_Intrinsics_vec256 t01 = a06;
    Lib_IntVector_Intrinsics_vec256 t11 = a16;
    Lib_IntVector_Intrinsics_vec256 t2 = a26;
    Lib_IntVector_Intrinsics_vec256 t3 = a36;
    Lib_IntVector_Intrinsics_vec256 t4 = a46;
    Lib_IntVector_Intrinsics_vec256
    l = Lib_IntVector_Intrinsics_vec256_add64(t01, Lib_IntVector_Intrinsics_vec256_zero);
    Lib_IntVector_Intrinsics_vec256
    tmp0 =
      Lib_IntVector_Intrinsics_vec256_and(l,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    c0 = Lib_IntVector_Intrinsics_vec256_shift_right64(l, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec256 l24 = Lib_IntVector_Intrinsics_vec256_add64(t11, c0);
    Lib_IntVector_Intrinsics_vec256
    tmp1 =
      Lib_IntVector_Intrinsics_vec256_and(l24,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    c1 = Lib_IntVector_Intrinsics_vec256_shift_right64(l24, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec256 l25 = Lib_IntVector_Intrinsics_vec256_add64(t2, c1);
    Lib_IntVector_Intrinsics_vec256
    tmp2 =
      Lib_IntVector_Intrinsics_vec256_and(l25,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    c2 = Lib_IntVector_Intrinsics_vec256_shift_right64(l25, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec256 l26 = Lib_IntVector_Intrinsics_vec256_add64(t3, c2);
    Lib_IntVector_Intrinsics_vec256
    tmp3 =
      Lib_IntVector_Intrinsics_vec256_and(l26,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    c3 = Lib_IntVector_Intrinsics_vec256_shift_right64(l26, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec256 l27 = Lib_IntVector_Intrinsics_vec256_add64(t4, c3);
    Lib_IntVector_Intrinsics_vec256
    tmp4 =
      Lib_IntVector_Intrinsics_vec256_and(l27,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    c4 = Lib_IntVector_Intrinsics_vec256_shift_right64(l27, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec256
    l28 =
      Lib_IntVector_Intrinsics_vec256_add64(tmp0,
        Lib_IntVector_Intrinsics_vec256_smul64(c4, (uint64_t)5U));
    Lib_IntVector_Intrinsics_vec256
    tmp01 =
      Lib_IntVector_Intrinsics_vec256_and(l28,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    c5 = Lib_IntVector_Intrinsics_vec256_shift_right64(l28, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec256 tmp112 = Lib_IntVector_Intrinsics_vec256_add64(tmp1, c5);
    Lib_IntVector_Intrinsics_vec256 o0 = tmp01;
    Lib_IntVector_Intrinsics_vec256 o1 = tmp112;
    Lib_IntVector_Intrinsics_vec256 o2 = tmp2;
    Lib_IntVector_Intrinsics_vec256 o3 = tmp3;
    Lib_IntVector_Intrinsics_vec256 o4 = tmp4;
    acc[0U] = o0;
    acc[1U] = o1;
    acc[2U] = o2;
    acc[3U] = o3;
    acc[4U] = o4;
  }
  uint8_t *b = t1 + nb * (uint32_t)16U;
  if (rem1 > (uint32_t)0U)
  {
    KRML_CHECK_SIZE(sizeof (Lib_IntVector_Intrinsics_vec256), (uint32_t)5U);
    Lib_IntVector_Intrinsics_vec256 e[5U];
    for (uint32_t _i = 0U; _i < (uint32_t)5U; ++_i)
      e[_i] = Lib_IntVector_Intrinsics_vec256_zero;
    uint8_t tmp[16U] = { 0U };
    memcpy(tmp, b, rem1 * sizeof b[0U]);
    uint64_t u0 = load64_le(tmp);
    uint64_t lo = u0;
    uint64_t u = load64_le(tmp + (uint32_t)8U);
    uint64_t hi = u;
    Lib_IntVector_Intrinsics_vec256 f0 = Lib_IntVector_Intrinsics_vec256_load64(lo);
    Lib_IntVector_Intrinsics_vec256 f1 = Lib_IntVector_Intrinsics_vec256_load64(hi);
    Lib_IntVector_Intrinsics_vec256
    f010 =
      Lib_IntVector_Intrinsics_vec256_and(f0,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    f110 =
      Lib_IntVector_Intrinsics_vec256_and(Lib_IntVector_Intrinsics_vec256_shift_right64(f0,
          (uint32_t)26U),
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    f20 =
      Lib_IntVector_Intrinsics_vec256_or(Lib_IntVector_Intrinsics_vec256_shift_right64(f0,
          (uint32_t)52U),
        Lib_IntVector_Intrinsics_vec256_shift_left64(Lib_IntVector_Intrinsics_vec256_and(f1,
            Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3fffU)),
          (uint32_t)12U));
    Lib_IntVector_Intrinsics_vec256
    f30 =
      Lib_IntVector_Intrinsics_vec256_and(Lib_IntVector_Intrinsics_vec256_shift_right64(f1,
          (uint32_t)14U),
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    f40 = Lib_IntVector_Intrinsics_vec256_shift_right64(f1, (uint32_t)40U);
    Lib_IntVector_Intrinsics_vec256 f01 = f010;
    Lib_IntVector_Intrinsics_vec256 f111 = f110;
    Lib_IntVector_Intrinsics_vec256 f2 = f20;
    Lib_IntVector_Intrinsics_vec256 f3 = f30;
    Lib_IntVector_Intrinsics_vec256 f4 = f40;
    e[0U] = f01;
    e[1U] = f111;
    e[2U] = f2;
    e[3U] = f3;
    e[4U] = f4;
    uint64_t b1 = (uint64_t)1U << rem1 * (uint32_t)8U % (uint32_t)26U;
    Lib_IntVector_Intrinsics_vec256 mask = Lib_IntVector_Intrinsics_vec256_load64(b1);
    Lib_IntVector_Intrinsics_vec256 fi = e[rem1 * (uint32_t)8U / (uint32_t)26U];
    e[rem1 * (uint32_t)8U / (uint32_t)26U] = Lib_IntVector_Intrinsics_vec256_or(fi, mask);
    Lib_IntVector_Intrinsics_vec256 *r6 = pre;
    Lib_IntVector_Intrinsics_vec256 *r5 = pre + (uint32_t)5U;
    Lib_IntVector_Intrinsics_vec256 r0 = r6[0U];
    Lib_IntVector_Intrinsics_vec256 r1 = r6[1U];
    Lib_IntVector_Intrinsics_vec256 r2 = r6[2U];
    Lib_IntVector_Intrinsics_vec256 r3 = r6[3U];
    Lib_IntVector_Intrinsics_vec256 r4 = r6[4U];
    Lib_IntVector_Intrinsics_vec256 r51 = r5[1U];
    Lib_IntVector_Intrinsics_vec256 r52 = r5[2U];
    Lib_IntVector_Intrinsics_vec256 r53 = r5[3U];
    Lib_IntVector_Intrinsics_vec256 r54 = r5[4U];
    Lib_IntVector_Intrinsics_vec256 f10 = e[0U];
    Lib_IntVector_Intrinsics_vec256 f11 = e[1U];
    Lib_IntVector_Intrinsics_vec256 f12 = e[2U];
    Lib_IntVector_Intrinsics_vec256 f13 = e[3U];
    Lib_IntVector_Intrinsics_vec256 f14 = e[4U];
    Lib_IntVector_Intrinsics_vec256 a0 = acc[0U];
    Lib_IntVector_Intrinsics_vec256 a1 = acc[1U];
    Lib_IntVector_Intrinsics_vec256 a2 = acc[2U];
    Lib_IntVector_Intrinsics_vec256 a3 = acc[3U];
    Lib_IntVector_Intrinsics_vec256 a4 = acc[4U];
    Lib_IntVector_Intrinsics_vec256 a01 = Lib_IntVector_Intrinsics_vec256_add64(a0, f10);
    Lib_IntVector_Intrinsics_vec256 a11 = Lib_IntVector_Intrinsics_vec256_add64(a1, f11);
    Lib_IntVector_Intrinsics_vec256 a21 = Lib_IntVector_Intrinsics_vec256_add64(a2, f12);
    Lib_IntVector_Intrinsics_vec256 a31 = Lib_IntVector_Intrinsics_vec256_add64(a3, f13);
    Lib_IntVector_Intrinsics_vec256 a41 = Lib_IntVector_Intrinsics_vec256_add64(a4, f14);
    Lib_IntVector_Intrinsics_vec256 a02 = Lib_IntVector_Intrinsics_vec256_mul64(r0, a01);
    Lib_IntVector_Intrinsics_vec256 a12 = Lib_IntVector_Intrinsics_vec256_mul64(r1, a01);
    Lib_IntVector_Intrinsics_vec256 a22 = Lib_IntVector_Intrinsics_vec256_mul64(r2, a01);
    Lib_IntVector_Intrinsics_vec256 a32 = Lib_IntVector_Intrinsics_vec256_mul64(r3, a01);
    Lib_IntVector_Intrinsics_vec256 a42 = Lib_IntVector_Intrinsics_vec256_mul64(r4, a01);
    Lib_IntVector_Intrinsics_vec256
    a03 =
      Lib_IntVector_Intrinsics_vec256_add64(a02,
        Lib_IntVector_Intrinsics_vec256_mul64(r54, a11));
    Lib_IntVector_Intrinsics_vec256
    a13 =
      Lib_IntVector_Intrinsics_vec256_add64(a12,
        Lib_IntVector_Intrinsics_vec256_mul64(r0, a11));
    Lib_IntVector_Intrinsics_vec256
    a23 =
      Lib_IntVector_Intrinsics_vec256_add64(a22,
        Lib_IntVector_Intrinsics_vec256_mul64(r1, a11));
    Lib_IntVector_Intrinsics_vec256
    a33 =
      Lib_IntVector_Intrinsics_vec256_add64(a32,
        Lib_IntVector_Intrinsics_vec256_mul64(r2, a11));
    Lib_IntVector_Intrinsics_vec256
    a43 =
      Lib_IntVector_Intrinsics_vec256_add64(a42,
        Lib_IntVector_Intrinsics_vec256_mul64(r3, a11));
    Lib_IntVector_Intrinsics_vec256
    a04 =
      Lib_IntVector_Intrinsics_vec256_add64(a03,
        Lib_IntVector_Intrinsics_vec256_mul64(r53, a21));
    Lib_IntVector_Intrinsics_vec256
    a14 =
      Lib_IntVector_Intrinsics_vec256_add64(a13,
        Lib_IntVector_Intrinsics_vec256_mul64(r54, a21));
    Lib_IntVector_Intrinsics_vec256
    a24 =
      Lib_IntVector_Intrinsics_vec256_add64(a23,
        Lib_IntVector_Intrinsics_vec256_mul64(r0, a21));
    Lib_IntVector_Intrinsics_vec256
    a34 =
      Lib_IntVector_Intrinsics_vec256_add64(a33,
        Lib_IntVector_Intrinsics_vec256_mul64(r1, a21));
    Lib_IntVector_Intrinsics_vec256
    a44 =
      Lib_IntVector_Intrinsics_vec256_add64(a43,
        Lib_IntVector_Intrinsics_vec256_mul64(r2, a21));
    Lib_IntVector_Intrinsics_vec256
    a05 =
      Lib_IntVector_Intrinsics_vec256_add64(a04,
        Lib_IntVector_Intrinsics_vec256_mul64(r52, a31));
    Lib_IntVector_Intrinsics_vec256
    a15 =
      Lib_IntVector_Intrinsics_vec256_add64(a14,
        Lib_IntVector_Intrinsics_vec256_mul64(r53, a31));
    Lib_IntVector_Intrinsics_vec256
    a25 =
      Lib_IntVector_Intrinsics_vec256_add64(a24,
        Lib_IntVector_Intrinsics_vec256_mul64(r54, a31));
    Lib_IntVector_Intrinsics_vec256
    a35 =
      Lib_IntVector_Intrinsics_vec256_add64(a34,
        Lib_IntVector_Intrinsics_vec256_mul64(r0, a31));
    Lib_IntVector_Intrinsics_vec256
    a45 =
      Lib_IntVector_Intrinsics_vec256_add64(a44,
        Lib_IntVector_Intrinsics_vec256_mul64(r1, a31));
    Lib_IntVector_Intrinsics_vec256
    a06 =
      Lib_IntVector_Intrinsics_vec256_add64(a05,
        Lib_IntVector_Intrinsics_vec256_mul64(r51, a41));
    Lib_IntVector_Intrinsics_vec256
    a16 =
      Lib_IntVector_Intrinsics_vec256_add64(a15,
        Lib_IntVector_Intrinsics_vec256_mul64(r52, a41));
    Lib_IntVector_Intrinsics_vec256
    a26 =
      Lib_IntVector_Intrinsics_vec256_add64(a25,
        Lib_IntVector_Intrinsics_vec256_mul64(r53, a41));
    Lib_IntVector_Intrinsics_vec256
    a36 =
      Lib_IntVector_Intrinsics_vec256_add64(a35,
        Lib_IntVector_Intrinsics_vec256_mul64(r54, a41));
    Lib_IntVector_Intrinsics_vec256
    a46 =
      Lib_IntVector_Intrinsics_vec256_add64(a45,
        Lib_IntVector_Intrinsics_vec256_mul64(r0, a41));
    Lib_IntVector_Intrinsics_vec256 t01 = a06;
    Lib_IntVector_Intrinsics_vec256 t11 = a16;
    Lib_IntVector_Intrinsics_vec256 t2 = a26;
    Lib_IntVector_Intrinsics_vec256 t3 = a36;
    Lib_IntVector_Intrinsics_vec256 t4 = a46;
    Lib_IntVector_Intrinsics_vec256
    l = Lib_IntVector_Intrinsics_vec256_add64(t01, Lib_IntVector_Intrinsics_vec256_zero);
    Lib_IntVector_Intrinsics_vec256
    tmp0 =
      Lib_IntVector_Intrinsics_vec256_and(l,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    c0 = Lib_IntVector_Intrinsics_vec256_shift_right64(l, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec256 l24 = Lib_IntVector_Intrinsics_vec256_add64(t11, c0);
    Lib_IntVector_Intrinsics_vec256
    tmp1 =
      Lib_IntVector_Intrinsics_vec256_and(l24,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    c1 = Lib_IntVector_Intrinsics_vec256_shift_right64(l24, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec256 l25 = Lib_IntVector_Intrinsics_vec256_add64(t2, c1);
    Lib_IntVector_Intrinsics_vec256
    tmp2 =
      Lib_IntVector_Intrinsics_vec256_and(l25,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    c2 = Lib_IntVector_Intrinsics_vec256_shift_right64(l25, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec256 l26 = Lib_IntVector_Intrinsics_vec256_add64(t3, c2);
    Lib_IntVector_Intrinsics_vec256
    tmp3 =
      Lib_IntVector_Intrinsics_vec256_and(l26,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    c3 = Lib_IntVector_Intrinsics_vec256_shift_right64(l26, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec256 l27 = Lib_IntVector_Intrinsics_vec256_add64(t4, c3);
    Lib_IntVector_Intrinsics_vec256
    tmp4 =
      Lib_IntVector_Intrinsics_vec256_and(l27,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    c4 = Lib_IntVector_Intrinsics_vec256_shift_right64(l27, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec256
    l28 =
      Lib_IntVector_Intrinsics_vec256_add64(tmp0,
        Lib_IntVector_Intrinsics_vec256_smul64(c4, (uint64_t)5U));
    Lib_IntVector_Intrinsics_vec256
    tmp01 =
      Lib_IntVector_Intrinsics_vec256_and(l28,
        Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
    Lib_IntVector_Intrinsics_vec256
    c5 = Lib_IntVector_Intrinsics_vec256_shift_right64(l28, (uint32_t)26U);
    Lib_IntVector_Intrinsics_vec256 tmp112 = Lib_IntVector_Intrinsics_vec256_add64(tmp1, c5);
    Lib_IntVector_Intrinsics_vec256 o0 = tmp01;
    Lib_IntVector_Intrinsics_vec256 o1 = tmp112;
    Lib_IntVector_Intrinsics_vec256 o2 = tmp2;
    Lib_IntVector_Intrinsics_vec256 o3 = tmp3;
    Lib_IntVector_Intrinsics_vec256 o4 = tmp4;
    acc[0U] = o0;
    acc[1U] = o1;
    acc[2U] = o2;
    acc[3U] = o3;
    acc[4U] = o4;
  }
}

inline void Hacl_Impl_Poly1305_poly1305_finish_32(uint8_t *tag, uint8_t *key, uint64_t *ctx)
{
  uint64_t *acc = ctx;
  uint8_t *ks = key + (uint32_t)16U;
  uint64_t f00 = acc[0U];
  uint64_t f12 = acc[1U];
  uint64_t f22 = acc[2U];
  uint64_t f32 = acc[3U];
  uint64_t f40 = acc[4U];
  uint64_t l = f00 + (uint64_t)0U;
  uint64_t tmp0 = l & (uint64_t)0x3ffffffU;
  uint64_t c0 = l >> (uint32_t)26U;
  uint64_t l0 = f12 + c0;
  uint64_t tmp1 = l0 & (uint64_t)0x3ffffffU;
  uint64_t c1 = l0 >> (uint32_t)26U;
  uint64_t l1 = f22 + c1;
  uint64_t tmp2 = l1 & (uint64_t)0x3ffffffU;
  uint64_t c2 = l1 >> (uint32_t)26U;
  uint64_t l2 = f32 + c2;
  uint64_t tmp3 = l2 & (uint64_t)0x3ffffffU;
  uint64_t c3 = l2 >> (uint32_t)26U;
  uint64_t l3 = f40 + c3;
  uint64_t tmp4 = l3 & (uint64_t)0x3ffffffU;
  uint64_t c4 = l3 >> (uint32_t)26U;
  uint64_t l4 = tmp0 + c4 * (uint64_t)5U;
  uint64_t tmp0_ = l4 & (uint64_t)0x3ffffffU;
  uint64_t c5 = l4 >> (uint32_t)26U;
  uint64_t f010 = tmp0_;
  uint64_t f110 = tmp1 + c5;
  uint64_t f210 = tmp2;
  uint64_t f310 = tmp3;
  uint64_t f410 = tmp4;
  uint64_t mh = (uint64_t)0x3ffffffU;
  uint64_t ml = (uint64_t)0x3fffffbU;
  uint64_t mask = FStar_UInt64_eq_mask(f410, mh);
  uint64_t mask1 = mask & FStar_UInt64_eq_mask(f310, mh);
  uint64_t mask2 = mask1 & FStar_UInt64_eq_mask(f210, mh);
  uint64_t mask3 = mask2 & FStar_UInt64_eq_mask(f110, mh);
  uint64_t mask4 = mask3 & ~~FStar_UInt64_gte_mask(f010, ml);
  uint64_t ph = mask4 & mh;
  uint64_t pl = mask4 & ml;
  uint64_t o0 = f010 - pl;
  uint64_t o1 = f110 - ph;
  uint64_t o2 = f210 - ph;
  uint64_t o3 = f310 - ph;
  uint64_t o4 = f410 - ph;
  uint64_t f01 = o0;
  uint64_t f111 = o1;
  uint64_t f211 = o2;
  uint64_t f311 = o3;
  uint64_t f41 = o4;
  acc[0U] = f01;
  acc[1U] = f111;
  acc[2U] = f211;
  acc[3U] = f311;
  acc[4U] = f41;
  uint64_t f02 = acc[0U];
  uint64_t f13 = acc[1U];
  uint64_t f2 = acc[2U];
  uint64_t f3 = acc[3U];
  uint64_t f4 = acc[4U];
  uint64_t lo = (f02 | f13 << (uint32_t)26U) | f2 << (uint32_t)52U;
  uint64_t hi = (f2 >> (uint32_t)12U | f3 << (uint32_t)14U) | f4 << (uint32_t)40U;
  uint64_t f10 = lo;
  uint64_t f11 = hi;
  uint64_t u0 = load64_le(ks);
  uint64_t lo0 = u0;
  uint64_t u = load64_le(ks + (uint32_t)8U);
  uint64_t hi0 = u;
  uint64_t f0 = lo0;
  uint64_t f1 = hi0;
  uint64_t f20 = f0;
  uint64_t f21 = f1;
  uint64_t r0 = f10 + f20;
  uint64_t r1 = f11 + f21;
  uint64_t c = (r0 ^ ((r0 ^ f20) | ((r0 - f20) ^ f20))) >> (uint32_t)63U;
  uint64_t r11 = r1 + c;
  uint64_t f30 = r0;
  uint64_t f31 = r11;
  store64_le(tag, f30);
  store64_le(tag + (uint32_t)8U, f31);
}

inline static void
Hacl_Impl_Poly1305_poly1305_finish_128(
  uint8_t *tag,
  uint8_t *key,
  Lib_IntVector_Intrinsics_vec128 *ctx
)
{
  Lib_IntVector_Intrinsics_vec128 *acc = ctx;
  uint8_t *ks = key + (uint32_t)16U;
  Lib_IntVector_Intrinsics_vec128 f00 = acc[0U];
  Lib_IntVector_Intrinsics_vec128 f12 = acc[1U];
  Lib_IntVector_Intrinsics_vec128 f22 = acc[2U];
  Lib_IntVector_Intrinsics_vec128 f32 = acc[3U];
  Lib_IntVector_Intrinsics_vec128 f40 = acc[4U];
  Lib_IntVector_Intrinsics_vec128
  l = Lib_IntVector_Intrinsics_vec128_add64(f00, Lib_IntVector_Intrinsics_vec128_zero);
  Lib_IntVector_Intrinsics_vec128
  tmp0 =
    Lib_IntVector_Intrinsics_vec128_and(l,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c0 = Lib_IntVector_Intrinsics_vec128_shift_right64(l, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 l0 = Lib_IntVector_Intrinsics_vec128_add64(f12, c0);
  Lib_IntVector_Intrinsics_vec128
  tmp1 =
    Lib_IntVector_Intrinsics_vec128_and(l0,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c1 = Lib_IntVector_Intrinsics_vec128_shift_right64(l0, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 l1 = Lib_IntVector_Intrinsics_vec128_add64(f22, c1);
  Lib_IntVector_Intrinsics_vec128
  tmp2 =
    Lib_IntVector_Intrinsics_vec128_and(l1,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c2 = Lib_IntVector_Intrinsics_vec128_shift_right64(l1, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 l2 = Lib_IntVector_Intrinsics_vec128_add64(f32, c2);
  Lib_IntVector_Intrinsics_vec128
  tmp3 =
    Lib_IntVector_Intrinsics_vec128_and(l2,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c3 = Lib_IntVector_Intrinsics_vec128_shift_right64(l2, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 l3 = Lib_IntVector_Intrinsics_vec128_add64(f40, c3);
  Lib_IntVector_Intrinsics_vec128
  tmp4 =
    Lib_IntVector_Intrinsics_vec128_and(l3,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c4 = Lib_IntVector_Intrinsics_vec128_shift_right64(l3, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128
  l4 =
    Lib_IntVector_Intrinsics_vec128_add64(tmp0,
      Lib_IntVector_Intrinsics_vec128_smul64(c4, (uint64_t)5U));
  Lib_IntVector_Intrinsics_vec128
  tmp0_ =
    Lib_IntVector_Intrinsics_vec128_and(l4,
      Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec128
  c5 = Lib_IntVector_Intrinsics_vec128_shift_right64(l4, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec128 f010 = tmp0_;
  Lib_IntVector_Intrinsics_vec128 f110 = Lib_IntVector_Intrinsics_vec128_add64(tmp1, c5);
  Lib_IntVector_Intrinsics_vec128 f210 = tmp2;
  Lib_IntVector_Intrinsics_vec128 f310 = tmp3;
  Lib_IntVector_Intrinsics_vec128 f410 = tmp4;
  Lib_IntVector_Intrinsics_vec128
  mh = Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3ffffffU);
  Lib_IntVector_Intrinsics_vec128
  ml = Lib_IntVector_Intrinsics_vec128_load64((uint64_t)0x3fffffbU);
  Lib_IntVector_Intrinsics_vec128 mask = Lib_IntVector_Intrinsics_vec128_eq64(f410, mh);
  Lib_IntVector_Intrinsics_vec128
  mask1 =
    Lib_IntVector_Intrinsics_vec128_and(mask,
      Lib_IntVector_Intrinsics_vec128_eq64(f310, mh));
  Lib_IntVector_Intrinsics_vec128
  mask2 =
    Lib_IntVector_Intrinsics_vec128_and(mask1,
      Lib_IntVector_Intrinsics_vec128_eq64(f210, mh));
  Lib_IntVector_Intrinsics_vec128
  mask3 =
    Lib_IntVector_Intrinsics_vec128_and(mask2,
      Lib_IntVector_Intrinsics_vec128_eq64(f110, mh));
  Lib_IntVector_Intrinsics_vec128
  mask4 =
    Lib_IntVector_Intrinsics_vec128_and(mask3,
      Lib_IntVector_Intrinsics_vec128_lognot(Lib_IntVector_Intrinsics_vec128_gt64(ml, f010)));
  Lib_IntVector_Intrinsics_vec128 ph = Lib_IntVector_Intrinsics_vec128_and(mask4, mh);
  Lib_IntVector_Intrinsics_vec128 pl = Lib_IntVector_Intrinsics_vec128_and(mask4, ml);
  Lib_IntVector_Intrinsics_vec128 o0 = Lib_IntVector_Intrinsics_vec128_sub64(f010, pl);
  Lib_IntVector_Intrinsics_vec128 o1 = Lib_IntVector_Intrinsics_vec128_sub64(f110, ph);
  Lib_IntVector_Intrinsics_vec128 o2 = Lib_IntVector_Intrinsics_vec128_sub64(f210, ph);
  Lib_IntVector_Intrinsics_vec128 o3 = Lib_IntVector_Intrinsics_vec128_sub64(f310, ph);
  Lib_IntVector_Intrinsics_vec128 o4 = Lib_IntVector_Intrinsics_vec128_sub64(f410, ph);
  Lib_IntVector_Intrinsics_vec128 f01 = o0;
  Lib_IntVector_Intrinsics_vec128 f111 = o1;
  Lib_IntVector_Intrinsics_vec128 f211 = o2;
  Lib_IntVector_Intrinsics_vec128 f311 = o3;
  Lib_IntVector_Intrinsics_vec128 f41 = o4;
  acc[0U] = f01;
  acc[1U] = f111;
  acc[2U] = f211;
  acc[3U] = f311;
  acc[4U] = f41;
  Lib_IntVector_Intrinsics_vec128 f02 = acc[0U];
  Lib_IntVector_Intrinsics_vec128 f13 = acc[1U];
  Lib_IntVector_Intrinsics_vec128 f2 = acc[2U];
  Lib_IntVector_Intrinsics_vec128 f3 = acc[3U];
  Lib_IntVector_Intrinsics_vec128 f4 = acc[4U];
  Lib_IntVector_Intrinsics_vec128
  lo =
    Lib_IntVector_Intrinsics_vec128_or(Lib_IntVector_Intrinsics_vec128_or(f02,
        Lib_IntVector_Intrinsics_vec128_shift_left64(f13, (uint32_t)26U)),
      Lib_IntVector_Intrinsics_vec128_shift_left64(f2, (uint32_t)52U));
  Lib_IntVector_Intrinsics_vec128
  hi =
    Lib_IntVector_Intrinsics_vec128_or(Lib_IntVector_Intrinsics_vec128_or(Lib_IntVector_Intrinsics_vec128_shift_right64(f2,
          (uint32_t)12U),
        Lib_IntVector_Intrinsics_vec128_shift_left64(f3, (uint32_t)14U)),
      Lib_IntVector_Intrinsics_vec128_shift_left64(f4, (uint32_t)40U));
  Lib_IntVector_Intrinsics_vec128 f10 = lo;
  Lib_IntVector_Intrinsics_vec128 f11 = hi;
  uint64_t u0 = load64_le(ks);
  uint64_t lo0 = u0;
  uint64_t u = load64_le(ks + (uint32_t)8U);
  uint64_t hi0 = u;
  Lib_IntVector_Intrinsics_vec128 f0 = Lib_IntVector_Intrinsics_vec128_load64(lo0);
  Lib_IntVector_Intrinsics_vec128 f1 = Lib_IntVector_Intrinsics_vec128_load64(hi0);
  Lib_IntVector_Intrinsics_vec128 f20 = f0;
  Lib_IntVector_Intrinsics_vec128 f21 = f1;
  Lib_IntVector_Intrinsics_vec128 r0 = Lib_IntVector_Intrinsics_vec128_add64(f10, f20);
  Lib_IntVector_Intrinsics_vec128 r1 = Lib_IntVector_Intrinsics_vec128_add64(f11, f21);
  Lib_IntVector_Intrinsics_vec128
  c =
    Lib_IntVector_Intrinsics_vec128_shift_right64(Lib_IntVector_Intrinsics_vec128_xor(r0,
        Lib_IntVector_Intrinsics_vec128_or(Lib_IntVector_Intrinsics_vec128_xor(r0, f20),
          Lib_IntVector_Intrinsics_vec128_xor(Lib_IntVector_Intrinsics_vec128_sub64(r0, f20), f20))),
      (uint32_t)63U);
  Lib_IntVector_Intrinsics_vec128 r11 = Lib_IntVector_Intrinsics_vec128_add64(r1, c);
  Lib_IntVector_Intrinsics_vec128 f30 = r0;
  Lib_IntVector_Intrinsics_vec128 f31 = r11;
  Lib_IntVector_Intrinsics_vec128
  r00 = Lib_IntVector_Intrinsics_vec128_interleave_low64(f30, f31);
  Lib_IntVector_Intrinsics_vec128_store_le(tag, r00);
}

inline static void
Hacl_Impl_Poly1305_poly1305_finish_256(
  uint8_t *tag,
  uint8_t *key,
  Lib_IntVector_Intrinsics_vec256 *ctx
)
{
  Lib_IntVector_Intrinsics_vec256 *acc = ctx;
  uint8_t *ks = key + (uint32_t)16U;
  Lib_IntVector_Intrinsics_vec256 f00 = acc[0U];
  Lib_IntVector_Intrinsics_vec256 f12 = acc[1U];
  Lib_IntVector_Intrinsics_vec256 f22 = acc[2U];
  Lib_IntVector_Intrinsics_vec256 f32 = acc[3U];
  Lib_IntVector_Intrinsics_vec256 f40 = acc[4U];
  Lib_IntVector_Intrinsics_vec256
  l = Lib_IntVector_Intrinsics_vec256_add64(f00, Lib_IntVector_Intrinsics_vec256_zero);
  Lib_IntVector_Intrinsics_vec256
  tmp0 =
    Lib_IntVector_Intrinsics_vec256_and(l,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c0 = Lib_IntVector_Intrinsics_vec256_shift_right64(l, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l0 = Lib_IntVector_Intrinsics_vec256_add64(f12, c0);
  Lib_IntVector_Intrinsics_vec256
  tmp1 =
    Lib_IntVector_Intrinsics_vec256_and(l0,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c1 = Lib_IntVector_Intrinsics_vec256_shift_right64(l0, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l1 = Lib_IntVector_Intrinsics_vec256_add64(f22, c1);
  Lib_IntVector_Intrinsics_vec256
  tmp2 =
    Lib_IntVector_Intrinsics_vec256_and(l1,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c2 = Lib_IntVector_Intrinsics_vec256_shift_right64(l1, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l2 = Lib_IntVector_Intrinsics_vec256_add64(f32, c2);
  Lib_IntVector_Intrinsics_vec256
  tmp3 =
    Lib_IntVector_Intrinsics_vec256_and(l2,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c3 = Lib_IntVector_Intrinsics_vec256_shift_right64(l2, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 l3 = Lib_IntVector_Intrinsics_vec256_add64(f40, c3);
  Lib_IntVector_Intrinsics_vec256
  tmp4 =
    Lib_IntVector_Intrinsics_vec256_and(l3,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c4 = Lib_IntVector_Intrinsics_vec256_shift_right64(l3, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256
  l4 =
    Lib_IntVector_Intrinsics_vec256_add64(tmp0,
      Lib_IntVector_Intrinsics_vec256_smul64(c4, (uint64_t)5U));
  Lib_IntVector_Intrinsics_vec256
  tmp0_ =
    Lib_IntVector_Intrinsics_vec256_and(l4,
      Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU));
  Lib_IntVector_Intrinsics_vec256
  c5 = Lib_IntVector_Intrinsics_vec256_shift_right64(l4, (uint32_t)26U);
  Lib_IntVector_Intrinsics_vec256 f010 = tmp0_;
  Lib_IntVector_Intrinsics_vec256 f110 = Lib_IntVector_Intrinsics_vec256_add64(tmp1, c5);
  Lib_IntVector_Intrinsics_vec256 f210 = tmp2;
  Lib_IntVector_Intrinsics_vec256 f310 = tmp3;
  Lib_IntVector_Intrinsics_vec256 f410 = tmp4;
  Lib_IntVector_Intrinsics_vec256
  mh = Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3ffffffU);
  Lib_IntVector_Intrinsics_vec256
  ml = Lib_IntVector_Intrinsics_vec256_load64((uint64_t)0x3fffffbU);
  Lib_IntVector_Intrinsics_vec256 mask = Lib_IntVector_Intrinsics_vec256_eq64(f410, mh);
  Lib_IntVector_Intrinsics_vec256
  mask1 =
    Lib_IntVector_Intrinsics_vec256_and(mask,
      Lib_IntVector_Intrinsics_vec256_eq64(f310, mh));
  Lib_IntVector_Intrinsics_vec256
  mask2 =
    Lib_IntVector_Intrinsics_vec256_and(mask1,
      Lib_IntVector_Intrinsics_vec256_eq64(f210, mh));
  Lib_IntVector_Intrinsics_vec256
  mask3 =
    Lib_IntVector_Intrinsics_vec256_and(mask2,
      Lib_IntVector_Intrinsics_vec256_eq64(f110, mh));
  Lib_IntVector_Intrinsics_vec256
  mask4 =
    Lib_IntVector_Intrinsics_vec256_and(mask3,
      Lib_IntVector_Intrinsics_vec256_lognot(Lib_IntVector_Intrinsics_vec256_gt64(ml, f010)));
  Lib_IntVector_Intrinsics_vec256 ph = Lib_IntVector_Intrinsics_vec256_and(mask4, mh);
  Lib_IntVector_Intrinsics_vec256 pl = Lib_IntVector_Intrinsics_vec256_and(mask4, ml);
  Lib_IntVector_Intrinsics_vec256 o0 = Lib_IntVector_Intrinsics_vec256_sub64(f010, pl);
  Lib_IntVector_Intrinsics_vec256 o1 = Lib_IntVector_Intrinsics_vec256_sub64(f110, ph);
  Lib_IntVector_Intrinsics_vec256 o2 = Lib_IntVector_Intrinsics_vec256_sub64(f210, ph);
  Lib_IntVector_Intrinsics_vec256 o3 = Lib_IntVector_Intrinsics_vec256_sub64(f310, ph);
  Lib_IntVector_Intrinsics_vec256 o4 = Lib_IntVector_Intrinsics_vec256_sub64(f410, ph);
  Lib_IntVector_Intrinsics_vec256 f01 = o0;
  Lib_IntVector_Intrinsics_vec256 f111 = o1;
  Lib_IntVector_Intrinsics_vec256 f211 = o2;
  Lib_IntVector_Intrinsics_vec256 f311 = o3;
  Lib_IntVector_Intrinsics_vec256 f41 = o4;
  acc[0U] = f01;
  acc[1U] = f111;
  acc[2U] = f211;
  acc[3U] = f311;
  acc[4U] = f41;
  Lib_IntVector_Intrinsics_vec256 f02 = acc[0U];
  Lib_IntVector_Intrinsics_vec256 f13 = acc[1U];
  Lib_IntVector_Intrinsics_vec256 f2 = acc[2U];
  Lib_IntVector_Intrinsics_vec256 f3 = acc[3U];
  Lib_IntVector_Intrinsics_vec256 f4 = acc[4U];
  Lib_IntVector_Intrinsics_vec256
  lo0 =
    Lib_IntVector_Intrinsics_vec256_or(Lib_IntVector_Intrinsics_vec256_or(f02,
        Lib_IntVector_Intrinsics_vec256_shift_left64(f13, (uint32_t)26U)),
      Lib_IntVector_Intrinsics_vec256_shift_left64(f2, (uint32_t)52U));
  Lib_IntVector_Intrinsics_vec256
  hi0 =
    Lib_IntVector_Intrinsics_vec256_or(Lib_IntVector_Intrinsics_vec256_or(Lib_IntVector_Intrinsics_vec256_shift_right64(f2,
          (uint32_t)12U),
        Lib_IntVector_Intrinsics_vec256_shift_left64(f3, (uint32_t)14U)),
      Lib_IntVector_Intrinsics_vec256_shift_left64(f4, (uint32_t)40U));
  Lib_IntVector_Intrinsics_vec256 f10 = lo0;
  Lib_IntVector_Intrinsics_vec256 f11 = hi0;
  uint64_t u0 = load64_le(ks);
  uint64_t lo2 = u0;
  uint64_t u = load64_le(ks + (uint32_t)8U);
  uint64_t hi2 = u;
  Lib_IntVector_Intrinsics_vec256 f0 = Lib_IntVector_Intrinsics_vec256_load64(lo2);
  Lib_IntVector_Intrinsics_vec256 f1 = Lib_IntVector_Intrinsics_vec256_load64(hi2);
  Lib_IntVector_Intrinsics_vec256 f20 = f0;
  Lib_IntVector_Intrinsics_vec256 f21 = f1;
  Lib_IntVector_Intrinsics_vec256 r0 = Lib_IntVector_Intrinsics_vec256_add64(f10, f20);
  Lib_IntVector_Intrinsics_vec256 r1 = Lib_IntVector_Intrinsics_vec256_add64(f11, f21);
  Lib_IntVector_Intrinsics_vec256
  c =
    Lib_IntVector_Intrinsics_vec256_shift_right64(Lib_IntVector_Intrinsics_vec256_xor(r0,
        Lib_IntVector_Intrinsics_vec256_or(Lib_IntVector_Intrinsics_vec256_xor(r0, f20),
          Lib_IntVector_Intrinsics_vec256_xor(Lib_IntVector_Intrinsics_vec256_sub64(r0, f20), f20))),
      (uint32_t)63U);
  Lib_IntVector_Intrinsics_vec256 r11 = Lib_IntVector_Intrinsics_vec256_add64(r1, c);
  Lib_IntVector_Intrinsics_vec256 f30 = r0;
  Lib_IntVector_Intrinsics_vec256 f31 = r11;
  Lib_IntVector_Intrinsics_vec256
  lo = Lib_IntVector_Intrinsics_vec256_interleave_low64(f30, f31);
  Lib_IntVector_Intrinsics_vec256
  hi = Lib_IntVector_Intrinsics_vec256_interleave_high64(f30, f31);
  Lib_IntVector_Intrinsics_vec256 lo1 = lo;
  Lib_IntVector_Intrinsics_vec256 hi1 = hi;
  Lib_IntVector_Intrinsics_vec256
  r00 = Lib_IntVector_Intrinsics_vec256_interleave_low128(lo1, hi1);
  uint8_t tmp[32U] = { 0U };
  Lib_IntVector_Intrinsics_vec256_store_le(tmp, r00);
  memcpy(tag, tmp, (uint32_t)16U * sizeof tmp[0U]);
}

uint32_t Hacl_Poly1305_32_blocklen = (uint32_t)16U;

void Hacl_Poly1305_32_poly1305_init(uint64_t *ctx, uint8_t *key)
{
  Hacl_Impl_Poly1305_poly1305_init_32(ctx, key);
}

void Hacl_Poly1305_32_poly1305_update_blocks(uint64_t *ctx, uint32_t len1, uint8_t *text)
{
  Hacl_Impl_Poly1305_poly1305_update_32(ctx, len1, text);
}

void Hacl_Poly1305_32_poly1305_update_padded(uint64_t *ctx, uint32_t len1, uint8_t *text)
{
  Hacl_Impl_Poly1305_poly1305_update_32(ctx, len1, text);
}

void Hacl_Poly1305_32_poly1305_update_last(uint64_t *ctx, uint32_t len1, uint8_t *text)
{
  Hacl_Impl_Poly1305_poly1305_update_32(ctx, len1, text);
}

void Hacl_Poly1305_32_poly1305_finish(uint8_t *tag, uint8_t *k, uint64_t *ctx)
{
  Hacl_Impl_Poly1305_poly1305_finish_32(tag, k, ctx);
}

void Hacl_Poly1305_32_poly1305_mac(uint8_t *o, uint8_t *t, uint32_t l, uint8_t *k)
{
  KRML_CHECK_SIZE(sizeof (uint64_t), (uint32_t)5U + (uint32_t)20U);
  uint64_t ctx[(uint32_t)5U + (uint32_t)20U];
  memset(ctx, 0U, ((uint32_t)5U + (uint32_t)20U) * sizeof ctx[0U]);
  Hacl_Impl_Poly1305_poly1305_init_32(ctx, k);
  Hacl_Impl_Poly1305_poly1305_update_32(ctx, l, t);
  Hacl_Impl_Poly1305_poly1305_finish_32(o, k, ctx);
}

uint32_t Hacl_Poly1305_128_blocklen = (uint32_t)16U;

void Hacl_Poly1305_128_poly1305_init(Lib_IntVector_Intrinsics_vec128 *ctx, uint8_t *key)
{
  Hacl_Impl_Poly1305_poly1305_init_128(ctx, key);
}

void
Hacl_Poly1305_128_poly1305_update_blocks(
  Lib_IntVector_Intrinsics_vec128 *ctx,
  uint32_t len1,
  uint8_t *text
)
{
  Hacl_Impl_Poly1305_poly1305_update_128(ctx, len1, text);
}

void
Hacl_Poly1305_128_poly1305_update_padded(
  Lib_IntVector_Intrinsics_vec128 *ctx,
  uint32_t len1,
  uint8_t *text
)
{
  Hacl_Impl_Poly1305_poly1305_update_128(ctx, len1, text);
}

void
Hacl_Poly1305_128_poly1305_update_last(
  Lib_IntVector_Intrinsics_vec128 *ctx,
  uint32_t len1,
  uint8_t *text
)
{
  Hacl_Impl_Poly1305_poly1305_update_128(ctx, len1, text);
}

void
Hacl_Poly1305_128_poly1305_finish(
  uint8_t *tag,
  uint8_t *k,
  Lib_IntVector_Intrinsics_vec128 *ctx
)
{
  Hacl_Impl_Poly1305_poly1305_finish_128(tag, k, ctx);
}

void Hacl_Poly1305_128_poly1305_mac(uint8_t *o, uint8_t *t, uint32_t l, uint8_t *k)
{
  KRML_CHECK_SIZE(sizeof (Lib_IntVector_Intrinsics_vec128), (uint32_t)5U + (uint32_t)20U);
  Lib_IntVector_Intrinsics_vec128 ctx[(uint32_t)5U + (uint32_t)20U];
  for (uint32_t _i = 0U; _i < (uint32_t)5U + (uint32_t)20U; ++_i)
    ctx[_i] = Lib_IntVector_Intrinsics_vec128_zero;
  Hacl_Impl_Poly1305_poly1305_init_128(ctx, k);
  Hacl_Impl_Poly1305_poly1305_update_128(ctx, l, t);
  Hacl_Impl_Poly1305_poly1305_finish_128(o, k, ctx);
}

uint32_t Hacl_Poly1305_256_blocklen = (uint32_t)16U;

void Hacl_Poly1305_256_poly1305_init(Lib_IntVector_Intrinsics_vec256 *ctx, uint8_t *key)
{
  Hacl_Impl_Poly1305_poly1305_init_256(ctx, key);
}

void
Hacl_Poly1305_256_poly1305_update_blocks(
  Lib_IntVector_Intrinsics_vec256 *ctx,
  uint32_t len1,
  uint8_t *text
)
{
  Hacl_Impl_Poly1305_poly1305_update_256(ctx, len1, text);
}

void
Hacl_Poly1305_256_poly1305_update_padded(
  Lib_IntVector_Intrinsics_vec256 *ctx,
  uint32_t len1,
  uint8_t *text
)
{
  Hacl_Impl_Poly1305_poly1305_update_256(ctx, len1, text);
}

void
Hacl_Poly1305_256_poly1305_update_last(
  Lib_IntVector_Intrinsics_vec256 *ctx,
  uint32_t len1,
  uint8_t *text
)
{
  Hacl_Impl_Poly1305_poly1305_update_256(ctx, len1, text);
}

void
Hacl_Poly1305_256_poly1305_finish(
  uint8_t *tag,
  uint8_t *k,
  Lib_IntVector_Intrinsics_vec256 *ctx
)
{
  Hacl_Impl_Poly1305_poly1305_finish_256(tag, k, ctx);
}

void Hacl_Poly1305_256_poly1305_mac(uint8_t *o, uint8_t *t, uint32_t l, uint8_t *k)
{
  KRML_CHECK_SIZE(sizeof (Lib_IntVector_Intrinsics_vec256), (uint32_t)5U + (uint32_t)20U);
  Lib_IntVector_Intrinsics_vec256 ctx[(uint32_t)5U + (uint32_t)20U];
  for (uint32_t _i = 0U; _i < (uint32_t)5U + (uint32_t)20U; ++_i)
    ctx[_i] = Lib_IntVector_Intrinsics_vec256_zero;
  Hacl_Impl_Poly1305_poly1305_init_256(ctx, k);
  Hacl_Impl_Poly1305_poly1305_update_256(ctx, l, t);
  Hacl_Impl_Poly1305_poly1305_finish_256(o, k, ctx);
}

