/* 
  This file was generated by KreMLin <https://github.com/FStarLang/kremlin>
  KreMLin invocation: /home/jonathan/Code/kremlin/krml -bundle Hacl.Spec.*,Spec.*[rename=Hacl_Spec] -bundle Hacl.Poly1305.Field32xN.Lemmas[rename=Hacl_Lemmas] -bundle Lib.*[rename=Hacl_Lib] -drop Lib.IntVector.Intrinsics -add-include "libintvector.h" -add-include "evercrypt_targetconfig.h" -drop EverCrypt.TargetConfig -bundle Test,Test.*,Hacl.Test.* -bundle EverCrypt.BCrypt -bundle EverCrypt.OpenSSL -bundle MerkleTree.Spec,MerkleTree.Spec.*,MerkleTree.New.High,MerkleTree.New.High.* -bundle Vale.Stdcalls.*,Interop,Interop.*,Fadd_stdcalls,Cpuid_stdcalls,Fswap_stdcalls,Fmul_stdcalls,Fsqr_stdcalls,Fsub_stdcalls,Poly_stdcalls,Sha_stdcalls,GCMencrypt_stdcalls,GCMencryptOpt_stdcalls,AES_stdcalls,AEShash_stdcalls,GCMencryptOpt256_stdcalls,GCMdecrypt_stdcalls[rename=Vale] -bundle Fadd_inline,Fmul_inline,Fsqr_inline,Fswap_inline[rename=Vale_Inline] -bundle FStar.Tactics.CanonCommMonoid,FStar.Tactics.CanonCommSemiring,FStar.Tactics.CanonCommSwaps[rename=Unused] -bundle FastUtil_helpers,FastHybrid_helpers,FastSqr_helpers,FastMul_helpers[rename=Unused2] -bundle Opaque_s,Map16,Test.Vale_memcpy,Fast_defs,Interop_Printer,Memcpy[rename=Unused3] -bundle X64.*,Arch.*,Words.*,Vale.*,Collections.*,Collections,SHA_helpers[rename=Unused4] -bundle Prop_s,Types_s,Words_s,Views,AES_s,Workarounds,Math.*,Interop,TypesNative_s[rename=Unused5] -bundle GF128_s,GF128,Poly1305.*,GCTR,GCTR_s,GHash_s,GCM_helpers,GHash[rename=Unused6] -bundle AES_helpers,AES256_helpers,GCM_s,GCM,Interop_assumptions[rename=Unused7] -library Vale.Stdcalls.* -static-header Vale_Inline -library Fadd_inline -library Fmul_inline -library Fswap_inline -library Fsqr_inline -no-prefix Vale.Stdcalls.* -no-prefix Fadd_inline -no-prefix Fmul_inline -no-prefix Fswap_inline -no-prefix Fsqr_inline -no-prefix EverCrypt.Vale -add-include "curve25519-inline.h" -no-prefix MerkleTree.New.Low -no-prefix MerkleTree.New.Low.Serialization -fparentheses -fno-shadow -fcurly-braces -bundle EverCrypt -bundle Hacl.Hash.MD5+Hacl.Hash.Core.MD5+Hacl.Hash.SHA1+Hacl.Hash.Core.SHA1+Hacl.Hash.SHA2+Hacl.Hash.Core.SHA2+Hacl.Hash.Core.SHA2.Constants=Hacl.Hash.*[rename=Hacl_Hash] -bundle Hacl.Impl.SHA3+Hacl.SHA3=[rename=Hacl_SHA3] -bundle Hacl.Poly1305_32+Hacl.Poly1305_128+Hacl.Poly1305_256=Hacl.Poly1305.*,Hacl.Impl.Poly1305,Hacl.Impl.Poly1305.*[rename=Hacl_Poly1305] -bundle Hacl.Impl.Chacha20=Hacl.Impl.Chacha20.*[rename=Hacl_Chacha20] -bundle Hacl.Curve25519_51+Hacl.Curve25519_64=Hacl.Impl.Curve25519.*[rename=Hacl_Curve25519] -bundle Hacl.Impl.Chacha20Poly1305=Hacl.Impl.Chacha20Poly1305.*[rename=Hacl_Chacha20Poly1305] -bundle LowStar.* -bundle Prims,C.Failure,C,C.String,C.Loops,Spec.Loops,C.Endianness,FStar.*[rename=Hacl_Kremlib] -bundle EverCrypt.Spec.* -bundle MerkleTree.* -bundle Test,Test.*,WindowsHack -bundle EverCrypt.Hash+EverCrypt.Hash.Incremental=[rename=EverCrypt_Hash] -library EverCrypt.AutoConfig,EverCrypt.OpenSSL,EverCrypt.BCrypt -minimal -add-include "kremlin/internal/types.h" -add-include "kremlin/internal/target.h" -add-include "kremlin/lowstar_endianness.h" -add-include <string.h> -fc89 -ccopt -std=c89 -ccopt -Wno-typedef-redefinition -tmpdir dist/compact-c89/ -skip-compilation obj/prims.krml obj/FStar_Pervasives_Native.krml obj/FStar_Pervasives.krml obj/Prop_s.krml obj/FStar_Exn.krml obj/FStar_Squash.krml obj/FStar_Classical.krml obj/FStar_FunctionalExtensionality.krml obj/FStar_Set.krml obj/FStar_Preorder.krml obj/FStar_Monotonic_Witnessed.krml obj/FStar_Ghost.krml obj/FStar_ErasedLogic.krml obj/FStar_StrongExcludedMiddle.krml obj/FStar_PropositionalExtensionality.krml obj/FStar_PredicateExtensionality.krml obj/FStar_TSet.krml obj/FStar_Monotonic_Heap.krml obj/FStar_Heap.krml obj/FStar_ST.krml obj/FStar_All.krml obj/FStar_Map.krml obj/FStar_List_Tot_Base.krml obj/FStar_List_Tot_Properties.krml obj/FStar_List_Tot.krml obj/FStar_Seq_Base.krml obj/FStar_Mul.krml obj/FStar_Calc.krml obj/FStar_Seq_Properties.krml obj/FStar_Seq.krml obj/FStar_Math_Lib.krml obj/FStar_Math_Lemmas.krml obj/FStar_BitVector.krml obj/FStar_UInt.krml obj/FStar_UInt32.krml obj/FStar_UInt8.krml obj/FStar_Monotonic_HyperHeap.krml obj/FStar_Monotonic_HyperStack.krml obj/FStar_HyperStack.krml obj/FStar_HyperStack_ST.krml obj/FStar_Universe.krml obj/FStar_GSet.krml obj/FStar_ModifiesGen.krml obj/FStar_Range.krml obj/FStar_Reflection_Types.krml obj/FStar_Tactics_Types.krml obj/FStar_Tactics_Result.krml obj/FStar_Tactics_Effect.krml obj/FStar_Tactics_Util.krml obj/FStar_Reflection_Data.krml obj/FStar_Reflection_Const.krml obj/FStar_Char.krml obj/FStar_List.krml obj/FStar_String.krml obj/FStar_Order.krml obj/FStar_Reflection_Basic.krml obj/FStar_Reflection_Derived.krml obj/FStar_Tactics_Builtins.krml obj/FStar_Reflection_Formula.krml obj/FStar_Reflection_Derived_Lemmas.krml obj/FStar_Reflection.krml obj/FStar_Tactics_Derived.krml obj/FStar_Tactics_Logic.krml obj/FStar_Tactics.krml obj/FStar_BigOps.krml obj/LowStar_Monotonic_Buffer.krml obj/LowStar_Buffer.krml obj/LowStar_Modifies.krml obj/LowStar_ModifiesPat.krml obj/LowStar_BufferView_Down.krml obj/LowStar_BufferView_Up.krml obj/LowStar_BufferView.krml obj/BufferViewHelpers.krml obj/FStar_UInt64.krml obj/FStar_UInt16.krml obj/Words_s.krml obj/Collections_Seqs_s.krml obj/Words_Four_s.krml obj/Words_Two_s.krml obj/Words_Seq_s.krml obj/Opaque_s.krml obj/Types_s.krml obj/X64_Machine_s.krml obj/AES_s.krml obj/Math_Poly2_Defs_s.krml obj/Math_Poly2_s.krml obj/Math_Poly2_Bits_s.krml obj/Vale_Set.krml obj/FStar_HyperStack_All.krml obj/FStar_Kremlin_Endianness.krml obj/FStar_Int.krml obj/FStar_Int64.krml obj/FStar_Int63.krml obj/FStar_Int32.krml obj/FStar_Int16.krml obj/FStar_Int8.krml obj/FStar_UInt63.krml obj/FStar_Int_Cast.krml obj/FStar_UInt128.krml obj/Spec_Hash_Definitions.krml obj/Spec_Hash_Lemmas0.krml obj/Spec_Hash_PadFinish.krml obj/Spec_Loops.krml obj/Spec_SHA2_Constants.krml obj/Spec_SHA2.krml obj/X64_CryptoInstructions_s.krml obj/X64_CPU_Features_s.krml obj/X64_Bytes_Semantics_s.krml obj/FStar_Float.krml obj/FStar_BaseTypes.krml obj/X64_Taint_Semantics_s.krml obj/LowStar_ImmutableBuffer.krml obj/Util_Meta.krml obj/Words_Two.krml obj/Collections_Seqs.krml obj/TypesNative_s.krml obj/Arch_TypesNative.krml obj/Words_Seq.krml obj/Arch_Types.krml obj/Views.krml obj/Interop_Types.krml obj/Interop_Base.krml obj/X64_Bytes_Semantics.krml obj/Interop.krml obj/Fast_lemmas_internal.krml obj/Fast_defs.krml obj/FStar_Tactics_CanonCommSwaps.krml obj/FStar_Algebra_CommMonoid.krml obj/FStar_Tactics_CanonCommMonoid.krml obj/FStar_Tactics_CanonCommSemiring.krml obj/FastUtil_helpers.krml obj/FastHybrid_helpers.krml obj/Fast_lemmas_external.krml obj/Map16.krml obj/X64_Vale_Xmms.krml obj/X64_Vale_Regs.krml obj/FStar_IO.krml obj/X64_Stack_i.krml obj/X64_Stack_Sems.krml obj/X64_Memory.krml obj/X64_BufferViewStore.krml obj/X64_Memory_Sems.krml obj/X64_Vale_State.krml obj/X64_Vale_StateLemmas.krml obj/X64_Vale_Lemmas.krml obj/X64_Print_s.krml obj/X64_Vale_Decls.krml obj/X64_Vale_QuickCode.krml obj/X64_Vale_QuickCodes.krml obj/X64_Taint_Semantics.krml obj/X64_Vale_InsLemmas.krml obj/X64_Vale_InsBasic.krml obj/X64_Vale_InsMem.krml obj/X64_Vale_InsVector.krml obj/X64_Vale_InsStack.krml obj/X64_FastHybrid.krml obj/FastSqr_helpers.krml obj/X64_FastSqr.krml obj/FastMul_helpers.krml obj/X64_FastMul.krml obj/X64_FastWide.krml obj/X64_FastUtil.krml obj/Interop_Assumptions.krml obj/Interop_X64.krml obj/X64_Print_Inline_s.krml obj/X64_MemoryAdapters.krml obj/Vale_AsLowStar_ValeSig.krml obj/Vale_AsLowStar_LowStarSig.krml obj/Vale_AsLowStar_MemoryHelpers.krml obj/Vale_AsLowStar_Wrapper.krml obj/Vale_Stdcalls_Fadd.krml obj/Fadd_stdcalls.krml obj/Fsqr_inline.krml obj/X64_Stack.krml obj/X64_Vale_InsAes.krml obj/Math_Poly2_Defs.krml obj/Math_Poly2.krml obj/Math_Poly2_Lemmas.krml obj/Math_Poly2_Bits.krml obj/Math_Poly2_Words.krml obj/GF128_s.krml obj/GF128.krml obj/X64_GF128_Mul.krml obj/FStar_BV.krml obj/FStar_Reflection_Arith.krml obj/FStar_Tactics_BV.krml obj/Vale_Bv_s.krml obj/Math_Bits.krml obj/Vale_Tactics.krml obj/X64_Poly1305_Bitvectors.krml obj/Math_Lemmas_Int.krml obj/FStar_Tactics_Canon.krml obj/Poly1305_Spec_s.krml obj/X64_Poly1305_Math.krml obj/Workarounds.krml obj/GCTR_s.krml obj/GCM_helpers.krml obj/GHash_s.krml obj/OptPublic.krml obj/GHash.krml obj/X64_GHash.krml obj/GCTR.krml obj/AES_helpers.krml obj/X64_AESCTR.krml obj/X64_AESCTRplain.krml obj/AES256_helpers.krml obj/X64_AES256.krml obj/X64_AES128.krml obj/X64_AES.krml obj/X64_GCTR.krml obj/GCM_s.krml obj/GCM.krml obj/X64_GCMencrypt.krml obj/Test_Vale_memcpy.krml obj/Lib_LoopCombinators.krml obj/FStar_Int_Cast_Full.krml obj/Lib_IntTypes.krml obj/Lib_Sequence.krml obj/Spec_SHA3_Constants.krml obj/Spec_SHA1.krml obj/Spec_MD5.krml obj/Spec_Hash.krml obj/Spec_Hash_Incremental.krml obj/Spec_Hash_Lemmas.krml obj/LowStar_BufferOps.krml obj/C_Loops.krml obj/C_Endianness.krml obj/Hacl_Hash_Lemmas.krml obj/Hacl_Hash_Definitions.krml obj/Hacl_Hash_PadFinish.krml obj/Hacl_Hash_MD.krml obj/SHA_helpers.krml obj/X64_Vale_InsSha.krml obj/X64_SHA.krml obj/Vale_Stdcalls_Sha.krml obj/Simplify_Sha.krml obj/Sha_stdcalls.krml obj/Hacl_Hash_Core_SHA2_Constants.krml obj/Hacl_Hash_Core_SHA2.krml obj/Hacl_Hash_SHA2.krml obj/Hacl_Hash_Core_SHA1.krml obj/Hacl_Hash_SHA1.krml obj/Hacl_Hash_Core_MD5.krml obj/Hacl_Hash_MD5.krml obj/C.krml obj/C_String.krml obj/C_Failure.krml obj/FStar_Int128.krml obj/FStar_Int31.krml obj/FStar_UInt31.krml obj/FStar_Integers.krml obj/EverCrypt_StaticConfig.krml obj/X64_Cpuid.krml obj/X64_Cpuidstdcall.krml obj/Vale_Stdcalls_Cpuid.krml obj/Cpuid_stdcalls.krml obj/EverCrypt_TargetConfig.krml obj/EverCrypt_AutoConfig2.krml obj/EverCrypt_Helpers.krml obj/EverCrypt_Hash.krml obj/Lib_RawIntTypes.krml obj/Lib_Loops.krml obj/Lib_ByteSequence.krml obj/Hacl_Impl_Curve25519_Lemmas.krml obj/Spec_Curve25519_Lemmas.krml obj/Spec_Curve25519.krml obj/Hacl_Spec_Curve25519_Field51_Definition.krml obj/Hacl_Spec_Curve25519_Field51_Lemmas.krml obj/Hacl_Spec_Curve25519_Field51.krml obj/Lib_Buffer.krml obj/Hacl_Impl_Curve25519_Field51.krml obj/LowStar_Vector.krml obj/LowStar_Regional.krml obj/LowStar_RVector.krml obj/Hacl_Spec_Curve25519_AddAndDouble.krml obj/Hacl_Spec_Curve25519_Field64_Definition.krml obj/Hacl_Spec_Curve25519_Field64_Lemmas.krml obj/Hacl_Spec_Curve25519_Field64_Core.krml obj/Hacl_Spec_Curve25519_Field64.krml obj/Vale_Stdcalls_Fswap.krml obj/Fswap_stdcalls.krml obj/Fswap_inline.krml obj/Vale_Stdcalls_Fsqr.krml obj/Fsqr_stdcalls.krml obj/Vale_Stdcalls_Fmul.krml obj/Fmul_stdcalls.krml obj/Fmul_inline.krml obj/Vale_Stdcalls_Fsub.krml obj/Fsub_stdcalls.krml obj/Fadd_inline.krml obj/Hacl_Impl_Curve25519_Field64_Core.krml obj/Hacl_Impl_Curve25519_Field64.krml obj/Hacl_Impl_Curve25519_Fields.krml obj/Lib_ByteBuffer.krml obj/Hacl_Impl_Curve25519_AddAndDouble.krml obj/Lib_IntVector_Intrinsics.krml obj/Lib_IntVector.krml obj/X64_PolyOps.krml obj/Vale_Stdcalls_Aes.krml obj/Spec_Chacha20.krml obj/Hacl_Impl_Chacha20_Core32.krml obj/Hacl_Impl_Chacha20.krml obj/Spec_Poly1305.krml obj/Hacl_Spec_Poly1305_Vec.krml obj/Lib_Unlib.krml obj/X64_Poly1305_Util.krml obj/X64_Poly1305.krml obj/Vale_Stdcalls_Poly.krml obj/Poly_stdcalls.krml obj/FStar_Endianness.krml obj/Arch_BufferFriend.krml obj/Hacl_Impl_Poly1305_Lemmas.krml obj/Hacl_Spec_Poly1305_Field32xN.krml obj/Hacl_Poly1305_Field32xN_Lemmas.krml obj/Hacl_Spec_Poly1305_Field32xN_Lemmas.krml obj/Hacl_Impl_Poly1305_Field32xN.krml obj/Hacl_Impl_Poly1305_Fields.krml obj/Hacl_Spec_Poly1305_Equiv.krml obj/Hacl_Impl_Poly1305.krml obj/Spec_Chacha20Poly1305.krml obj/Hacl_Impl_Chacha20Poly1305_PolyCore.krml obj/Hacl_Impl_Chacha20Poly1305_Poly.krml obj/Hacl_Impl_Chacha20Poly1305.krml obj/FStar_Dyn.krml obj/EverCrypt_Vale.krml obj/EverCrypt_Specs.krml obj/EverCrypt_OpenSSL.krml obj/EverCrypt_Hacl.krml obj/EverCrypt_BCrypt.krml obj/EverCrypt_Cipher.krml obj/Hacl_Spec_Curve25519_Finv.krml obj/Hacl_Impl_Curve25519_Finv.krml obj/Hacl_Impl_Curve25519_Generic.krml obj/Hacl_Curve25519_51.krml obj/Hacl_Curve25519_64.krml obj/EverCrypt_Curve25519.krml obj/Hacl_Poly1305_32.krml obj/Poly1305_Equiv.krml obj/X64_Poly1305_CallingFromLowStar.krml obj/Hacl_Poly1305_128.krml obj/Hacl_Poly1305_256.krml obj/EverCrypt_Poly1305.krml obj/EverCrypt_HMAC.krml obj/EverCrypt_HKDF.krml obj/EverCrypt.krml obj/MerkleTree_Spec.krml obj/Gcm_simplify.krml obj/Vale_Stdcalls_GCMencrypt.krml obj/GCMencrypt_stdcalls.krml obj/MerkleTree_New_High.krml obj/LowStar_Regional_Instances.krml obj/MerkleTree_New_Low.krml obj/MerkleTree_New_Low_Serialization.krml obj/X64_Leakage_s.krml obj/X64_Leakage_Helpers.krml obj/X64_GCMdecrypt.krml obj/Vale_Stdcalls_GCMdecrypt.krml obj/GCMdecrypt_stdcalls.krml obj/X64_AESopt2.krml obj/X64_AESGCM.krml obj/X64_GCMencryptOpt.krml obj/Vale_Stdcalls_GCMencryptOpt.krml obj/GCMencryptOpt256_stdcalls.krml obj/GCMencryptOpt_stdcalls.krml obj/X64_GF128_Init.krml obj/Vale_Stdcalls_AesHash.krml obj/AEShash_stdcalls.krml obj/AES_stdcalls.krml obj/Spec_AEAD.krml obj/EverCrypt_AEAD.krml obj/MerkleTree_New_High_Correct_Base.krml obj/MerkleTree_New_High_Correct_Rhs.krml obj/MerkleTree_New_High_Correct_Path.krml obj/MerkleTree_New_High_Correct_Flushing.krml obj/MerkleTree_New_High_Correct_Insertion.krml obj/MerkleTree_New_High_Correct.krml obj/EverCrypt_Hash_Incremental.krml obj/Test_Hash.krml obj/Operator.krml obj/Spec_SHA3.krml obj/Hacl_Impl_SHA3.krml obj/TestLib.krml obj/EverCrypt_Chacha20Poly1305.krml obj/Hacl_SHA3.krml obj/Lib_PrintBuffer.krml obj/Hacl_Test_CSHAKE.krml obj/Spec_Hash_Test.krml obj/X64_Leakage_Ins_Xmm.krml obj/X64_Leakage_Ins.krml obj/X64_Leakage.krml obj/Test_Vectors_Chacha20Poly1305.krml obj/Test_Memcpy.krml obj/Lib_RandomBuffer.krml obj/Test_Vectors_Aes128.krml obj/Collections_Lists.krml obj/Hacl_Hash_Agile.krml obj/Hacl_Test_SHA3.krml obj/Test_Vectors_Curve25519.krml obj/Spec_Chacha20Poly1305_Test.krml obj/Test_Vectors_Poly1305.krml obj/Test_Args.krml obj/Vale_AsLowStar_Test.krml obj/Spec_SHA3_Test.krml obj/Test_Lowstarize.krml obj/Test_Vectors.krml obj/Test_Vectors_Aes128Gcm.krml obj/Spec_Curve25519_Test.krml obj/Test.krml obj/Spec_Chacha20_Test.krml obj/X64_AESopt.krml -silent -ccopt -Wno-unused -warn-error @4-6 -fparentheses Hacl_AES.c Hacl_Ed25519.c Lib_RandomBuffer.c Lib_PrintBuffer.c evercrypt_vale_stubs.c -o libevercrypt.a
  F* version: 28a5baa2
  KreMLin version: f534ac02
 */

#include "EverCrypt_Hash.h"

C_String_t EverCrypt_Hash_string_of_alg(Spec_Hash_Definitions_hash_alg uu___0_6)
{
  switch (uu___0_6)
  {
    case Spec_Hash_Definitions_MD5:
      {
        return "MD5";
      }
    case Spec_Hash_Definitions_SHA1:
      {
        return "SHA1";
      }
    case Spec_Hash_Definitions_SHA2_224:
      {
        return "SHA2_224";
      }
    case Spec_Hash_Definitions_SHA2_256:
      {
        return "SHA2_256";
      }
    case Spec_Hash_Definitions_SHA2_384:
      {
        return "SHA2_384";
      }
    case Spec_Hash_Definitions_SHA2_512:
      {
        return "SHA2_512";
      }
    default:
      {
        KRML_HOST_PRINTF("KreMLin incomplete match at %s:%d\n", __FILE__, __LINE__);
        KRML_HOST_EXIT(253U);
      }
  }
}

uint32_t EverCrypt_Hash_tagLen(Spec_Hash_Definitions_hash_alg a)
{
  switch (a)
  {
    case Spec_Hash_Definitions_MD5:
      {
        return (uint32_t)16U;
      }
    case Spec_Hash_Definitions_SHA1:
      {
        return (uint32_t)20U;
      }
    case Spec_Hash_Definitions_SHA2_224:
      {
        return (uint32_t)28U;
      }
    case Spec_Hash_Definitions_SHA2_256:
      {
        return (uint32_t)32U;
      }
    case Spec_Hash_Definitions_SHA2_384:
      {
        return (uint32_t)48U;
      }
    case Spec_Hash_Definitions_SHA2_512:
      {
        return (uint32_t)64U;
      }
    default:
      {
        KRML_HOST_PRINTF("KreMLin incomplete match at %s:%d\n", __FILE__, __LINE__);
        KRML_HOST_EXIT(253U);
      }
  }
}

uint32_t EverCrypt_Hash_blockLen(Spec_Hash_Definitions_hash_alg a)
{
  switch (a)
  {
    case Spec_Hash_Definitions_MD5:
      {
        return (uint32_t)64U;
      }
    case Spec_Hash_Definitions_SHA1:
      {
        return (uint32_t)64U;
      }
    case Spec_Hash_Definitions_SHA2_224:
      {
        return (uint32_t)64U;
      }
    case Spec_Hash_Definitions_SHA2_256:
      {
        return (uint32_t)64U;
      }
    case Spec_Hash_Definitions_SHA2_384:
      {
        return (uint32_t)128U;
      }
    case Spec_Hash_Definitions_SHA2_512:
      {
        return (uint32_t)128U;
      }
    default:
      {
        KRML_HOST_PRINTF("KreMLin incomplete match at %s:%d\n", __FILE__, __LINE__);
        KRML_HOST_EXIT(253U);
      }
  }
}

bool
EverCrypt_Hash_uu___is_MD5_s(
  Spec_Hash_Definitions_hash_alg uu____259,
  EverCrypt_Hash_state_s projectee
)
{
  if (projectee.tag == EverCrypt_Hash_MD5_s)
  {
    return true;
  }
  else
  {
    return false;
  }
}

uint32_t
*EverCrypt_Hash___proj__MD5_s__item__p(
  Spec_Hash_Definitions_hash_alg uu____287,
  EverCrypt_Hash_state_s projectee
)
{
  if (projectee.tag == EverCrypt_Hash_MD5_s)
  {
    return projectee.val.case_MD5_s;
  }
  else
  {
    KRML_HOST_PRINTF("KreMLin abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
}

bool
EverCrypt_Hash_uu___is_SHA1_s(
  Spec_Hash_Definitions_hash_alg uu____310,
  EverCrypt_Hash_state_s projectee
)
{
  if (projectee.tag == EverCrypt_Hash_SHA1_s)
  {
    return true;
  }
  else
  {
    return false;
  }
}

uint32_t
*EverCrypt_Hash___proj__SHA1_s__item__p(
  Spec_Hash_Definitions_hash_alg uu____338,
  EverCrypt_Hash_state_s projectee
)
{
  if (projectee.tag == EverCrypt_Hash_SHA1_s)
  {
    return projectee.val.case_SHA1_s;
  }
  else
  {
    KRML_HOST_PRINTF("KreMLin abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
}

bool
EverCrypt_Hash_uu___is_SHA2_224_s(
  Spec_Hash_Definitions_hash_alg uu____361,
  EverCrypt_Hash_state_s projectee
)
{
  if (projectee.tag == EverCrypt_Hash_SHA2_224_s)
  {
    return true;
  }
  else
  {
    return false;
  }
}

uint32_t
*EverCrypt_Hash___proj__SHA2_224_s__item__p(
  Spec_Hash_Definitions_hash_alg uu____389,
  EverCrypt_Hash_state_s projectee
)
{
  if (projectee.tag == EverCrypt_Hash_SHA2_224_s)
  {
    return projectee.val.case_SHA2_224_s;
  }
  else
  {
    KRML_HOST_PRINTF("KreMLin abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
}

bool
EverCrypt_Hash_uu___is_SHA2_256_s(
  Spec_Hash_Definitions_hash_alg uu____412,
  EverCrypt_Hash_state_s projectee
)
{
  if (projectee.tag == EverCrypt_Hash_SHA2_256_s)
  {
    return true;
  }
  else
  {
    return false;
  }
}

uint32_t
*EverCrypt_Hash___proj__SHA2_256_s__item__p(
  Spec_Hash_Definitions_hash_alg uu____440,
  EverCrypt_Hash_state_s projectee
)
{
  if (projectee.tag == EverCrypt_Hash_SHA2_256_s)
  {
    return projectee.val.case_SHA2_256_s;
  }
  else
  {
    KRML_HOST_PRINTF("KreMLin abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
}

bool
EverCrypt_Hash_uu___is_SHA2_384_s(
  Spec_Hash_Definitions_hash_alg uu____463,
  EverCrypt_Hash_state_s projectee
)
{
  if (projectee.tag == EverCrypt_Hash_SHA2_384_s)
  {
    return true;
  }
  else
  {
    return false;
  }
}

uint64_t
*EverCrypt_Hash___proj__SHA2_384_s__item__p(
  Spec_Hash_Definitions_hash_alg uu____491,
  EverCrypt_Hash_state_s projectee
)
{
  if (projectee.tag == EverCrypt_Hash_SHA2_384_s)
  {
    return projectee.val.case_SHA2_384_s;
  }
  else
  {
    KRML_HOST_PRINTF("KreMLin abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
}

bool
EverCrypt_Hash_uu___is_SHA2_512_s(
  Spec_Hash_Definitions_hash_alg uu____514,
  EverCrypt_Hash_state_s projectee
)
{
  if (projectee.tag == EverCrypt_Hash_SHA2_512_s)
  {
    return true;
  }
  else
  {
    return false;
  }
}

uint64_t
*EverCrypt_Hash___proj__SHA2_512_s__item__p(
  Spec_Hash_Definitions_hash_alg uu____542,
  EverCrypt_Hash_state_s projectee
)
{
  if (projectee.tag == EverCrypt_Hash_SHA2_512_s)
  {
    return projectee.val.case_SHA2_512_s;
  }
  else
  {
    KRML_HOST_PRINTF("KreMLin abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
}

/*

  val create_in :a: alg -> r: HS.rid
  -> ST (state a)
      (requires (fun _ -> HyperStack.ST.is_eternal_region r))
      (ensures
        (fun h0 s h1 ->
            invariant s h1 /\ M.(modifies loc_none h0 h1) /\
            fresh_loc (footprint s h1) h0 h1 /\
            M.(loc_includes (loc_region_only true r) (footprint s h1)) /\
            freeable h1 s))
*/
EverCrypt_Hash_state_s *EverCrypt_Hash_create_in(Spec_Hash_Definitions_hash_alg a)
{
  EverCrypt_Hash_state_s s;
  switch (a)
  {
    case Spec_Hash_Definitions_MD5:
      {
        EverCrypt_Hash_state_s lit;
        lit.tag = EverCrypt_Hash_MD5_s;
        {
          uint32_t *buf = KRML_HOST_CALLOC((uint32_t)4U, sizeof (uint32_t));
          lit.val.case_MD5_s = buf;
          s = lit;
        }
        break;
      }
    case Spec_Hash_Definitions_SHA1:
      {
        EverCrypt_Hash_state_s lit;
        lit.tag = EverCrypt_Hash_SHA1_s;
        {
          uint32_t *buf = KRML_HOST_CALLOC((uint32_t)5U, sizeof (uint32_t));
          lit.val.case_SHA1_s = buf;
          s = lit;
        }
        break;
      }
    case Spec_Hash_Definitions_SHA2_224:
      {
        EverCrypt_Hash_state_s lit;
        lit.tag = EverCrypt_Hash_SHA2_224_s;
        {
          uint32_t *buf = KRML_HOST_CALLOC((uint32_t)8U, sizeof (uint32_t));
          lit.val.case_SHA2_224_s = buf;
          s = lit;
        }
        break;
      }
    case Spec_Hash_Definitions_SHA2_256:
      {
        EverCrypt_Hash_state_s lit;
        lit.tag = EverCrypt_Hash_SHA2_256_s;
        {
          uint32_t *buf = KRML_HOST_CALLOC((uint32_t)8U, sizeof (uint32_t));
          lit.val.case_SHA2_256_s = buf;
          s = lit;
        }
        break;
      }
    case Spec_Hash_Definitions_SHA2_384:
      {
        EverCrypt_Hash_state_s lit;
        lit.tag = EverCrypt_Hash_SHA2_384_s;
        {
          uint64_t *buf = KRML_HOST_CALLOC((uint32_t)8U, sizeof (uint64_t));
          lit.val.case_SHA2_384_s = buf;
          s = lit;
        }
        break;
      }
    case Spec_Hash_Definitions_SHA2_512:
      {
        EverCrypt_Hash_state_s lit;
        lit.tag = EverCrypt_Hash_SHA2_512_s;
        {
          uint64_t *buf = KRML_HOST_CALLOC((uint32_t)8U, sizeof (uint64_t));
          lit.val.case_SHA2_512_s = buf;
          s = lit;
        }
        break;
      }
    default:
      {
        KRML_HOST_PRINTF("KreMLin incomplete match at %s:%d\n", __FILE__, __LINE__);
        KRML_HOST_EXIT(253U);
      }
  }
  KRML_CHECK_SIZE(sizeof (EverCrypt_Hash_state_s), (uint32_t)1U);
  {
    EverCrypt_Hash_state_s *buf = KRML_HOST_MALLOC(sizeof (EverCrypt_Hash_state_s));
    buf[0U] = s;
    return buf;
  }
}

/*

  val create :a: alg
  -> ST (state a)
      (requires fun h0 -> True)
      (ensures
        fun h0 s h1 ->
          invariant s h1 /\ M.(modifies loc_none h0 h1) /\
          fresh_loc (footprint s h1) h0 h1 /\ freeable h1 s)
*/
EverCrypt_Hash_state_s *EverCrypt_Hash_create(Spec_Hash_Definitions_hash_alg a)
{
  return EverCrypt_Hash_create_in(a);
}

/*

  val init :#a: e_alg
  -> (let a = Ghost.reveal a in
      s: state a
        -> ST unit
            (requires invariant s)
            (ensures
              fun h0 _ h1 ->
                invariant s h1 /\ repr s h1 == acc0 #a /\
                M.(modifies (footprint s h0) h0 h1) /\
                footprint s h0 == footprint s h1 /\ preserves_freeable s h0 h1))
*/
void EverCrypt_Hash_init(EverCrypt_Hash_state_s *s)
{
  EverCrypt_Hash_state_s scrut = *s;
  if (scrut.tag == EverCrypt_Hash_MD5_s)
  {
    uint32_t *p1 = scrut.val.case_MD5_s;
    Hacl_Hash_Core_MD5_init(p1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA1_s)
  {
    uint32_t *p1 = scrut.val.case_SHA1_s;
    Hacl_Hash_Core_SHA1_init(p1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_224_s)
  {
    uint32_t *p1 = scrut.val.case_SHA2_224_s;
    Hacl_Hash_Core_SHA2_init_224(p1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_256_s)
  {
    uint32_t *p1 = scrut.val.case_SHA2_256_s;
    Hacl_Hash_Core_SHA2_init_256(p1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_384_s)
  {
    uint64_t *p1 = scrut.val.case_SHA2_384_s;
    Hacl_Hash_Core_SHA2_init_384(p1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_512_s)
  {
    uint64_t *p1 = scrut.val.case_SHA2_512_s;
    Hacl_Hash_Core_SHA2_init_512(p1);
  }
  else
  {
    KRML_HOST_PRINTF("KreMLin abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
}

/*

  val update :#a: e_alg
  -> (let a = Ghost.reveal a in
      s: state a -> block: uint8_p{B.length block = block_length a}
        -> Stack unit
            (requires
              fun h0 ->
                invariant s h0 /\ B.live h0 block /\
                M.(loc_disjoint (footprint s h0) (loc_buffer block)))
            (ensures
              fun h0 _ h1 ->
                M.(modifies (footprint s h0) h0 h1) /\
                footprint s h0 == footprint s h1 /\ invariant s h1 /\
                repr s h1 == compress (repr s h0) (B.as_seq h0 block) /\
                preserves_freeable s h0 h1))
*/
void EverCrypt_Hash_update(EverCrypt_Hash_state_s *s, uint8_t *block1)
{
  EverCrypt_Hash_state_s scrut = *s;
  if (scrut.tag == EverCrypt_Hash_MD5_s)
  {
    uint32_t *p1 = scrut.val.case_MD5_s;
    Hacl_Hash_Core_MD5_update(p1, block1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA1_s)
  {
    uint32_t *p1 = scrut.val.case_SHA1_s;
    Hacl_Hash_Core_SHA1_update(p1, block1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_224_s)
  {
    uint32_t *p1 = scrut.val.case_SHA2_224_s;
    Hacl_Hash_Core_SHA2_update_224(p1, block1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_256_s)
  {
    uint32_t *p1 = scrut.val.case_SHA2_256_s;
    bool has_shaext1 = EverCrypt_AutoConfig2_has_shaext();
    Hacl_Hash_SHA2_update_multi_256(p1, block1, (uint32_t)1U);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_384_s)
  {
    uint64_t *p1 = scrut.val.case_SHA2_384_s;
    Hacl_Hash_Core_SHA2_update_384(p1, block1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_512_s)
  {
    uint64_t *p1 = scrut.val.case_SHA2_512_s;
    Hacl_Hash_Core_SHA2_update_512(p1, block1);
  }
  else
  {
    KRML_HOST_PRINTF("KreMLin abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
}

/*

  val update_multi :#a: e_alg
  -> (let a = Ghost.reveal a in
      
          s: state a ->
          blocks: uint8_p{B.length blocks % block_length a = 0} ->
          len: UInt32.t{v len = B.length blocks}
        -> Stack unit
            (requires
              fun h0 ->
                invariant s h0 /\ B.live h0 blocks /\
                M.(loc_disjoint (footprint s h0) (loc_buffer blocks)))
            (ensures
              fun h0 _ h1 ->
                M.(modifies (footprint s h0) h0 h1) /\
                footprint s h0 == footprint s h1 /\ invariant s h1 /\
                repr s h1 == compress_many (repr s h0) (B.as_seq h0 blocks) /\
                preserves_freeable s h0 h1))
*/
void EverCrypt_Hash_update_multi(EverCrypt_Hash_state_s *s, uint8_t *blocks, uint32_t len1)
{
  EverCrypt_Hash_state_s scrut = *s;
  if (scrut.tag == EverCrypt_Hash_MD5_s)
  {
    uint32_t *p1 = scrut.val.case_MD5_s;
    uint32_t n1 = len1 / (uint32_t)64U;
    Hacl_Hash_MD5_update_multi(p1, blocks, n1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA1_s)
  {
    uint32_t *p1 = scrut.val.case_SHA1_s;
    uint32_t n1 = len1 / (uint32_t)64U;
    Hacl_Hash_SHA1_update_multi(p1, blocks, n1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_224_s)
  {
    uint32_t *p1 = scrut.val.case_SHA2_224_s;
    uint32_t n1 = len1 / (uint32_t)64U;
    Hacl_Hash_SHA2_update_multi_224(p1, blocks, n1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_256_s)
  {
    uint32_t *p1 = scrut.val.case_SHA2_256_s;
    uint32_t n1 = len1 / (uint32_t)64U;
    bool has_shaext1 = EverCrypt_AutoConfig2_has_shaext();
    Hacl_Hash_SHA2_update_multi_256(p1, blocks, n1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_384_s)
  {
    uint64_t *p1 = scrut.val.case_SHA2_384_s;
    uint32_t n1 = len1 / (uint32_t)128U;
    Hacl_Hash_SHA2_update_multi_384(p1, blocks, n1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_512_s)
  {
    uint64_t *p1 = scrut.val.case_SHA2_512_s;
    uint32_t n1 = len1 / (uint32_t)128U;
    Hacl_Hash_SHA2_update_multi_512(p1, blocks, n1);
  }
  else
  {
    KRML_HOST_PRINTF("KreMLin abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
}

static void
EverCrypt_Hash_update_last_256(
  uint32_t *s,
  uint64_t prev_len,
  uint8_t *input,
  uint32_t input_len
)
{
  uint32_t blocks_n = input_len / (uint32_t)64U;
  uint32_t blocks_len = blocks_n * (uint32_t)64U;
  uint8_t *blocks = input;
  uint32_t rest_len = input_len - blocks_len;
  uint8_t *rest = input + blocks_len;
  bool has_shaext10 = EverCrypt_AutoConfig2_has_shaext();
  uint64_t total_input_len;
  uint32_t pad_len1;
  uint32_t tmp_len;
  uint8_t tmp_twoblocks[128U];
  uint8_t *tmp;
  uint8_t *tmp_rest;
  uint8_t *tmp_pad;
  bool has_shaext1;
  Hacl_Hash_SHA2_update_multi_256(s, blocks, blocks_n);
  total_input_len = prev_len + (uint64_t)input_len;
  pad_len1 =
    (uint32_t)1U
    +
      ((uint32_t)128U - ((uint32_t)9U + (uint32_t)(total_input_len % (uint64_t)(uint32_t)64U)))
      % (uint32_t)64U
    + (uint32_t)8U;
  tmp_len = rest_len + pad_len1;
  {
    uint8_t init = (uint8_t)0U;
    {
      uint32_t i;
      for (i = (uint32_t)0U; i < (uint32_t)128U; i = i + (uint32_t)1U)
      {
        tmp_twoblocks[i] = init;
      }
    }
    tmp = tmp_twoblocks;
    tmp_rest = tmp;
    tmp_pad = tmp + rest_len;
    memcpy(tmp_rest, rest, rest_len * sizeof rest[0U]);
    Hacl_Hash_Core_SHA2_pad_256(total_input_len, tmp_pad);
    has_shaext1 = EverCrypt_AutoConfig2_has_shaext();
    Hacl_Hash_SHA2_update_multi_256(s, tmp, tmp_len / (uint32_t)64U);
  }
}

/*

  val update_last :#a: e_alg
  -> (let a = Ghost.reveal a in
      
          s: state a ->
          last: uint8_p{B.length last < block_length a} ->
          total_len:
            uint64_t
              { v total_len < max_input_length a /\
                (v total_len - B.length last) % block_length a = 0 }
        -> Stack unit
            (requires
              fun h0 ->
                invariant s h0 /\ B.live h0 last /\
                M.(loc_disjoint (footprint s h0) (loc_buffer last)))
            (ensures
              fun h0 _ h1 ->
                invariant s h1 /\
                (B.length last +
                  Seq.length (Spec.Hash.PadFinish.pad a (v total_len))) %
                block_length a =
                0 /\
                repr s h1 ==
                compress_many (repr s h0)
                  (Seq.append (B.as_seq h0 last)
                      (Spec.Hash.PadFinish.pad a (v total_len))) /\
                M.(modifies (footprint s h0) h0 h1) /\
                footprint s h0 == footprint s h1 /\ preserves_freeable s h0 h1))
*/
void EverCrypt_Hash_update_last(EverCrypt_Hash_state_s *s, uint8_t *last1, uint64_t total_len)
{
  EverCrypt_Hash_state_s scrut = *s;
  if (scrut.tag == EverCrypt_Hash_MD5_s)
  {
    uint32_t *p1 = scrut.val.case_MD5_s;
    uint64_t input_len = total_len % (uint64_t)(uint32_t)64U;
    uint64_t prev_len = total_len - input_len;
    Hacl_Hash_MD5_update_last(p1, prev_len, last1, (uint32_t)input_len);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA1_s)
  {
    uint32_t *p1 = scrut.val.case_SHA1_s;
    uint64_t input_len = total_len % (uint64_t)(uint32_t)64U;
    uint64_t prev_len = total_len - input_len;
    Hacl_Hash_SHA1_update_last(p1, prev_len, last1, (uint32_t)input_len);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_224_s)
  {
    uint32_t *p1 = scrut.val.case_SHA2_224_s;
    uint64_t input_len = total_len % (uint64_t)(uint32_t)64U;
    uint64_t prev_len = total_len - input_len;
    Hacl_Hash_SHA2_update_last_224(p1, prev_len, last1, (uint32_t)input_len);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_256_s)
  {
    uint32_t *p1 = scrut.val.case_SHA2_256_s;
    uint64_t input_len = total_len % (uint64_t)(uint32_t)64U;
    uint64_t prev_len = total_len - input_len;
    EverCrypt_Hash_update_last_256(p1, prev_len, last1, (uint32_t)input_len);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_384_s)
  {
    uint64_t *p1 = scrut.val.case_SHA2_384_s;
    uint64_t input_len = total_len % (uint64_t)(uint32_t)128U;
    FStar_UInt128_uint128 prev_len = FStar_Int_Cast_Full_uint64_to_uint128(total_len - input_len);
    Hacl_Hash_SHA2_update_last_384(p1, prev_len, last1, (uint32_t)input_len);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_512_s)
  {
    uint64_t *p1 = scrut.val.case_SHA2_512_s;
    uint64_t input_len = total_len % (uint64_t)(uint32_t)128U;
    FStar_UInt128_uint128 prev_len = FStar_Int_Cast_Full_uint64_to_uint128(total_len - input_len);
    Hacl_Hash_SHA2_update_last_512(p1, prev_len, last1, (uint32_t)input_len);
  }
  else
  {
    KRML_HOST_PRINTF("KreMLin abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
}

/*

  val finish :#a: e_alg
  -> (let a = Ghost.reveal a in
      s: state a -> dst: uint8_p{B.length dst = hash_length a}
        -> Stack unit
            (requires
              fun h0 ->
                invariant s h0 /\ B.live h0 dst /\
                M.(loc_disjoint (footprint s h0) (loc_buffer dst)))
            (ensures
              fun h0 _ h1 ->
                invariant s h1 /\ M.(modifies (loc_buffer dst) h0 h1) /\
                footprint s h0 == footprint s h1 /\
                B.as_seq h1 dst == extract (repr s h0) /\
                preserves_freeable s h0 h1))
*/
void EverCrypt_Hash_finish(EverCrypt_Hash_state_s *s, uint8_t *dst)
{
  EverCrypt_Hash_state_s scrut = *s;
  if (scrut.tag == EverCrypt_Hash_MD5_s)
  {
    uint32_t *p1 = scrut.val.case_MD5_s;
    Hacl_Hash_Core_MD5_finish(p1, dst);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA1_s)
  {
    uint32_t *p1 = scrut.val.case_SHA1_s;
    Hacl_Hash_Core_SHA1_finish(p1, dst);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_224_s)
  {
    uint32_t *p1 = scrut.val.case_SHA2_224_s;
    Hacl_Hash_Core_SHA2_finish_224(p1, dst);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_256_s)
  {
    uint32_t *p1 = scrut.val.case_SHA2_256_s;
    Hacl_Hash_Core_SHA2_finish_256(p1, dst);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_384_s)
  {
    uint64_t *p1 = scrut.val.case_SHA2_384_s;
    Hacl_Hash_Core_SHA2_finish_384(p1, dst);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_512_s)
  {
    uint64_t *p1 = scrut.val.case_SHA2_512_s;
    Hacl_Hash_Core_SHA2_finish_512(p1, dst);
  }
  else
  {
    KRML_HOST_PRINTF("KreMLin abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
}

/*

  val free :#a: e_alg
  -> (let a = Ghost.reveal a in
      s: state a
        -> ST unit
            (requires fun h0 -> freeable h0 s /\ invariant s h0)
            (ensures
              fun h0 _ h1 -> let open M in modifies (footprint s h0) h0 h1))
*/
void EverCrypt_Hash_free(EverCrypt_Hash_state_s *s)
{
  EverCrypt_Hash_state_s scrut = *s;
  if (scrut.tag == EverCrypt_Hash_MD5_s)
  {
    uint32_t *p1 = scrut.val.case_MD5_s;
    KRML_HOST_FREE(p1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA1_s)
  {
    uint32_t *p1 = scrut.val.case_SHA1_s;
    KRML_HOST_FREE(p1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_224_s)
  {
    uint32_t *p1 = scrut.val.case_SHA2_224_s;
    KRML_HOST_FREE(p1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_256_s)
  {
    uint32_t *p1 = scrut.val.case_SHA2_256_s;
    KRML_HOST_FREE(p1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_384_s)
  {
    uint64_t *p1 = scrut.val.case_SHA2_384_s;
    KRML_HOST_FREE(p1);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_512_s)
  {
    uint64_t *p1 = scrut.val.case_SHA2_512_s;
    KRML_HOST_FREE(p1);
  }
  else
  {
    KRML_HOST_PRINTF("KreMLin abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
  KRML_HOST_FREE(s);
}

/*

  val copy :#a: e_alg
  -> (let a = Ghost.reveal a in
      s_src: state a -> s_dst: state a
        -> Stack unit
            (requires
              (fun h0 ->
                  invariant s_src h0 /\ invariant s_dst h0 /\
                  B.(loc_disjoint (footprint s_src h0) (footprint s_dst h0))))
            (ensures
              fun h0 _ h1 ->
                M.(modifies (footprint s_dst h0) h0 h1) /\
                footprint s_dst h0 == footprint s_dst h1 /\
                preserves_freeable s_dst h0 h1 /\ invariant s_dst h1 /\
                repr s_dst h1 == repr s_src h0))
*/
void EverCrypt_Hash_copy(EverCrypt_Hash_state_s *s_src, EverCrypt_Hash_state_s *s_dst)
{
  EverCrypt_Hash_state_s scrut = *s_src;
  if (scrut.tag == EverCrypt_Hash_MD5_s)
  {
    uint32_t *p_src = scrut.val.case_MD5_s;
    EverCrypt_Hash_state_s x1 = *s_dst;
    uint32_t *p_dst;
    if (x1.tag == EverCrypt_Hash_MD5_s)
    {
      p_dst = x1.val.case_MD5_s;
    }
    else
    {
      p_dst = KRML_EABORT(uint32_t *, "unreachable (pattern matches are exhaustive in F*)");
    }
    memcpy(p_dst, p_src, (uint32_t)4U * sizeof p_src[0U]);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA1_s)
  {
    uint32_t *p_src = scrut.val.case_SHA1_s;
    EverCrypt_Hash_state_s x1 = *s_dst;
    uint32_t *p_dst;
    if (x1.tag == EverCrypt_Hash_SHA1_s)
    {
      p_dst = x1.val.case_SHA1_s;
    }
    else
    {
      p_dst = KRML_EABORT(uint32_t *, "unreachable (pattern matches are exhaustive in F*)");
    }
    memcpy(p_dst, p_src, (uint32_t)5U * sizeof p_src[0U]);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_224_s)
  {
    uint32_t *p_src = scrut.val.case_SHA2_224_s;
    EverCrypt_Hash_state_s x1 = *s_dst;
    uint32_t *p_dst;
    if (x1.tag == EverCrypt_Hash_SHA2_224_s)
    {
      p_dst = x1.val.case_SHA2_224_s;
    }
    else
    {
      p_dst = KRML_EABORT(uint32_t *, "unreachable (pattern matches are exhaustive in F*)");
    }
    memcpy(p_dst, p_src, (uint32_t)8U * sizeof p_src[0U]);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_256_s)
  {
    uint32_t *p_src = scrut.val.case_SHA2_256_s;
    EverCrypt_Hash_state_s x1 = *s_dst;
    uint32_t *p_dst;
    if (x1.tag == EverCrypt_Hash_SHA2_256_s)
    {
      p_dst = x1.val.case_SHA2_256_s;
    }
    else
    {
      p_dst = KRML_EABORT(uint32_t *, "unreachable (pattern matches are exhaustive in F*)");
    }
    memcpy(p_dst, p_src, (uint32_t)8U * sizeof p_src[0U]);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_384_s)
  {
    uint64_t *p_src = scrut.val.case_SHA2_384_s;
    EverCrypt_Hash_state_s x1 = *s_dst;
    uint64_t *p_dst;
    if (x1.tag == EverCrypt_Hash_SHA2_384_s)
    {
      p_dst = x1.val.case_SHA2_384_s;
    }
    else
    {
      p_dst = KRML_EABORT(uint64_t *, "unreachable (pattern matches are exhaustive in F*)");
    }
    memcpy(p_dst, p_src, (uint32_t)8U * sizeof p_src[0U]);
  }
  else if (scrut.tag == EverCrypt_Hash_SHA2_512_s)
  {
    uint64_t *p_src = scrut.val.case_SHA2_512_s;
    EverCrypt_Hash_state_s x1 = *s_dst;
    uint64_t *p_dst;
    if (x1.tag == EverCrypt_Hash_SHA2_512_s)
    {
      p_dst = x1.val.case_SHA2_512_s;
    }
    else
    {
      p_dst = KRML_EABORT(uint64_t *, "unreachable (pattern matches are exhaustive in F*)");
    }
    memcpy(p_dst, p_src, (uint32_t)8U * sizeof p_src[0U]);
  }
  else
  {
    KRML_HOST_PRINTF("KreMLin abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
}

static void EverCrypt_Hash_hash_256(uint8_t *input, uint32_t input_len, uint8_t *dst)
{
  uint32_t
  s[8U] =
    {
      (uint32_t)0x6a09e667U, (uint32_t)0xbb67ae85U, (uint32_t)0x3c6ef372U, (uint32_t)0xa54ff53aU,
      (uint32_t)0x510e527fU, (uint32_t)0x9b05688cU, (uint32_t)0x1f83d9abU, (uint32_t)0x5be0cd19U
    };
  uint32_t blocks_n = input_len / (uint32_t)64U;
  uint32_t blocks_len = blocks_n * (uint32_t)64U;
  uint8_t *blocks = input;
  uint32_t rest_len = input_len - blocks_len;
  uint8_t *rest = input + blocks_len;
  Hacl_Hash_SHA2_update_multi_256(s, blocks, blocks_n);
  Hacl_Hash_SHA2_update_last_256(s, (uint64_t)blocks_len, rest, rest_len);
  Hacl_Hash_Core_SHA2_finish_256(s, dst);
}

/*

  val hash :
    a: alg ->
    dst: uint8_p{B.length dst = hash_length a} ->
    input: uint8_p ->
    len: uint32_t{B.length input = v len /\ v len < max_input_length a}
  -> Stack unit
      (requires
        fun h0 ->
          B.live h0 dst /\ B.live h0 input /\
          M.(loc_disjoint (loc_buffer input) (loc_buffer dst)))
      (ensures
        fun h0 _ h1 ->
          M.(modifies (loc_buffer dst) h0 h1) /\
          B.as_seq h1 dst == Spec.Hash.hash a (B.as_seq h0 input))
*/
void
EverCrypt_Hash_hash(
  Spec_Hash_Definitions_hash_alg a,
  uint8_t *dst,
  uint8_t *input,
  uint32_t len1
)
{
  switch (a)
  {
    case Spec_Hash_Definitions_MD5:
      {
        Hacl_Hash_MD5_hash(input, len1, dst);
        break;
      }
    case Spec_Hash_Definitions_SHA1:
      {
        Hacl_Hash_SHA1_hash(input, len1, dst);
        break;
      }
    case Spec_Hash_Definitions_SHA2_224:
      {
        Hacl_Hash_SHA2_hash_224(input, len1, dst);
        break;
      }
    case Spec_Hash_Definitions_SHA2_256:
      {
        EverCrypt_Hash_hash_256(input, len1, dst);
        break;
      }
    case Spec_Hash_Definitions_SHA2_384:
      {
        Hacl_Hash_SHA2_hash_384(input, len1, dst);
        break;
      }
    case Spec_Hash_Definitions_SHA2_512:
      {
        Hacl_Hash_SHA2_hash_512(input, len1, dst);
        break;
      }
    default:
      {
        KRML_HOST_PRINTF("KreMLin incomplete match at %s:%d\n", __FILE__, __LINE__);
        KRML_HOST_EXIT(253U);
      }
  }
}

bool
EverCrypt_Hash_Incremental_uu___is_State(
  Spec_Hash_Definitions_hash_alg a,
  EverCrypt_Hash_Incremental_state projectee
)
{
  return true;
}

EverCrypt_Hash_state_s
*EverCrypt_Hash_Incremental___proj__State__item__hash_state(
  Spec_Hash_Definitions_hash_alg a,
  EverCrypt_Hash_Incremental_state projectee
)
{
  return projectee.hash_state;
}

uint8_t
*EverCrypt_Hash_Incremental___proj__State__item__buf(
  Spec_Hash_Definitions_hash_alg a,
  EverCrypt_Hash_Incremental_state projectee
)
{
  return projectee.buf;
}

uint64_t
EverCrypt_Hash_Incremental___proj__State__item__total_len(
  Spec_Hash_Definitions_hash_alg a,
  EverCrypt_Hash_Incremental_state projectee
)
{
  return projectee.total_len;
}

/*

  val create_in :a: Hash.alg -> r: HS.rid
  -> ST (state a)
      (requires (fun _ -> HyperStack.ST.is_eternal_region r))
      (ensures
        (fun h0 s h1 ->
            hashes h1 s S.empty /\ B.(modifies (footprint s h1) h0 h1) /\
            Hash.fresh_loc (footprint s h1) h0 h1 /\
            B.(loc_includes (loc_region_only true r) (footprint s h1)) /\
            freeable s h1))
*/
EverCrypt_Hash_Incremental_state
EverCrypt_Hash_Incremental_create_in(Spec_Hash_Definitions_hash_alg a)
{
  uint32_t sw;
  switch (a)
  {
    case Spec_Hash_Definitions_MD5:
      {
        sw = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA1:
      {
        sw = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_224:
      {
        sw = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_256:
      {
        sw = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_384:
      {
        sw = (uint32_t)128U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_512:
      {
        sw = (uint32_t)128U;
        break;
      }
    default:
      {
        KRML_HOST_PRINTF("KreMLin incomplete match at %s:%d\n", __FILE__, __LINE__);
        KRML_HOST_EXIT(253U);
      }
  }
  KRML_CHECK_SIZE(sizeof (uint8_t), sw);
  {
    uint8_t *buf1 = KRML_HOST_CALLOC(sw, sizeof (uint8_t));
    EverCrypt_Hash_state_s *hash_state = EverCrypt_Hash_create_in(a);
    EverCrypt_Hash_Incremental_state s;
    s.hash_state = hash_state;
    s.buf = buf1;
    s.total_len = (uint64_t)0U;
    EverCrypt_Hash_init(hash_state);
    return s;
  }
}

static EverCrypt_Hash_Incremental_state
EverCrypt_Hash_Incremental_update_small(
  Spec_Hash_Definitions_hash_alg a,
  EverCrypt_Hash_Incremental_state s,
  uint8_t *data,
  uint32_t len1
)
{
  EverCrypt_Hash_state_s *hash_state = s.hash_state;
  uint8_t *buf1 = s.buf;
  uint64_t total_len = s.total_len;
  uint32_t sw;
  switch (a)
  {
    case Spec_Hash_Definitions_MD5:
      {
        sw = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA1:
      {
        sw = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_224:
      {
        sw = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_256:
      {
        sw = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_384:
      {
        sw = (uint32_t)128U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_512:
      {
        sw = (uint32_t)128U;
        break;
      }
    default:
      {
        KRML_HOST_PRINTF("KreMLin incomplete match at %s:%d\n", __FILE__, __LINE__);
        KRML_HOST_EXIT(253U);
      }
  }
  {
    uint32_t sz = (uint32_t)(total_len % (uint64_t)sw);
    uint8_t *buf2 = buf1 + sz;
    memcpy(buf2, data, len1 * sizeof data[0U]);
    {
      EverCrypt_Hash_Incremental_state lit;
      lit.hash_state = hash_state;
      lit.buf = buf1;
      lit.total_len = total_len + (uint64_t)len1;
      return lit;
    }
  }
}

static EverCrypt_Hash_Incremental_state
EverCrypt_Hash_Incremental_update_empty_buf(
  Spec_Hash_Definitions_hash_alg a,
  EverCrypt_Hash_Incremental_state s,
  uint8_t *data,
  uint32_t len1
)
{
  EverCrypt_Hash_state_s *hash_state = s.hash_state;
  uint8_t *buf1 = s.buf;
  uint64_t total_len = s.total_len;
  uint32_t sw0;
  switch (a)
  {
    case Spec_Hash_Definitions_MD5:
      {
        sw0 = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA1:
      {
        sw0 = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_224:
      {
        sw0 = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_256:
      {
        sw0 = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_384:
      {
        sw0 = (uint32_t)128U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_512:
      {
        sw0 = (uint32_t)128U;
        break;
      }
    default:
      {
        KRML_HOST_PRINTF("KreMLin incomplete match at %s:%d\n", __FILE__, __LINE__);
        KRML_HOST_EXIT(253U);
      }
  }
  {
    uint32_t sz = (uint32_t)(total_len % (uint64_t)sw0);
    uint32_t sw1;
    switch (a)
    {
      case Spec_Hash_Definitions_MD5:
        {
          sw1 = (uint32_t)64U;
          break;
        }
      case Spec_Hash_Definitions_SHA1:
        {
          sw1 = (uint32_t)64U;
          break;
        }
      case Spec_Hash_Definitions_SHA2_224:
        {
          sw1 = (uint32_t)64U;
          break;
        }
      case Spec_Hash_Definitions_SHA2_256:
        {
          sw1 = (uint32_t)64U;
          break;
        }
      case Spec_Hash_Definitions_SHA2_384:
        {
          sw1 = (uint32_t)128U;
          break;
        }
      case Spec_Hash_Definitions_SHA2_512:
        {
          sw1 = (uint32_t)128U;
          break;
        }
      default:
        {
          KRML_HOST_PRINTF("KreMLin incomplete match at %s:%d\n", __FILE__, __LINE__);
          KRML_HOST_EXIT(253U);
        }
    }
    {
      uint32_t n_blocks = len1 / sw1;
      uint32_t sw;
      switch (a)
      {
        case Spec_Hash_Definitions_MD5:
          {
            sw = (uint32_t)64U;
            break;
          }
        case Spec_Hash_Definitions_SHA1:
          {
            sw = (uint32_t)64U;
            break;
          }
        case Spec_Hash_Definitions_SHA2_224:
          {
            sw = (uint32_t)64U;
            break;
          }
        case Spec_Hash_Definitions_SHA2_256:
          {
            sw = (uint32_t)64U;
            break;
          }
        case Spec_Hash_Definitions_SHA2_384:
          {
            sw = (uint32_t)128U;
            break;
          }
        case Spec_Hash_Definitions_SHA2_512:
          {
            sw = (uint32_t)128U;
            break;
          }
        default:
          {
            KRML_HOST_PRINTF("KreMLin incomplete match at %s:%d\n", __FILE__, __LINE__);
            KRML_HOST_EXIT(253U);
          }
      }
      {
        uint32_t data1_len = n_blocks * sw;
        uint32_t data2_len = len1 - data1_len;
        uint8_t *data1 = data;
        uint8_t *data2 = data + data1_len;
        uint8_t *dst;
        EverCrypt_Hash_update_multi(hash_state, data1, data1_len);
        dst = buf1;
        memcpy(dst, data2, data2_len * sizeof data2[0U]);
        {
          EverCrypt_Hash_Incremental_state lit;
          lit.hash_state = hash_state;
          lit.buf = buf1;
          lit.total_len = total_len + (uint64_t)len1;
          return lit;
        }
      }
    }
  }
}

static EverCrypt_Hash_Incremental_state
EverCrypt_Hash_Incremental_update_round(
  Spec_Hash_Definitions_hash_alg a,
  EverCrypt_Hash_Incremental_state s,
  uint8_t *data,
  uint32_t len1
)
{
  EverCrypt_Hash_state_s *hash_state = s.hash_state;
  uint8_t *buf_ = s.buf;
  uint64_t total_len = s.total_len;
  uint32_t sw0;
  switch (a)
  {
    case Spec_Hash_Definitions_MD5:
      {
        sw0 = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA1:
      {
        sw0 = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_224:
      {
        sw0 = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_256:
      {
        sw0 = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_384:
      {
        sw0 = (uint32_t)128U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_512:
      {
        sw0 = (uint32_t)128U;
        break;
      }
    default:
      {
        KRML_HOST_PRINTF("KreMLin incomplete match at %s:%d\n", __FILE__, __LINE__);
        KRML_HOST_EXIT(253U);
      }
  }
  {
    uint32_t sz = (uint32_t)(total_len % (uint64_t)sw0);
    uint32_t sw1;
    switch (a)
    {
      case Spec_Hash_Definitions_MD5:
        {
          sw1 = (uint32_t)64U;
          break;
        }
      case Spec_Hash_Definitions_SHA1:
        {
          sw1 = (uint32_t)64U;
          break;
        }
      case Spec_Hash_Definitions_SHA2_224:
        {
          sw1 = (uint32_t)64U;
          break;
        }
      case Spec_Hash_Definitions_SHA2_256:
        {
          sw1 = (uint32_t)64U;
          break;
        }
      case Spec_Hash_Definitions_SHA2_384:
        {
          sw1 = (uint32_t)128U;
          break;
        }
      case Spec_Hash_Definitions_SHA2_512:
        {
          sw1 = (uint32_t)128U;
          break;
        }
      default:
        {
          KRML_HOST_PRINTF("KreMLin incomplete match at %s:%d\n", __FILE__, __LINE__);
          KRML_HOST_EXIT(253U);
        }
    }
    {
      uint32_t diff = sw1 - sz;
      uint8_t *buf0 = buf_;
      uint8_t *buf2 = buf0 + sz;
      uint32_t sw;
      memcpy(buf2, data, diff * sizeof data[0U]);
      switch (a)
      {
        case Spec_Hash_Definitions_MD5:
          {
            sw = (uint32_t)64U;
            break;
          }
        case Spec_Hash_Definitions_SHA1:
          {
            sw = (uint32_t)64U;
            break;
          }
        case Spec_Hash_Definitions_SHA2_224:
          {
            sw = (uint32_t)64U;
            break;
          }
        case Spec_Hash_Definitions_SHA2_256:
          {
            sw = (uint32_t)64U;
            break;
          }
        case Spec_Hash_Definitions_SHA2_384:
          {
            sw = (uint32_t)128U;
            break;
          }
        case Spec_Hash_Definitions_SHA2_512:
          {
            sw = (uint32_t)128U;
            break;
          }
        default:
          {
            KRML_HOST_PRINTF("KreMLin incomplete match at %s:%d\n", __FILE__, __LINE__);
            KRML_HOST_EXIT(253U);
          }
      }
      EverCrypt_Hash_update_multi(hash_state, buf0, sw);
      {
        EverCrypt_Hash_Incremental_state lit;
        lit.hash_state = hash_state;
        lit.buf = buf_;
        lit.total_len = total_len + (uint64_t)len1;
        return lit;
      }
    }
  }
}

/*

  val update :
    a: Hash.alg ->
    s: state a ->
    prev: G.erased bytes ->
    data: B.buffer UInt8.t ->
    len: UInt32.t
  -> Stack (state a)
      (requires fun h0 -> update_pre a s prev data len h0)
      (ensures fun h0 s' h1 -> update_post a s s' prev data len h0 h1)
*/
EverCrypt_Hash_Incremental_state
EverCrypt_Hash_Incremental_update(
  Spec_Hash_Definitions_hash_alg a,
  EverCrypt_Hash_Incremental_state s,
  uint8_t *data,
  uint32_t len1
)
{
  uint64_t total_len = s.total_len;
  uint32_t sw0;
  switch (a)
  {
    case Spec_Hash_Definitions_MD5:
      {
        sw0 = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA1:
      {
        sw0 = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_224:
      {
        sw0 = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_256:
      {
        sw0 = (uint32_t)64U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_384:
      {
        sw0 = (uint32_t)128U;
        break;
      }
    case Spec_Hash_Definitions_SHA2_512:
      {
        sw0 = (uint32_t)128U;
        break;
      }
    default:
      {
        KRML_HOST_PRINTF("KreMLin incomplete match at %s:%d\n", __FILE__, __LINE__);
        KRML_HOST_EXIT(253U);
      }
  }
  {
    uint32_t sz = (uint32_t)(total_len % (uint64_t)sw0);
    uint32_t sw;
    switch (a)
    {
      case Spec_Hash_Definitions_MD5:
        {
          sw = (uint32_t)64U;
          break;
        }
      case Spec_Hash_Definitions_SHA1:
        {
          sw = (uint32_t)64U;
          break;
        }
      case Spec_Hash_Definitions_SHA2_224:
        {
          sw = (uint32_t)64U;
          break;
        }
      case Spec_Hash_Definitions_SHA2_256:
        {
          sw = (uint32_t)64U;
          break;
        }
      case Spec_Hash_Definitions_SHA2_384:
        {
          sw = (uint32_t)128U;
          break;
        }
      case Spec_Hash_Definitions_SHA2_512:
        {
          sw = (uint32_t)128U;
          break;
        }
      default:
        {
          KRML_HOST_PRINTF("KreMLin incomplete match at %s:%d\n", __FILE__, __LINE__);
          KRML_HOST_EXIT(253U);
        }
    }
    if (len1 < sw - sz)
    {
      return EverCrypt_Hash_Incremental_update_small(a, s, data, len1);
    }
    else if (sz == (uint32_t)0U)
    {
      return EverCrypt_Hash_Incremental_update_empty_buf(a, s, data, len1);
    }
    else
    {
      uint32_t sw1;
      switch (a)
      {
        case Spec_Hash_Definitions_MD5:
          {
            sw1 = (uint32_t)64U;
            break;
          }
        case Spec_Hash_Definitions_SHA1:
          {
            sw1 = (uint32_t)64U;
            break;
          }
        case Spec_Hash_Definitions_SHA2_224:
          {
            sw1 = (uint32_t)64U;
            break;
          }
        case Spec_Hash_Definitions_SHA2_256:
          {
            sw1 = (uint32_t)64U;
            break;
          }
        case Spec_Hash_Definitions_SHA2_384:
          {
            sw1 = (uint32_t)128U;
            break;
          }
        case Spec_Hash_Definitions_SHA2_512:
          {
            sw1 = (uint32_t)128U;
            break;
          }
        default:
          {
            KRML_HOST_PRINTF("KreMLin incomplete match at %s:%d\n", __FILE__, __LINE__);
            KRML_HOST_EXIT(253U);
          }
      }
      {
        uint32_t diff = sw1 - sz;
        uint8_t *data1 = data;
        uint8_t *data2 = data + diff;
        EverCrypt_Hash_Incremental_state
        s1 = EverCrypt_Hash_Incremental_update_round(a, s, data1, diff);
        EverCrypt_Hash_Incremental_state
        s2 = EverCrypt_Hash_Incremental_update_empty_buf(a, s1, data2, len1 - diff);
        return s2;
      }
    }
  }
}

static void
EverCrypt_Hash_Incremental_finish_md5(EverCrypt_Hash_Incremental_state s, uint8_t *dst)
{
  EverCrypt_Hash_state_s *hash_state = s.hash_state;
  uint8_t *buf_ = s.buf;
  uint64_t total_len = s.total_len;
  uint8_t *buf_1 = buf_;
  EverCrypt_Hash_state_s s1;
  uint32_t buf[4U];
  EverCrypt_Hash_state_s tmp_hash_state[1U];
  s1.tag = EverCrypt_Hash_MD5_s;
  {
    uint32_t init = (uint32_t)0U;
    {
      uint32_t i;
      for (i = (uint32_t)0U; i < (uint32_t)4U; i = i + (uint32_t)1U)
      {
        buf[i] = init;
      }
    }
    s1.val.case_MD5_s = buf;
    tmp_hash_state[0U] = s1;
    EverCrypt_Hash_copy(hash_state, tmp_hash_state);
    EverCrypt_Hash_update_last(tmp_hash_state, buf_1, total_len);
    EverCrypt_Hash_finish(tmp_hash_state, dst);
  }
}

static void
EverCrypt_Hash_Incremental_finish_sha1(EverCrypt_Hash_Incremental_state s, uint8_t *dst)
{
  EverCrypt_Hash_state_s *hash_state = s.hash_state;
  uint8_t *buf_ = s.buf;
  uint64_t total_len = s.total_len;
  uint8_t *buf_1 = buf_;
  EverCrypt_Hash_state_s s1;
  uint32_t buf[5U];
  EverCrypt_Hash_state_s tmp_hash_state[1U];
  s1.tag = EverCrypt_Hash_SHA1_s;
  {
    uint32_t init = (uint32_t)0U;
    {
      uint32_t i;
      for (i = (uint32_t)0U; i < (uint32_t)5U; i = i + (uint32_t)1U)
      {
        buf[i] = init;
      }
    }
    s1.val.case_SHA1_s = buf;
    tmp_hash_state[0U] = s1;
    EverCrypt_Hash_copy(hash_state, tmp_hash_state);
    EverCrypt_Hash_update_last(tmp_hash_state, buf_1, total_len);
    EverCrypt_Hash_finish(tmp_hash_state, dst);
  }
}

static void
EverCrypt_Hash_Incremental_finish_sha224(EverCrypt_Hash_Incremental_state s, uint8_t *dst)
{
  EverCrypt_Hash_state_s *hash_state = s.hash_state;
  uint8_t *buf_ = s.buf;
  uint64_t total_len = s.total_len;
  uint8_t *buf_1 = buf_;
  EverCrypt_Hash_state_s s1;
  uint32_t buf[8U];
  EverCrypt_Hash_state_s tmp_hash_state[1U];
  s1.tag = EverCrypt_Hash_SHA2_224_s;
  {
    uint32_t init = (uint32_t)0U;
    {
      uint32_t i;
      for (i = (uint32_t)0U; i < (uint32_t)8U; i = i + (uint32_t)1U)
      {
        buf[i] = init;
      }
    }
    s1.val.case_SHA2_224_s = buf;
    tmp_hash_state[0U] = s1;
    EverCrypt_Hash_copy(hash_state, tmp_hash_state);
    EverCrypt_Hash_update_last(tmp_hash_state, buf_1, total_len);
    EverCrypt_Hash_finish(tmp_hash_state, dst);
  }
}

static void
EverCrypt_Hash_Incremental_finish_sha256(EverCrypt_Hash_Incremental_state s, uint8_t *dst)
{
  EverCrypt_Hash_state_s *hash_state = s.hash_state;
  uint8_t *buf_ = s.buf;
  uint64_t total_len = s.total_len;
  uint8_t *buf_1 = buf_;
  EverCrypt_Hash_state_s s1;
  uint32_t buf[8U];
  EverCrypt_Hash_state_s tmp_hash_state[1U];
  s1.tag = EverCrypt_Hash_SHA2_256_s;
  {
    uint32_t init = (uint32_t)0U;
    {
      uint32_t i;
      for (i = (uint32_t)0U; i < (uint32_t)8U; i = i + (uint32_t)1U)
      {
        buf[i] = init;
      }
    }
    s1.val.case_SHA2_256_s = buf;
    tmp_hash_state[0U] = s1;
    EverCrypt_Hash_copy(hash_state, tmp_hash_state);
    EverCrypt_Hash_update_last(tmp_hash_state, buf_1, total_len);
    EverCrypt_Hash_finish(tmp_hash_state, dst);
  }
}

static void
EverCrypt_Hash_Incremental_finish_sha384(EverCrypt_Hash_Incremental_state s, uint8_t *dst)
{
  EverCrypt_Hash_state_s *hash_state = s.hash_state;
  uint8_t *buf_ = s.buf;
  uint64_t total_len = s.total_len;
  uint8_t *buf_1 = buf_;
  EverCrypt_Hash_state_s s1;
  uint64_t buf[8U];
  EverCrypt_Hash_state_s tmp_hash_state[1U];
  s1.tag = EverCrypt_Hash_SHA2_384_s;
  {
    uint64_t init = (uint64_t)0U;
    {
      uint32_t i;
      for (i = (uint32_t)0U; i < (uint32_t)8U; i = i + (uint32_t)1U)
      {
        buf[i] = init;
      }
    }
    s1.val.case_SHA2_384_s = buf;
    tmp_hash_state[0U] = s1;
    EverCrypt_Hash_copy(hash_state, tmp_hash_state);
    EverCrypt_Hash_update_last(tmp_hash_state, buf_1, total_len);
    EverCrypt_Hash_finish(tmp_hash_state, dst);
  }
}

static void
EverCrypt_Hash_Incremental_finish_sha512(EverCrypt_Hash_Incremental_state s, uint8_t *dst)
{
  EverCrypt_Hash_state_s *hash_state = s.hash_state;
  uint8_t *buf_ = s.buf;
  uint64_t total_len = s.total_len;
  uint8_t *buf_1 = buf_;
  EverCrypt_Hash_state_s s1;
  uint64_t buf[8U];
  EverCrypt_Hash_state_s tmp_hash_state[1U];
  s1.tag = EverCrypt_Hash_SHA2_512_s;
  {
    uint64_t init = (uint64_t)0U;
    {
      uint32_t i;
      for (i = (uint32_t)0U; i < (uint32_t)8U; i = i + (uint32_t)1U)
      {
        buf[i] = init;
      }
    }
    s1.val.case_SHA2_512_s = buf;
    tmp_hash_state[0U] = s1;
    EverCrypt_Hash_copy(hash_state, tmp_hash_state);
    EverCrypt_Hash_update_last(tmp_hash_state, buf_1, total_len);
    EverCrypt_Hash_finish(tmp_hash_state, dst);
  }
}

/*

  val finish :a: Hash.alg -> finish_st a
*/
void
EverCrypt_Hash_Incremental_finish(
  Spec_Hash_Definitions_hash_alg a,
  EverCrypt_Hash_Incremental_state s,
  uint8_t *dst
)
{
  switch (a)
  {
    case Spec_Hash_Definitions_MD5:
      {
        EverCrypt_Hash_Incremental_finish_md5(s, dst);
        break;
      }
    case Spec_Hash_Definitions_SHA1:
      {
        EverCrypt_Hash_Incremental_finish_sha1(s, dst);
        break;
      }
    case Spec_Hash_Definitions_SHA2_224:
      {
        EverCrypt_Hash_Incremental_finish_sha224(s, dst);
        break;
      }
    case Spec_Hash_Definitions_SHA2_256:
      {
        EverCrypt_Hash_Incremental_finish_sha256(s, dst);
        break;
      }
    case Spec_Hash_Definitions_SHA2_384:
      {
        EverCrypt_Hash_Incremental_finish_sha384(s, dst);
        break;
      }
    case Spec_Hash_Definitions_SHA2_512:
      {
        EverCrypt_Hash_Incremental_finish_sha512(s, dst);
        break;
      }
    default:
      {
        KRML_HOST_PRINTF("KreMLin incomplete match at %s:%d\n", __FILE__, __LINE__);
        KRML_HOST_EXIT(253U);
      }
  }
}

